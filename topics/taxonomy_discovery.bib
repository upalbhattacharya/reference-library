@Comment{
ebib-main-file: /home/upal/References/bibliography.bib
}


@InProceedings{jain2022DistillingHypernymyRelations,
	keywords = {taxonomy discovery},
	file = {References/pdf/jain2022DistillingHypernymyRelations.pdf},
	author = {Devansh Jain and Luis Espinosa Anke},
	title = {Distilling Hypernymy Relations from Language Models:
                  On the Effectiveness of Zero-Shot Taxonomy
                  Induction},
	year = 2022,
	booktitle = {Proceedings of the 11th Joint Conference on Lexical
                  and Computational Semantics, *SEM@NAACL-HLT 2022,
                  Seattle, WA, USA, July 14-15, 2022},
	pages = {151-156},
	doi = {10.18653/V1/2022.STARSEM-1.13},
	url = {https://doi.org/10.18653/v1/2022.starsem-1.13},
	crossref = {DBLP:conf/starsem/2022},
	timestamp = {Thu, 22 Aug 2024 07:28:05 +0200},
	biburl = {https://dblp.org/rec/conf/starsem/JainA22.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{cocos2018ComparingConstraintsTaxonomic,
	keywords = {taxonomy discovery},
	file = {References/pdf/cocos2018ComparingConstraintsTaxonomic.pdf},
	author = {Anne Cocos and Marianna Apidianaki and Chris
                  Callison{-}Burch},
	title = {Comparing Constraints for Taxonomic Organization},
	year = 2018,
	booktitle = {Proceedings of the 2018 Conference of the North
                  American Chapter of the Association for
                  Computational Linguistics: Human Language
                  Technologies, {NAACL-HLT} 2018, New Orleans,
                  Louisiana, USA, June 1-6, 2018, Volume 1 (Long
                  Papers)},
	pages = {323-333},
	doi = {10.18653/V1/N18-1030},
	url = {https://doi.org/10.18653/v1/n18-1030},
	crossref = {DBLP:conf/naacl/2018-1},
	timestamp = {Fri, 06 Aug 2021 00:41:32 +0200},
	biburl = {https://dblp.org/rec/conf/naacl/CocosAC18.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{chen2021ConstructingTaxonomiesPretrained,
	keywords = {taxonomy discovery},
	file = {References/pdf/chen2021ConstructingTaxonomiesPretrained.pdf},
	author = {Catherine Chen and Kevin Lin and Dan Klein},
	title = {Constructing Taxonomies from Pretrained Language
                  Models},
	year = 2021,
	booktitle = {Proceedings of the 2021 Conference of the North
                  American Chapter of the Association for
                  Computational Linguistics: Human Language
                  Technologies, {NAACL-HLT} 2021, Online, June 6-11,
                  2021},
	pages = {4687-4700},
	doi = {10.18653/V1/2021.NAACL-MAIN.373},
	url = {https://doi.org/10.18653/v1/2021.naacl-main.373},
	crossref = {DBLP:conf/naacl/2021},
	timestamp = {Mon, 19 May 2025 23:15:41 +0200},
	biburl = {https://dblp.org/rec/conf/naacl/ChenLK21.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{babaei2023Llms4olLargeLanguage,
	title = {{{LLMs4OL}}: {{Large Language Models}} for {{Ontology Learning}}},
	shorttitle = {{{LLMs4OL}}},
	booktitle = {The {{Semantic Web}} – {{ISWC}} 2023},
	author = {Babaei Giglou, Hamed and D'Souza, Jennifer and Auer, Sören},
	editor = {Payne, Terry R. and Presutti, Valentina and Qi, Guilin and Poveda-Villalón, María and Stoilos, Giorgos and Hollink, Laura and Kaoudi, Zoi and Cheng, Gong and Li, Juanzi},
	date = {2023},
	pages = {408--427},
	publisher = {Springer Nature Switzerland},
	location = {Cham},
	doi = {10.1007/978-3-031-47240-4_22},
	abstract = {We propose the LLMs4OL approach, which utilizes Large Language Models (LLMs) for Ontology Learning (OL). LLMs have shown significant advancements in natural language processing, demonstrating their ability to capture complex language patterns in different knowledge domains. Our LLMs4OL paradigm investigates the following hypothesis: Can LLMs effectively apply their language pattern capturing capability to OL, which involves automatically extracting and structuring knowledge from natural language text? To test this hypothesis, we conduct a comprehensive evaluation using the zero-shot prompting method. We evaluate nine different LLM model families for three main OL tasks: term typing, taxonomy discovery, and extraction of non-taxonomic relations. Additionally, the evaluations encompass diverse genres of ontological knowledge, including lexicosemantic knowledge in WordNet, geographical knowledge in GeoNames, and medical knowledge in UMLS.},
	isbn = {978-3-031-47240-4},
	langid = {english},
	keywords = {Important,Large Language Models,LLMs,Ontologies,Ontology Learning,Prompt-based Learning,Prompting, taxonomy discovery},
	timestamp = {2024-09-12T12:01:26Z},
	file = {References/pdf/babaei2023Llms4olLargeLanguage.pdf}
}

@Online{chen2023PromptingOrFine,
	keywords = {taxonomy discovery, review},
	file = {References/pdf/chen2023PromptingOrFine.pdf},
	author = {Boqi Chen AND Fandi Yi AND Dániel Varró},
	title = {{Prompting or Fine-tuning? A Comparative Study of
                  Large Language Models for Taxonomy Construction}},
	year = 2023,
	eprint = {2309.01715v1},
	primaryclass = {cs.CL},
	archiveprefix = {arXiv}
}

@InProceedings{funk2023TowardsOntologyConstruction,
	file = {References/pdf/funk2023TowardsOntologyConstruction.pdf},
	title = {Towards {{Ontology Construction}} with {{Language Models}}},
	booktitle = {{{KBC-LM}} @ {{ISWC}} 2023},
	author = {Funk, Maurice and Hosemann, Simon and Jung, Jean Christoph and Lutz, Carsten},
	date = {2023},
	doi = {10.48550/arXiv.2309.09898},
	abstract = {An academic search engine that utilizes artificial intelligence methods to provide highly relevant results and novel tools to filter them with ease.},
	langid = {english},
	timestamp = {2024-07-25T09:10:54Z}
}

