
@InProceedings{zhu2024HotOrCold,
	file = {References/pdf/zhu2024HotOrCold.pdf},
	author = {Yuqi Zhu and Jia Li and Ge Li and Yunfei Zhao and
                  Jia Li and Zhi Jin and Hong Mei},
	title = {Hot or Cold? Adaptive Temperature Sampling for Code
                  Generation with Large Language Models},
	year = 2024,
	booktitle = {Thirty-Eighth {AAAI} Conference on Artificial
                  Intelligence, {AAAI} 2024, Thirty-Sixth Conference
                  on Innovative Applications of Artificial
                  Intelligence, {IAAI} 2024, Fourteenth Symposium on
                  Educational Advances in Artificial Intelligence,
                  {EAAI} 2014, February 20-27, 2024, Vancouver,
                  Canada},
	pages = {437-445},
	doi = {10.1609/AAAI.V38I1.27798},
	url = {https://doi.org/10.1609/aaai.v38i1.27798},
	crossref = {DBLP:conf/aaai/2024},
	timestamp = {Thu, 25 Sep 2025 08:48:18 +0200},
	biburl = {https://dblp.org/rec/conf/aaai/ZhuLLZLJ024.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{xu2020BriefReviewRelation,
	file = {References/pdf/xu2020BriefReviewRelation.pdf},
	author = {Tiange Xu and Fu Zhang},
	title = {A Brief Review of Relation Extraction Based on
                  Pre-Trained Language Models},
	year = 2020,
	booktitle = {Fuzzy Systems and Data Mining {VI} - Proceedings of
                  {FSDM} 2020, Virtual Event, November 13-16, 2020},
	pages = {775-789},
	doi = {10.3233/FAIA200755},
	url = {https://doi.org/10.3233/FAIA200755},
	crossref = {DBLP:conf/fsdm/2020},
	timestamp = {Mon, 24 Jun 2024 20:34:52 +0200},
	biburl = {https://dblp.org/rec/conf/fsdm/XuZ20.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{wilson2022OntologyQualityEvaluation,
	file = {References/pdf/wilson2022OntologyQualityEvaluation.pdf},
	author = {R. Shyama I. Wilson and Jeevani S. Goonetillake and
                  Athula Ginige and Anusha Indika Walisadeera},
	title = {Ontology Quality Evaluation Methodology},
	year = 2022,
	booktitle = {Computational Science and Its Applications - {ICCSA}
                  2022 - 22nd International Conference, Malaga, Spain,
                  July 4-7, 2022, Proceedings, Part {I}},
	pages = {509-528},
	doi = {10.1007/978-3-031-10522-7\_35},
	url = {https://doi.org/10.1007/978-3-031-10522-7\_35},
	crossref = {DBLP:conf/iccsa/2022-1},
	timestamp = {Mon, 25 Jul 2022 08:39:20 +0200},
	biburl = {https://dblp.org/rec/conf/iccsa/WilsonGGW22.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{wei2022ChainThoughtPrompting,
	file = {References/pdf/wei2022ChainThoughtPrompting.pdf},
	author = {Jason Wei and Xuezhi Wang and Dale Schuurmans and
                  Maarten Bosma and Brian Ichter and Fei Xia and Ed
                  H. Chi and Quoc V. Le and Denny Zhou},
	title = {Chain-of-Thought Prompting Elicits Reasoning in
                  Large Language Models},
	year = 2022,
	booktitle = {Advances in Neural Information Processing Systems
                  35: Annual Conference on Neural Information
                  Processing Systems 2022, NeurIPS 2022, New Orleans,
                  LA, USA, November 28 - December 9, 2022},
	url = {http://papers.nips.cc/paper\_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html},
	crossref = {DBLP:conf/nips/2022},
	timestamp = {Tue, 12 Nov 2024 16:50:49 +0100},
	biburl = {https://dblp.org/rec/conf/nips/Wei0SBIXCLZ22.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{wang2017ShortSurveyTaxonomy,
	file = {References/pdf/wang2017ShortSurveyTaxonomy.pdf},
	author = {Chengyu Wang and Xiaofeng He and Aoying Zhou},
	title = {A Short Survey on Taxonomy Learning from Text
                  Corpora: Issues, Resources and Recent Advances},
	year = 2017,
	booktitle = {Proceedings of the 2017 Conference on Empirical
                  Methods in Natural Language Processing, {EMNLP}
                  2017, Copenhagen, Denmark, September 9-11, 2017},
	pages = {1190-1203},
	doi = {10.18653/V1/D17-1123},
	url = {https://doi.org/10.18653/v1/d17-1123},
	crossref = {DBLP:conf/emnlp/2017},
	timestamp = {Fri, 06 Aug 2021 00:40:26 +0200},
	biburl = {https://dblp.org/rec/conf/emnlp/WangHZ17.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{wadhwa2023RevisitingRelationExtraction,
	file = {References/pdf/wadhwa2023RevisitingRelationExtraction.pdf},
	author = {Somin Wadhwa and Silvio Amir and Byron C. Wallace},
	title = {Revisiting Relation Extraction in the era of Large
                  Language Models},
	year = 2023,
	booktitle = {Proceedings of the 61st Annual Meeting of the
                  Association for Computational Linguistics (Volume 1:
                  Long Papers), {ACL} 2023, Toronto, Canada, July
                  9-14, 2023},
	pages = {15566-15589},
	doi = {10.18653/V1/2023.ACL-LONG.868},
	url = {https://doi.org/10.18653/v1/2023.acl-long.868},
	crossref = {DBLP:conf/acl/2023-1},
	timestamp = {Thu, 10 Aug 2023 12:36:01 +0200},
	biburl = {https://dblp.org/rec/conf/acl/WadhwaAW23.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{sun2024HeadTailHow,
	file = {References/pdf/sun2024HeadTailHow.pdf},
	author = {Kai Sun and Yifan Ethan Xu and Hanwen Zha and Yue
                  Liu and Xin Luna Dong},
	title = {Head-to-Tail: How Knowledgeable are Large Language
                  Models (LLMs)?  {A.K.A.} Will LLMs Replace Knowledge
                  Graphs?},
	year = 2024,
	booktitle = {Proceedings of the 2024 Conference of the North
                  American Chapter of the Association for
                  Computational Linguistics: Human Language
                  Technologies (Volume 1: Long Papers), {NAACL} 2024,
                  Mexico City, Mexico, June 16-21, 2024},
	pages = {311-325},
	doi = {10.18653/V1/2024.NAACL-LONG.18},
	url = {https://doi.org/10.18653/v1/2024.naacl-long.18},
	crossref = {DBLP:conf/naacl/2024},
	timestamp = {Thu, 29 Aug 2024 17:13:57 +0200},
	biburl = {https://dblp.org/rec/conf/naacl/SunXZLD24.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InCollection{suarezfigueroa2012NeonMethodologyOntology,
	file = {References/pdf/suarezfigueroa2012NeonMethodologyOntology.pdf},
	author = {Mari Carmen Su{\'{a}}rez{-}Figueroa and
                  Asunci{\'{o}}n G{\'{o}}mez{-}P{\'{e}}rez and Mariano
                  Fern{\'{a}}ndez{-}L{\'{o}}pez},
	title = {The NeOn Methodology for Ontology Engineering},
	year = 2012,
	booktitle = {Ontology Engineering in a Networked World},
	pages = {9-34},
	doi = {10.1007/978-3-642-24794-1\_2},
	url = {https://doi.org/10.1007/978-3-642-24794-1\_2},
	crossref = {DBLP:books/daglib/0028799},
	timestamp = {Wed, 14 Nov 2018 10:12:21 +0100},
	biburl = {https://dblp.org/rec/books/daglib/p/Suarez-FigueroaGF12.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{snijder2024AdvancingOntologyAlignment,
	file = {References/pdf/snijder2024AdvancingOntologyAlignment.pdf},
	author = {Lucas L. Snijder and Quirine T. S. Smit and Maaike
                  H. T. de Boer},
	title = {Advancing Ontology Alignment in the Labor Market:
                  Combining Large Language Models with Domain
                  Knowledge},
	year = 2024,
	booktitle = {Proceedings of the {AAAI} 2024 Spring Symposium
                  Series, Stanford, CA, USA, March 25-27, 2024},
	pages = {253-262},
	doi = {10.1609/AAAISS.V3I1.31208},
	url = {https://doi.org/10.1609/aaaiss.v3i1.31208},
	crossref = {DBLP:conf/aaaiss/2024},
	timestamp = {Mon, 03 Jun 2024 16:39:33 +0200},
	biburl = {https://dblp.org/rec/conf/aaaiss/SnijderSB24.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{roberts2020HowMuchKnowledge,
	file = {References/pdf/roberts2020HowMuchKnowledge.pdf},
	author = {Adam Roberts and Colin Raffel and Noam Shazeer},
	title = {How Much Knowledge Can You Pack Into the Parameters
                  of a Language Model?},
	year = 2020,
	booktitle = {Proceedings of the 2020 Conference on Empirical
                  Methods in Natural Language Processing, {EMNLP}
                  2020, Online, November 16-20, 2020},
	pages = {5418-5426},
	doi = {10.18653/V1/2020.EMNLP-MAIN.437},
	url = {https://doi.org/10.18653/v1/2020.emnlp-main.437},
	crossref = {DBLP:conf/emnlp/2020-1},
	timestamp = {Sun, 19 Jan 2025 13:09:51 +0100},
	biburl = {https://dblp.org/rec/conf/emnlp/RobertsRS20.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{renze2024EffectSamplingTemperature,
	file = {References/pdf/renze2024EffectSamplingTemperature.pdf},
	author = {Matthew Renze},
	title = {The Effect of Sampling Temperature on Problem
                  Solving in Large Language Models},
	year = 2024,
	booktitle = {Findings of the Association for Computational
                  Linguistics: {EMNLP} 2024, Miami, Florida, USA,
                  November 12-16, 2024},
	pages = {7346-7356},
	doi = {10.18653/V1/2024.FINDINGS-EMNLP.432},
	url = {https://doi.org/10.18653/v1/2024.findings-emnlp.432},
	crossref = {DBLP:conf/emnlp/2024f},
	timestamp = {Fri, 13 Jun 2025 08:28:39 +0200},
	biburl = {https://dblp.org/rec/conf/emnlp/Renze24.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{razeghi2022ImpactPretrainingTerm,
	file = {References/pdf/razeghi2022ImpactPretrainingTerm.pdf},
	author = {Yasaman Razeghi and Robert L. Logan IV and Matt
                  Gardner and Sameer Singh},
	title = {Impact of Pretraining Term Frequencies on Few-Shot
                  Numerical Reasoning},
	year = 2022,
	booktitle = {Findings of the Association for Computational
                  Linguistics: {EMNLP} 2022, Abu Dhabi, United Arab
                  Emirates, December 7-11, 2022},
	pages = {840-854},
	doi = {10.18653/V1/2022.FINDINGS-EMNLP.59},
	url = {https://doi.org/10.18653/v1/2022.findings-emnlp.59},
	crossref = {DBLP:conf/emnlp/2022f},
	timestamp = {Thu, 10 Aug 2023 12:35:31 +0200},
	biburl = {https://dblp.org/rec/conf/emnlp/RazeghiL0022.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{radford2021LearningTransferableVisual,
	file = {References/pdf/radford2021LearningTransferableVisual.pdf},
	author = {Alec Radford and Jong Wook Kim and Chris Hallacy and
                  Aditya Ramesh and Gabriel Goh and Sandhini Agarwal
                  and Girish Sastry and Amanda Askell and Pamela
                  Mishkin and Jack Clark and Gretchen Krueger and Ilya
                  Sutskever},
	title = {Learning Transferable Visual Models From Natural
                  Language Supervision},
	year = 2021,
	booktitle = {Proceedings of the 38th International Conference on
                  Machine Learning, {ICML} 2021, 18-24 July 2021,
                  Virtual Event},
	pages = {8748-8763},
	url = {http://proceedings.mlr.press/v139/radford21a.html},
	crossref = {DBLP:conf/icml/2021},
	timestamp = {Wed, 25 Aug 2021 17:11:17 +0200},
	biburl = {https://dblp.org/rec/conf/icml/RadfordKHRGASAM21.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{qiao2023ReasoningWithLanguage,
	file = {References/pdf/qiao2023ReasoningWithLanguage.pdf},
	author = {Shuofei Qiao and Yixin Ou and Ningyu Zhang and Xiang
                  Chen and Yunzhi Yao and Shumin Deng and Chuanqi Tan
                  and Fei Huang and Huajun Chen},
	title = {Reasoning with Language Model Prompting: {A} Survey},
	year = 2023,
	booktitle = {Proceedings of the 61st Annual Meeting of the
                  Association for Computational Linguistics (Volume 1:
                  Long Papers), {ACL} 2023, Toronto, Canada, July
                  9-14, 2023},
	pages = {5368-5393},
	doi = {10.18653/V1/2023.ACL-LONG.294},
	url = {https://doi.org/10.18653/v1/2023.acl-long.294},
	crossref = {DBLP:conf/acl/2023-1},
	timestamp = {Wed, 11 Jun 2025 16:18:28 +0200},
	biburl = {https://dblp.org/rec/conf/acl/QiaoO0CYDTHC23.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{petroni2019LanguageModelsAs,
	file = {References/pdf/petroni2019LanguageModelsAs.pdf},
	author = {Fabio Petroni and Tim Rockt{\"{a}}schel and
                  Sebastian Riedel and Patrick Lewis and Anton Bakhtin
                  and Yuxiang Wu and Alexander H. Miller},
	title = {Language Models as Knowledge Bases?},
	year = 2019,
	booktitle = {Proceedings of the 2019 Conference on Empirical
                  Methods in Natural Language Processing and the 9th
                  International Joint Conference on Natural Language
                  Processing, {EMNLP-IJCNLP} 2019, Hong Kong, China,
                  November 3-7, 2019},
	pages = {2463-2473},
	doi = {10.18653/V1/D19-1250},
	url = {https://doi.org/10.18653/v1/D19-1250},
	crossref = {DBLP:conf/emnlp/2019-1},
	timestamp = {Mon, 14 Apr 2025 22:18:59 +0200},
	biburl = {https://dblp.org/rec/conf/emnlp/PetroniRRLBWM19.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InCollection{petasis2011OntologyPopulationEnrichment,
	file = {References/pdf/petasis2011OntologyPopulationEnrichment.pdf},
	author = {Georgios Petasis and Vangelis Karkaletsis and
                  Georgios Paliouras and Anastasia Krithara and Elias
                  Zavitsanos},
	title = {Ontology Population and Enrichment: State of the
                  Art},
	year = 2011,
	booktitle = {Knowledge-Driven Multimedia Information Extraction
                  and Ontology Evolution - Bridging the Semantic Gap},
	pages = {134-166},
	doi = {10.1007/978-3-642-20795-2\_6},
	url = {https://doi.org/10.1007/978-3-642-20795-2\_6},
	crossref = {DBLP:conf/boemie/2011},
	timestamp = {Tue, 01 Apr 2025 19:06:01 +0200},
	biburl = {https://dblp.org/rec/conf/boemie/PetasisKPKZ11.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{nikankin2025ArithmeticWithoutAlgorithms,
	file = {References/pdf/nikankin2025ArithmeticWithoutAlgorithms.pdf},
	author = {Yaniv Nikankin and Anja Reusch and Aaron Mueller and
                  Yonatan Belinkov},
	title = {Arithmetic Without Algorithms: Language Models Solve
                  Math with a Bag of Heuristics},
	year = 2025,
	booktitle = {The Thirteenth International Conference on Learning
                  Representations, {ICLR} 2025, Singapore, April
                  24-28, 2025},
	url = {https://openreview.net/forum?id=O9YTt26r2P},
	crossref = {DBLP:conf/iclr/2025},
	timestamp = {Thu, 15 May 2025 17:19:06 +0200},
	biburl = {https://dblp.org/rec/conf/iclr/NikankinRMB25.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{mosbach2023FewShotFine,
	file = {References/pdf/mosbach2023FewShotFine.pdf},
	author = {Marius Mosbach and Tiago Pimentel and Shauli
                  Ravfogel and Dietrich Klakow and Yanai Elazar},
	title = {Few-shot Fine-tuning vs. In-context Learning: {A}
                  Fair Comparison and Evaluation},
	year = 2023,
	booktitle = {Findings of the Association for Computational
                  Linguistics: {ACL} 2023, Toronto, Canada, July 9-14,
                  2023},
	pages = {12284-12314},
	doi = {10.18653/V1/2023.FINDINGS-ACL.779},
	url = {https://doi.org/10.18653/v1/2023.findings-acl.779},
	crossref = {DBLP:conf/acl/2023f},
	timestamp = {Thu, 10 Aug 2023 12:35:46 +0200},
	biburl = {https://dblp.org/rec/conf/acl/MosbachPRKE23.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{mascardi2007ComparisonUpperOntologies,
	author = {Viviana Mascardi and Valentina Cord{\`{\i}} and
                  Paolo Rosso},
	title = {A Comparison of Upper Ontologies},
	year = 2007,
	booktitle = {{WOA} 2007: Dagli Oggetti agli Agenti. 8th
                  AI*IA/TABOO Joint Workshop "From Objects to Agents":
                  Agents and Industry: Technological Applications of
                  Software Agents, 24-25 September 2007, Genova,
                  Italy},
	pages = {55-64},
	url = {http://woa07.disi.unige.it/papers/mascardi.pdf},
	crossref = {DBLP:conf/woa/2007},
	timestamp = {Thu, 12 Mar 2020 11:37:41 +0100},
	biburl = {https://dblp.org/rec/conf/woa/MascardiCR07.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{mai2024DoLlmsReally,
	file = {References/pdf/mai2024DoLlmsReally.pdf},
	author = {Huu Tan Mai and Cuong Xuan Chu and Heiko Paulheim},
	title = {Do LLMs Really Adapt to Domains? An Ontology
                  Learning Perspective},
	year = 2024,
	booktitle = {The Semantic Web - {ISWC} 2024 - 23rd International
                  Semantic Web Conference, Baltimore, MD, USA,
                  November 11-15, 2024, Proceedings, Part {I}},
	pages = {126-143},
	doi = {10.1007/978-3-031-77844-5\_7},
	url = {https://doi.org/10.1007/978-3-031-77844-5\_7},
	crossref = {DBLP:conf/semweb/2024-1},
	timestamp = {Wed, 08 Jan 2025 21:12:57 +0100},
	biburl = {https://dblp.org/rec/conf/semweb/MaiCP24.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{liu2022FewShotParameter,
	file = {References/pdf/liu2022FewShotParameter.pdf},
	author = {Haokun Liu and Derek Tam and Mohammed Muqeeth and
                  Jay Mohta and Tenghao Huang and Mohit Bansal and
                  Colin Raffel},
	title = {Few-Shot Parameter-Efficient Fine-Tuning is Better
                  and Cheaper than In-Context Learning},
	year = 2022,
	booktitle = {Advances in Neural Information Processing Systems
                  35: Annual Conference on Neural Information
                  Processing Systems 2022, NeurIPS 2022, New Orleans,
                  LA, USA, November 28 - December 9, 2022},
	url = {http://papers.nips.cc/paper\_files/paper/2022/hash/0cde695b83bd186c1fd456302888454c-Abstract-Conference.html},
	crossref = {DBLP:conf/nips/2022},
	timestamp = {Mon, 08 Jan 2024 16:31:36 +0100},
	biburl = {https://dblp.org/rec/conf/nips/LiuTMMHBR22.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{lippolis2025OntologyGenerationUsing,
	file = {References/pdf/lippolis2025OntologyGenerationUsing.pdf},
	author = {Anna Sofia Lippolis and Mohammad Javad Saeedizade
                  and Robin Keskis{\"{a}}rkk{\"{a}} and Sara Zuppiroli
                  and Miguel Ceriani and Aldo Gangemi and Eva
                  Blomqvist and Andrea Giovanni Nuzzolese},
	title = {Ontology Generation Using Large Language Models},
	year = 2025,
	booktitle = {The Semantic Web - 22nd European Semantic Web
                  Conference, {ESWC} 2025, Portoroz, Slovenia, June
                  1-5, 2025, Proceedings, Part {I}},
	pages = {321-341},
	doi = {10.1007/978-3-031-94575-5\_18},
	url = {https://doi.org/10.1007/978-3-031-94575-5\_18},
	crossref = {DBLP:conf/esws/2025-1},
	timestamp = {Tue, 10 Jun 2025 17:38:39 +0200},
	biburl = {https://dblp.org/rec/conf/esws/LippolisSKZCGBN25.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{li2024RoleLongTail,
	file = {References/pdf/li2024RoleLongTail.pdf},
	author = {Dongyang Li and Junbing Yan and Taolin Zhang and
                  Chengyu Wang and Xiaofeng He and Longtao Huang and
                  Hui Xue and Jun Huang},
	title = {On the Role of Long-tail Knowledge in Retrieval
                  Augmented Large Language Models},
	year = 2024,
	booktitle = {Proceedings of the 62nd Annual Meeting of the
                  Association for Computational Linguistics, {ACL}
                  2024 - Short Papers, Bangkok, Thailand, August
                  11-16, 2024},
	pages = {120-126},
	doi = {10.18653/V1/2024.ACL-SHORT.12},
	url = {https://doi.org/10.18653/v1/2024.acl-short.12},
	crossref = {DBLP:conf/acl/2024short},
	timestamp = {Fri, 13 Jun 2025 08:28:05 +0200},
	biburl = {https://dblp.org/rec/conf/acl/LiYZWHHXH24.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{lewis2020RetrievalAugmentedGeneration,
	file = {References/pdf/lewis2020RetrievalAugmentedGeneration.pdf},
	author = {Patrick Lewis and Ethan Perez and Aleksandra Piktus
                  and Fabio Petroni and Vladimir Karpukhin and Naman
                  Goyal and Heinrich K{\"{u}}ttler and Mike Lewis and
                  Wen{-}tau Yih and Tim Rockt{\"{a}}schel and
                  Sebastian Riedel and Douwe Kiela},
	title = {Retrieval-Augmented Generation for
                  Knowledge-Intensive {NLP} Tasks},
	year = 2020,
	booktitle = {Advances in Neural Information Processing Systems
                  33: Annual Conference on Neural Information
                  Processing Systems 2020, NeurIPS 2020, December
                  6-12, 2020, virtual},
	url = {https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html},
	crossref = {DBLP:conf/nips/2020},
	timestamp = {Mon, 14 Apr 2025 22:19:00 +0200},
	biburl = {https://dblp.org/rec/conf/nips/LewisPPPKGKLYR020.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{kandpal2023LargeLanguageModels,
	file = {References/pdf/kandpal2023LargeLanguageModels.pdf},
	author = {Nikhil Kandpal and Haikang Deng and Adam Roberts and
                  Eric Wallace and Colin Raffel},
	title = {Large Language Models Struggle to Learn Long-Tail
                  Knowledge},
	year = 2023,
	booktitle = {International Conference on Machine Learning, {ICML}
                  2023, 23-29 July 2023, Honolulu, Hawaii, {USA}},
	pages = {15696-15707},
	url = {https://proceedings.mlr.press/v202/kandpal23a.html},
	crossref = {DBLP:conf/icml/2023},
	timestamp = {Mon, 28 Aug 2023 17:23:08 +0200},
	biburl = {https://dblp.org/rec/conf/icml/KandpalDRWR23.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{jain2022DistillingHypernymyRelations,
	file = {References/pdf/jain2022DistillingHypernymyRelations.pdf},
	author = {Devansh Jain and Luis Espinosa Anke},
	title = {Distilling Hypernymy Relations from Language Models:
                  On the Effectiveness of Zero-Shot Taxonomy
                  Induction},
	year = 2022,
	booktitle = {Proceedings of the 11th Joint Conference on Lexical
                  and Computational Semantics, *SEM@NAACL-HLT 2022,
                  Seattle, WA, USA, July 14-15, 2022},
	pages = {151-156},
	doi = {10.18653/V1/2022.STARSEM-1.13},
	url = {https://doi.org/10.18653/v1/2022.starsem-1.13},
	crossref = {DBLP:conf/starsem/2022},
	timestamp = {Thu, 22 Aug 2024 07:28:05 +0200},
	biburl = {https://dblp.org/rec/conf/starsem/JainA22.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{hendrycks2021MeasuringMassiveMultitask,
	file = {References/pdf/hendrycks2021MeasuringMassiveMultitask.pdf},
	author = {Dan Hendrycks and Collin Burns and Steven Basart and
                  Andy Zou and Mantas Mazeika and Dawn Song and Jacob
                  Steinhardt},
	title = {Measuring Massive Multitask Language Understanding},
	year = 2021,
	booktitle = {9th International Conference on Learning
                  Representations, {ICLR} 2021, Virtual Event,
                  Austria, May 3-7, 2021},
	url = {https://openreview.net/forum?id=d7KBjmI3GmQ},
	crossref = {DBLP:conf/iclr/2021},
	timestamp = {Wed, 23 Jun 2021 17:36:39 +0200},
	biburl = {https://dblp.org/rec/conf/iclr/HendrycksBBZMSS21.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{he2022BertmapBertBased,
	file = {References/pdf/he2022BertmapBertBased.pdf},
	author = {Yuan He and Jiaoyan Chen and Denvar Antonyrajah and
                  Ian Horrocks},
	title = {BERTMap: {A} BERT-Based Ontology Alignment System},
	year = 2022,
	booktitle = {Thirty-Sixth {AAAI} Conference on Artificial
                  Intelligence, {AAAI} 2022, Thirty-Fourth Conference
                  on Innovative Applications of Artificial
                  Intelligence, {IAAI} 2022, The Twelveth Symposium on
                  Educational Advances in Artificial Intelligence,
                  {EAAI} 2022 Virtual Event, February 22 - March 1,
                  2022},
	pages = {5684-5691},
	doi = {10.1609/AAAI.V36I5.20510},
	url = {https://doi.org/10.1609/aaai.v36i5.20510},
	crossref = {DBLP:conf/aaai/2022},
	timestamp = {Mon, 03 Jun 2024 15:23:13 +0200},
	biburl = {https://dblp.org/rec/conf/aaai/0008CA022.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{hao2023BertnetHarvestingKnowledge,
	file = {References/pdf/hao2023BertnetHarvestingKnowledge.pdf},
	author = {Shibo Hao and Bowen Tan and Kaiwen Tang and Bin Ni
                  and Xiyan Shao and Hengzhe Zhang and Eric P. Xing
                  and Zhiting Hu},
	title = {BertNet: Harvesting Knowledge Graphs with Arbitrary
                  Relations from Pretrained Language Models},
	year = 2023,
	booktitle = {Findings of the Association for Computational
                  Linguistics: {ACL} 2023, Toronto, Canada, July 9-14,
                  2023},
	pages = {5000-5015},
	doi = {10.18653/V1/2023.FINDINGS-ACL.309},
	url = {https://doi.org/10.18653/v1/2023.findings-acl.309},
	crossref = {DBLP:conf/acl/2023f},
	timestamp = {Thu, 10 Aug 2023 12:35:49 +0200},
	biburl = {https://dblp.org/rec/conf/acl/HaoTTNSZXH23.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{giglou2024Llms4omMatchingOntologies,
	file = {References/pdf/giglou2024Llms4omMatchingOntologies.pdf},
	author = {Hamed Babaei Giglou and Jennifer D'Souza and Felix
                  Engel and S{\"{o}}ren Auer},
	title = {LLMs4OM: Matching Ontologies with Large Language
                  Models},
	year = 2024,
	booktitle = {The Semantic Web: {ESWC} 2024 Satellite Events -
                  Hersonissos, Crete, Greece, May 26-30, 2024,
                  Proceedings, Part {I}},
	pages = {25-35},
	doi = {10.1007/978-3-031-78952-6\_3},
	url = {https://doi.org/10.1007/978-3-031-78952-6\_3},
	crossref = {DBLP:conf/esws/2024s-1},
	timestamp = {Wed, 19 Feb 2025 12:54:38 +0100},
	biburl = {https://dblp.org/rec/conf/esws/GiglouDEA24.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{giglou2024Llms4ol2024Overview,
	file = {References/pdf/giglou2024Llms4ol2024Overview.pdf},
	author = {Hamed Babaei Giglou and Jennifer D'Souza and
                  S{\"{o}}ren Auer},
	title = {LLMs4OL 2024 Overview: The 1st Large Language Models
                  for Ontology Learning Challenge},
	year = 2024,
	booktitle = {LLMs4OL 2024: The 1st Large Language Models for
                  Ontology Learning Challenge at the 23rd ISWC,
                  Co-located with the 23rd International Semantic Web
                  Conference {(ISWC} 2024), Baltimore, Maryland, USA,
                  November 11-15, 2024},
	pages = {3-16},
	doi = {10.52825/OCP.V4I.2473},
	url = {https://doi.org/10.52825/ocp.v4i.2473},
	crossref = {DBLP:conf/llms4ol/2024},
	timestamp = {Thu, 09 Oct 2025 17:16:30 +0200},
	biburl = {https://dblp.org/rec/conf/llms4ol/Giglou0A24a.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{giglou2023Llms4olLargeLanguage,
	file = {References/pdf/giglou2023Llms4olLargeLanguage.pdf},
	author = {Hamed Babaei Giglou and Jennifer D'Souza and
                  S{\"{o}}ren Auer},
	title = {LLMs4OL: Large Language Models for Ontology
                  Learning},
	year = 2023,
	booktitle = {The Semantic Web - {ISWC} 2023 - 22nd International
                  Semantic Web Conference, Athens, Greece, November
                  6-10, 2023, Proceedings, Part {I}},
	pages = {408-427},
	doi = {10.1007/978-3-031-47240-4\_22},
	url = {https://doi.org/10.1007/978-3-031-47240-4\_22},
	crossref = {DBLP:conf/semweb/2023-1},
	timestamp = {Sun, 19 Jan 2025 13:17:22 +0100},
	biburl = {https://dblp.org/rec/conf/semweb/GiglouDA23.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{garijo2024LlmsOntologyEngineering,
	file = {References/pdf/garijo2024LlmsOntologyEngineering.pdf},
	author = {Daniel Garijo and Mar{\'{\i}}a
                  Poveda{-}Villal{\'{o}}n and Elvira
                  Amador{-}Dom{\'{\i}}nguez and Ziyuan Wang and
                  Ra{\'{u}}l Garc{\'{\i}}a{-}Castro and {\'{O}}scar
                  Corcho},
	title = {LLMs for Ontology Engineering: {A} landscape of
                  Tasks and Benchmarking challenges},
	year = 2024,
	booktitle = {Proceedings of the Special Session on Harmonising
                  Generative {AI} and Semantic Web Technologies
                  {(HGAIS} 2024) co-located with the 23rd
                  International Semantic Web Conference {(ISWC} 2024),
                  Baltimore, Maryland, November 13, 2024},
	url = {https://ceur-ws.org/Vol-3953/364.pdf},
	crossref = {DBLP:conf/semweb/2024hgais},
	timestamp = {Thu, 12 Jun 2025 16:38:15 +0200},
	biburl = {https://dblp.org/rec/conf/semweb/GarijoPAWGC24.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{fathallah2024Llms4lifeLargeLanguage,
	file = {References/pdf/fathallah2024Llms4lifeLargeLanguage.pdf},
	author = {Nadeen Fathallah and Steffen Staab and Alsayed
                  Algergawy},
	title = {LLMs4Life: Large Language Models for Ontology
                  Learning in Life Sciences},
	year = 2024,
	booktitle = {Joint Proceedings of Posters, Demos, Workshops, and
                  Tutorials of the 24th International Conference on
                  Knowledge Engineering and Knowledge Management
                  {(EKAW-PDWT} 2024) co-located with 24th
                  International Conference on Knowledge Engineering
                  and Knowledge Management {(EKAW} 2024), Amsterdam,
                  Netherlands, November 26-28, 2024},
	url = {https://ceur-ws.org/Vol-3967/ELMKE\_2024\_paper\_3.pdf},
	crossref = {DBLP:conf/ekaw/2024c},
	timestamp = {Thu, 12 Jun 2025 16:38:15 +0200},
	biburl = {https://dblp.org/rec/conf/ekaw/FathallahSA24.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{evans2003FrameworkNamedEntity,
	file = {References/pdf/evans2003FrameworkNamedEntity.pdf},
	author = {Richard J. Evans},
	title = {A framework for named entity recognition in the open
                  domain},
	year = 2003,
	booktitle = {Recent Advances in Natural Language Processing III,
                  Selected Papers from {RANLP} 2003, Borovets,
                  Bulgaria},
	pages = {267-276},
	crossref = {DBLP:conf/ranlp/2003},
	timestamp = {Tue, 22 Feb 2005 13:47:43 +0100},
	biburl = {https://dblp.org/rec/conf/ranlp/Evans03.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{etzioni2004WebScaleInformation,
	file = {References/pdf/etzioni2004WebScaleInformation.pdf},
	author = {Oren Etzioni and Michael J. Cafarella and Doug
                  Downey and Stanley Kok and Ana{-}Maria Popescu and
                  Tal Shaked and Stephen Soderland and Daniel S. Weld
                  and Alexander Yates},
	title = {Web-scale information extraction in knowitall:
                  (preliminary results)},
	year = 2004,
	booktitle = {Proceedings of the 13th international conference on
                  World Wide Web, {WWW} 2004, New York, NY, USA, May
                  17-20, 2004},
	pages = {100-110},
	doi = {10.1145/988672.988687},
	url = {https://doi.org/10.1145/988672.988687},
	crossref = {DBLP:conf/www/2004},
	timestamp = {Tue, 06 Nov 2018 16:57:09 +0100},
	biburl = {https://dblp.org/rec/conf/www/EtzioniCDKPSSWY04.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{devlin2019BertPreTraining,
	file = {References/pdf/devlin2019BertPreTraining.pdf},
	author = {Jacob Devlin and Ming{-}Wei Chang and Kenton Lee and
                  Kristina Toutanova},
	title = {{BERT:} Pre-training of Deep Bidirectional
                  Transformers for Language Understanding},
	year = 2019,
	booktitle = {Proceedings of the 2019 Conference of the North
                  American Chapter of the Association for
                  Computational Linguistics: Human Language
                  Technologies, {NAACL-HLT} 2019, Minneapolis, MN,
                  USA, June 2-7, 2019, Volume 1 (Long and Short
                  Papers)},
	pages = {4171-4186},
	doi = {10.18653/V1/N19-1423},
	url = {https://doi.org/10.18653/v1/n19-1423},
	crossref = {DBLP:conf/naacl/2019-1},
	timestamp = {Mon, 26 Sep 2022 12:21:55 +0200},
	biburl = {https://dblp.org/rec/conf/naacl/DevlinCLT19.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{cocos2018ComparingConstraintsTaxonomic,
	file = {References/pdf/cocos2018ComparingConstraintsTaxonomic.pdf},
	author = {Anne Cocos and Marianna Apidianaki and Chris
                  Callison{-}Burch},
	title = {Comparing Constraints for Taxonomic Organization},
	year = 2018,
	booktitle = {Proceedings of the 2018 Conference of the North
                  American Chapter of the Association for
                  Computational Linguistics: Human Language
                  Technologies, {NAACL-HLT} 2018, New Orleans,
                  Louisiana, USA, June 1-6, 2018, Volume 1 (Long
                  Papers)},
	pages = {323-333},
	doi = {10.18653/V1/N18-1030},
	url = {https://doi.org/10.18653/v1/n18-1030},
	crossref = {DBLP:conf/naacl/2018-1},
	timestamp = {Fri, 06 Aug 2021 00:41:32 +0200},
	biburl = {https://dblp.org/rec/conf/naacl/CocosAC18.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{chen2023PromptingOrFine,
	file = {References/pdf/chen2023PromptingOrFine.pdf},
	author = {Boqi Chen and Fandi Yi and D{\'{a}}niel Varr{\'{o}}},
	title = {Prompting or Fine-tuning? {A} Comparative Study of
                  Large Language Models for Taxonomy Construction},
	year = 2023,
	booktitle = {{ACM/IEEE} International Conference on Model Driven
                  Engineering Languages and Systems, {MODELS} 2023
                  Companion, V{\"{a}}ster{\aa}s, Sweden, October 1-6,
                  2023},
	pages = {588-596},
	doi = {10.1109/MODELS-C59198.2023.00097},
	url = {https://doi.org/10.1109/MODELS-C59198.2023.00097},
	crossref = {DBLP:conf/models/2023c},
	timestamp = {Fri, 05 Jan 2024 16:35:45 +0100},
	biburl = {https://dblp.org/rec/conf/models/ChenYV23.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{chen2022EnhancingCrossLingual,
	file = {References/pdf/chen2022EnhancingCrossLingual.pdf},
	author = {Luming Chen and Yifan Qi and Aiping Wu and Lizong
                  Deng and Taijiao Jiang},
	title = {Enhancing Cross-lingual Medical Concept Alignment by
                  Leveraging Synonyms and Translations of the Unified
                  Medical Language System},
	year = 2022,
	booktitle = {24th {IEEE} Int Conf on High Performance Computing
                  {\&} Communications; 8th Int Conf on Data Science
                  {\&} Systems; 20th Int Conf on Smart City; 8th Int
                  Conf on Dependability in Sensor, Cloud {\&} Big Data
                  Systems {\&} Application,
                  HPCC/DSS/SmartCity/DependSys 2022, Hainan, China,
                  December 18-20, 2022},
	pages = {2078-2083},
	doi = {10.1109/HPCC-DSS-SMARTCITY-DEPENDSYS57074.2022.00309},
	url = {https://doi.org/10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00309},
	crossref = {DBLP:conf/hpcc/2022},
	timestamp = {Thu, 06 Apr 2023 11:34:02 +0200},
	biburl = {https://dblp.org/rec/conf/hpcc/ChenQWDJ22.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{chen2021ConstructingTaxonomiesPretrained,
	file = {References/pdf/chen2021ConstructingTaxonomiesPretrained.pdf},
	author = {Catherine Chen and Kevin Lin and Dan Klein},
	title = {Constructing Taxonomies from Pretrained Language
                  Models},
	year = 2021,
	booktitle = {Proceedings of the 2021 Conference of the North
                  American Chapter of the Association for
                  Computational Linguistics: Human Language
                  Technologies, {NAACL-HLT} 2021, Online, June 6-11,
                  2021},
	pages = {4687-4700},
	doi = {10.18653/V1/2021.NAACL-MAIN.373},
	url = {https://doi.org/10.18653/v1/2021.naacl-main.373},
	crossref = {DBLP:conf/naacl/2021},
	timestamp = {Mon, 19 May 2025 23:15:41 +0200},
	biburl = {https://dblp.org/rec/conf/naacl/ChenLK21.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{cavalleri2024InitialAchievementsIn,
	file = {References/pdf/cavalleri2024InitialAchievementsIn.pdf},
	author = {Emanuele Cavalleri and Mauricio Soto Gomez and Ali
                  Pashaeibarough and Dario Malchiodi and J. Harry
                  Caufield and Justin T. Reese and Christopher
                  J. Mungall and Peter N. Robinson and Elena Casiraghi
                  and Giorgio Valentini and Marco Mesiti},
	title = {Initial achievements in relation extraction from
                  RNA-focused scientific papers},
	year = 2024,
	booktitle = {Proceedings of the 32nd Symposium of Advanced
                  Database Systems, Villasimius, Italy, June 23rd to
                  26th, 2024},
	pages = {61-69},
	url = {https://ceur-ws.org/Vol-3741/paper53.pdf},
	crossref = {DBLP:conf/sebd/2024},
	timestamp = {Wed, 21 Aug 2024 22:46:00 +0200},
	biburl = {https://dblp.org/rec/conf/sebd/CavalleriGPMCRM24.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{carlini2023QuantifyingMemorizationAcross,
	file = {References/pdf/carlini2023QuantifyingMemorizationAcross.pdf},
	author = {Nicholas Carlini and Daphne Ippolito and Matthew
                  Jagielski and Katherine Lee and Florian Tram{\`{e}}r
                  and Chiyuan Zhang},
	title = {Quantifying Memorization Across Neural Language
                  Models},
	year = 2023,
	booktitle = {The Eleventh International Conference on Learning
                  Representations, {ICLR} 2023, Kigali, Rwanda, May
                  1-5, 2023},
	url = {https://openreview.net/forum?id=TatRHT\_1cK},
	crossref = {DBLP:conf/iclr/2023},
	timestamp = {Wed, 24 Jul 2024 16:50:33 +0200},
	biburl = {https://dblp.org/rec/conf/iclr/CarliniIJLTZ23.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{capshaw2024ContextualizingEntityRepresentations,
	file = {References/pdf/capshaw2024ContextualizingEntityRepresentations.pdf},
	author = {Riley Capshaw and Eva Blomqvist},
	title = {Contextualizing Entity Representations for Zero-Shot
                  Relation Extraction with Masked Language Models},
	year = 2024,
	booktitle = {Knowledge Engineering and Knowledge Management -
                  24th International Conference, {EKAW} 2024,
                  Amsterdam, The Netherlands, November 26-28, 2024,
                  Proceedings},
	pages = {399-415},
	doi = {10.1007/978-3-031-77792-9\_24},
	url = {https://doi.org/10.1007/978-3-031-77792-9\_24},
	crossref = {DBLP:conf/ekaw/2024},
	timestamp = {Sun, 19 Jan 2025 13:18:21 +0100},
	biburl = {https://dblp.org/rec/conf/ekaw/CapshawB24.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{bakker2024TextKnowledgeGraph,
	file = {References/pdf/bakker2024TextKnowledgeGraph.pdf},
	author = {Roos M. Bakker and Daan L. Di Scala},
	title = {From Text to Knowledge Graph: Comparing Relation
                  Extraction Methods in a Practical Context},
	year = 2024,
	booktitle = {Joint Proceedings of the {ESWC} 2024 Workshops and
                  Tutorials co-located with 21th European Semantic Web
                  Conference {(ESWC} 2024), Hersonissos, Greece, May
                  26-27, 2024},
	url = {https://ceur-ws.org/Vol-3749/genesy-04.pdf},
	crossref = {DBLP:conf/esws/2024w},
	timestamp = {Fri, 18 Oct 2024 20:55:30 +0200},
	biburl = {https://dblp.org/rec/conf/esws/BakkerS24.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{bakker2024OntologyLearningText,
	file = {References/pdf/bakker2024OntologyLearningText.pdf},
	author = {Roos M. Bakker and Daan L. Di Scala and Maaike
                  H. T. de Boer},
	title = {Ontology Learning from Text: an Analysis on {LLM}
                  Performance},
	year = 2024,
	booktitle = {Proceedings of the 3rd International Workshop on
                  Natural Language Processing for Knowledge Graph
                  Creation co-located with 20th International
                  Conference on Semantic Systems (SEMANTiCS 2024),
                  Amsterdam, The Netherlands, September 17, 2024},
	pages = {70-87},
	url = {https://ceur-ws.org/Vol-3874/paper5.pdf},
	crossref = {DBLP:conf/nlp4kgc/2024},
	timestamp = {Mon, 06 Jan 2025 16:59:41 +0100},
	biburl = {https://dblp.org/rec/conf/nlp4kgc/BakkerSB24.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{auer2007DbpediaNucleusWeb,
	file = {References/pdf/auer2007DbpediaNucleusWeb.pdf},
	author = {S{\"{o}}ren Auer and Christian Bizer and Georgi
                  Kobilarov and Jens Lehmann and Richard Cyganiak and
                  Zachary G. Ives},
	title = {DBpedia: {A} Nucleus for a Web of Open Data},
	year = 2007,
	booktitle = {The Semantic Web, 6th International Semantic Web
                  Conference, 2nd Asian Semantic Web Conference,
                  {ISWC} 2007 + {ASWC} 2007, Busan, Korea, November
                  11-15, 2007},
	pages = {722-735},
	doi = {10.1007/978-3-540-76298-0\_52},
	url = {https://doi.org/10.1007/978-3-540-76298-0\_52},
	crossref = {DBLP:conf/semweb/2007},
	timestamp = {Mon, 03 Mar 2025 21:21:20 +0100},
	biburl = {https://dblp.org/rec/conf/semweb/AuerBKLCI07.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{amardeilh2005DocumentAnnotationOntology,
	file = {References/pdf/amardeilh2005DocumentAnnotationOntology.pdf},
	author = {Florence Amardeilh and Philippe Laublet and
                  Jean{-}Luc Minel},
	title = {Document annotation and ontology population from
                  linguistic extractions},
	year = 2005,
	booktitle = {Proceedings of the 3rd International Conference on
                  Knowledge Capture {(K-CAP} 2005), October 2-5, 2005,
                  Banff, Alberta, Canada},
	pages = {161-168},
	doi = {10.1145/1088622.1088651},
	url = {https://doi.org/10.1145/1088622.1088651},
	crossref = {DBLP:conf/kcap/2005},
	timestamp = {Tue, 06 Nov 2018 16:58:28 +0100},
	biburl = {https://dblp.org/rec/conf/kcap/AmardeilhLM05.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{alt2019ImprovingRelationExtraction,
	file = {References/pdf/alt2019ImprovingRelationExtraction.pdf},
	author = {Christoph Alt and Marc H{\"{u}}bner and Leonhard
                  Hennig},
	title = {Improving Relation Extraction by Pre-trained
                  Language Representations},
	year = 2019,
	booktitle = {1st Conference on Automated Knowledge Base
                  Construction, {AKBC} 2019, Amherst, MA, USA, May
                  20-22, 2019},
	doi = {10.24432/C5KW2W},
	url = {https://doi.org/10.24432/C5KW2W},
	crossref = {DBLP:conf/akbc/2019},
	timestamp = {Fri, 15 May 2020 16:10:48 +0200},
	biburl = {https://dblp.org/rec/conf/akbc/AltHH19.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{abdelmageed2023BiodivbertPreTrained,
	file = {References/pdf/abdelmageed2023BiodivbertPreTrained.pdf},
	title = {{BiodivBERT}: a {Pre}-{Trained} {Language} {Model} for the {Biodiversity} {Domain}},
	volume = {3415},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165793172&partnerID=40&md5=8cca4477cb76fca65e4b133871920cbf},
	abstract = {Information Extraction in the Life Sciences is getting increasing attention due to the constantly growing amount of data and text. The advancements of deep learning models further accelerate this development. However, applying these models to domain-specific data is crucial as applied domains often require different entity type extractions than general ones. This paper introduces BiodivBERT, the first pre-trained language model for the biodiversity domain. We constructed two pre-training corpora (abstracts and abstracts + full text) based on a keyword search strategy from two leading publishers in the Life Sciences. In addition, we fine-tuned BiodivBERT on two downstream tasks, i.e., Named Entity Recognition (NER) and Relation Extraction (RE), using various state-of-the-art benchmarks. The results show that BiodivBERT outperforms the state-of-the-art approaches. Moreover, we discuss a potential application of BiodivBERT for ontology auto-population. We publicly release data and code for both pre-training and fine-tuning. © 2023 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Abdelmageed, Nora and Löffler, Felicitas and König-Ries, Birgitta},
	year = {2023},
	note = {Section: 0},
	keywords = {Language model, Biodiversity, BERT, Deep learning, Search engines, Pre-training, Computational linguistics, Abstracting, Domain specific, Learning models, Fine tuning, Life-sciences, Entity-types, Training corpus, Keyword search},
	pages = {62 -- 71},
	annote = {Type: Conference paper}
}

@article{abolhasani2025OntokgenGenuineOntology,
	file = {References/pdf/abolhasani2025OntokgenGenuineOntology.pdf},
	title = {{OntoKGen}: {A} {Genuine} {Ontology} and {Knowledge} {Graph} {Generator} {Using} {Large} {Language} {Model}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002271575&doi=10.1109%2FRAMS48127.2025.10935139&partnerID=40&md5=a1dda94eab8edc38426e8bfe96221f84},
	doi = {10.1109/RAMS48127.2025.10935139},
	abstract = {Extracting relevant and structured knowledge from large, complex technical documents within the Reliability and Maintainability (RAM) domain is labor-intensive and prone to errors. Our work addresses this challenge by presenting OntoKGen, a Genuine pipeline for Ontology extraction and Knowledge Graph (KG) generation. OntoKGen leverages Large Language Models (LLMs) through an interactive user interface guided by our adaptive iterative Chain of Thought (CoT) algorithm to ensure that the ontology extraction process and, thus, KG generation align with user-specific requirements. Although KG generation follows a clear, structured path based on the confirmed ontology, there is no universally correct ontology as it is inherently based on the user's preferences. OntoKGen recommends an ontology grounded in best practices, minimizing user effort and providing valuable insights that may have been overlooked, all while giving the user complete control over the final ontology. Having generated the KG based on the confirmed ontology, OntoKGen enables seamless integration into schemeless, non-relational databases like Neo4j. This integration allows for flexible storage and retrieval of knowledge from diverse, unstructured sources, facilitating advanced querying, analysis, and decision-making. Moreover, the generated KG serves as a robust foundation for future integration into Retrieval-Augmented Generation (RAG) systems, offering enhanced capabilities for developing domain-specific intelligent applications.},
	journal = {2025 Annual Reliability and Maintainability Symposium (RAMS)},
	author = {Abolhasani, Mohammad Sadeq and Pan, Rong},
	month = jan,
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Large language models, Retrieval augmented generation, Prompt Engineering, Large Language Model, Neo4j, Prompt engineering, Ontology Extraction, Pipelines, Generators, Neo4J, Ontology and Knowledge Graph Generator, Random access memory, Reliability engineering, User interfaces, Structured Query Language, Ontology's, Ontology graphs, Query languages, Relational database systems, Graph generation, Ontology and knowledge graph generator},
	pages = {1--6},
	annote = {ISSN: 2577-0993}
}

@article{aggarwal2024IdentifyingSemanticRelationships,
	file = {References/pdf/aggarwal2024IdentifyingSemanticRelationships.pdf},
	title = {Identifying {Semantic} {Relationships} {Between} {Research} {Topics} {Using} {Large} {Language} {Models} in a {Zero}-{Shot} {Learning} {Setting}},
	volume = {3780},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207042155&partnerID=40&md5=595559c5582ddfa5a9fb95c64b924450},
	abstract = {Knowledge Organization Systems (KOS), such as ontologies, taxonomies, and thesauri, play a crucial role in organising scientific knowledge. They help scientists navigate the vast landscape of research literature and are essential for building intelligent systems such as smart search engines, recommendation systems, conversational agents, and advanced analytics tools. However, the manual creation of these KOSs is costly, time-consuming, and often leads to outdated and overly broad representations. As a result, researchers have been exploring automated or semi-automated methods for generating ontologies of research topics. This paper analyses the use of large language models (LLMs) to identify semantic relationships between research topics. We specifically focus on six open and lightweight LLMs (up to 10.7 billion parameters) and use two zero-shot reasoning strategies to identify four types of relationships: broader, narrower, same-as, and other. Our preliminary analysis indicates that Dolphin2.1-OpenOrca-7B performs strongly in this task, achieving a 0.853 F1-score against a gold standard of 1,000 relationships derived from the IEEE Thesaurus. These promising results bring us one step closer to the next generation of tools for automatically curating KOSs, ultimately making the scientific literature easier to explore. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Aggarwal, Tanay and Salatino, Angelo Antonio and Osborne, Francesco and Motta, Enrico},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Semantics, Taxonomies, Ontology generation, Semantic relationships, Federated learning, Recommender systems, Latent semantic analysis, Zero-shot learning, Adversarial machine learning, Ontology's, Contrastive Learning, Knowledge organization system (KOS), Scientific knowledge, Scientific knowledge graph, Research topics, Scholarly knowledge},
	annote = {Type: Conference paper}
}

@article{agrawal2024BoostingEntityRecognition,
	file = {References/pdf/agrawal2024BoostingEntityRecognition.pdf},
	series = {{CIKM} '24},
	title = {Boosting {Entity} {Recognition} by leveraging {Cross}-task {Domain} {Models} for {Weak} {Supervision}},
	url = {https://doi.org/10.1145/3627673.3680009},
	doi = {10.1145/3627673.3680009},
	abstract = {Entity Recognition (ER) is a common natural language processing task encountered in a number of real-world applications. For common domains and named entities such as places and organisations, there exists sufficient high quality annotated data and foundational models such as T5 and GPT-3.5 also provide highly accurate predictions. However, for niche domains such as e-commerce and medicine with specialized entity types, there is a paucity of labeled data since manual labeling of tokens is often time-consuming and expensive, which makes entity recognition challenging for such domains. Recent works such as NEEDLE [48] propose hybrid solutions to efficiently combine a small amount of strongly labeled (human-annotated) with a large amount of weakly labeled (distant supervision) data to yield superior performance relative to supervised training. The extensive noise in the weakly labeled data, however, remains a challenge. In this paper, we propose WeSDoM (Weak Supervision with Domain Models), which leverages pretrained encoder models from the same domain but different tasks to create domain ontologies that can enable the creation of less noisy weakly labeled data. Experiments on internal e-commerce and public biomedical NER datasets demonstrate that WeSDoM outperforms existing SOTA baselines by a significant margin. We achieve new SOTA F1 scores on two popular Biomedical NER datasets, BC5CDR-chem 94.27, BC5CDR-disease 91.23.},
	journal = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
	author = {Agrawal, Sanjay and Merugu, Srujana and Sembium, Vivek},
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {ontologies, entity recognition, weak supervision, cross-task domain encoder},
	pages = {4324--4331},
	annote = {event-place: Boise, ID, USA}
}

@article{alharbi2024ExperimentInRetrofitting,
	file = {References/pdf/alharbi2024ExperimentInRetrofitting.pdf},
	series = {{SAC} '24},
	title = {An {Experiment} in {Retrofitting} {Competency} {Questions} for {Existing} {Ontologies}},
	url = {https://doi.org/10.1145/3605098.3636053},
	doi = {10.1145/3605098.3636053},
	abstract = {Competency Questions (CQs) are a form of ontology functional requirements expressed as natural language questions. Inspecting CQs together with the axioms in an ontology provides critical insights into the intended scope and applicability of the ontology. CQs also underpin a number of tasks in the development of ontologies e.g. ontology reuse, ontology testing, requirement specification, and the definition of patterns that implement such requirements. Although CQs are integral to the majority of ontology engineering methodologies, the practice of publishing CQs alongside the ontological artefacts is not widely observed by the community.In this context, we present an experiment in retrofitting CQs from existing ontologies. We propose RETROFIT-CQs, a method to extract candidate CQs directly from ontologies using Generative AI. In the paper we present the pipeline that facilitates the extraction of CQs by leveraging Large Language Models (LLMs) and we discuss its application to a number of existing ontologies.},
	journal = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
	author = {Alharbi, Reham and Tamma, Valentina and Grasso, Floriana and Payne, Terry},
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, large language models, Ontology reuse, Competency question, ontology engineering, Computational linguistics, competency questions, Ontology's, Natural language processing systems, Functional requirement, Natural language questions, Retrofitting, Testing requirements, Requirements specifications},
	pages = {1650--1658},
	annote = {event-place: Avila, Spain}
}

@article{alharbi2025RoleGenerativeAi,
	file = {References/pdf/alharbi2025RoleGenerativeAi.pdf},
	title = {The {Role} of {Generative} {AI} in {Competency} {Question} {Retrofitting}},
	volume = {15344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218447447&doi=10.1007%2F978-3-031-78952-6_1&partnerID=40&md5=de488f84c86cb908b9bf333e648ed84e},
	doi = {10.1007/978-3-031-78952-6_1},
	abstract = {Competency Questions (CQs) are essential in ontology engineering; they express an ontology’s functional requirements as natural language questions, offer crucial insights into an ontology’s scope and are pivotal for various tasks, e.g. ontology reuse, testing, requirement specification, and pattern definition. Despite their importance, the practice of publishing CQs alongside ontological artefacts is not commonly adopted. We propose an approach based on Generative AI, specifically Large Language Models (LLMs) for retrofitting CQs from existing ontologies and we study how the control parameters in two LLMs (i.e. gpt-3.5-turbo and gpt-4) affect their performance and investigate the interplay between prompts and configuration for retrofitting viable CQs. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Alharbi, Reham and Tamma, Valentina A.M. and Grasso, Floriana and Payne, Terry R.},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, Ontology reuse, Competency question, Requirements engineering, Ontology's, C (programming language), Functional requirement, Generative adversarial networks, Natural language questions, Ontology Engineering Methodologies, Retrofitting, Testing requirements, Incorrect information},
	pages = {3 -- 13},
	annote = {Type: Conference paper}
}

@InProceedings{amardeilh2006OntopopOrHow,
	file = {References/pdf/amardeilh2006OntopopOrHow.pdf},
	author = {Amardeilh, Florence},
	title = {{OntoPop or how to annotate documents and populate
                  ontologies from texts}},
	year = 2006,
	booktitle = {{ESWC 2006 Workshop on Mastering the Gap: From
                  Information Extraction to Semantic Representation}},
	volume = 187,
	note = {http://sunsite.informatik.rwth-aachen.de/Publications/CEUR-WS//Vol-187/11.pdf},
	publisher = {{CEUR Workshop Proceedings}},
	month = Jun,
	url = {https://shs.hal.science/halshs-00115255},
	KEYWORDS = {Semantic Web ; Information Extraction ; Semantic
                  Representation ; Ontology Population ; Web
                  s{\'e}mantique ; Extraction d'information ;
                  Repr{\'e}sentation de la connaissance ; Peuplement
                  d'ontologie},
	PDF = {https://shs.hal.science/halshs-00115255v1/file/amardeilh_ESWC06.pdf},
	HAL_ID = {halshs-00115255},
	HAL_VERSION = {v1}
}

@InCollection{amardeilh2008SemanticAnnotationOntology,
	file = {References/pdf/amardeilh2008SemanticAnnotationOntology.pdf},
	author = {Amardeilh, Florence},
	title = {{Semantic Annotation and Ontology Population}},
	year = 2008,
	booktitle = {{Semantic Web Engineering in the Knowledge Society}},
	editor = {Jorge Cardoso and SAP Research and Germany and
                  Miltiadis Lytras and Athens University of Economics
                  and Business and Greece},
	publisher = {{Information Science Reference (formerly Idea Group
                  Reference)}},
	pages = {424 p.},
	url = {https://hal.science/hal-00348925},
	KEYWORDS = {Ontologies ; Metadata ; Knowledge Acquisition ;
                  Natural Language Processors ; Semantic Integrity ;
                  Knowledge-Based Systems ; Web Technologies ;
                  Annotation ; S{\'e}mantique ; Connaissance ; TAL ;
                  NLP},
	HAL_ID = {hal-00348925},
	HAL_VERSION = {v1}
}

@article{amini2025TowardsComplexOntology,
	file = {References/pdf/amini2025TowardsComplexOntology.pdf},
	title = {Towards {Complex} {Ontology} {Alignment} {Using} {Large} {Language} {Models}},
	volume = {15459},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218934218&doi=10.1007%2F978-3-031-81221-7_2&partnerID=40&md5=0ceb4a7e31a8a179e3d1efda57c8567e},
	doi = {10.1007/978-3-031-81221-7_2},
	abstract = {Ontology alignment, a critical process in the Semantic Web for detecting relationships between different ontologies, has traditionally focused on identifying so-called “simple” 1-to-1 relationships through class labels and properties comparison. The more practically useful exploration of more complex alignments remains a hard problem to automate, and as such is largely underexplored, i.e. in application practice it is usually done manually by ontology and domain experts. Recently, the surge in Natural Language Processing (NLP) capabilities, driven by advancements in Large Language Models (LLMs), presents new opportunities for enhancing ontology engineering practices, including ontology alignment tasks. This paper investigates the application of LLM technologies to tackle the complex ontology alignment challenge. Leveraging a prompt-based approach and integrating rich ontology content – so-called modules – our work constitutes a significant advance towards automating the complex alignment task. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Amini, Reihaneh and Norouzi, Sanaz Saki and Hitzler, Pascal Al and Amini, Reza},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Ontology model, Language model, Semantics, Modular ontologies, Ontology alignment, Modular ontology modeling, Modeling languages, Ontology's, Natural language processing systems, Semantic-Web, Complex ontology alignment},
	pages = {17 -- 31},
	annote = {Type: Conference paper}
}

@article{arevalo2025AutontoTowardsSemi,
	file = {References/pdf/arevalo2025AutontoTowardsSemi.pdf},
	title = {{AutOnto}: {Towards} {A} {Semi}-{Automated} {Ontology} {Engineering} {Methodology}},
	volume = {15459},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218935432&doi=10.1007%2F978-3-031-81221-7_16&partnerID=40&md5=ca4a284fddf4e697c1b7573d812ac843},
	doi = {10.1007/978-3-031-81221-7_16},
	abstract = {This paper addresses the challenge of efficiently constructing domain ontologies for large, rapidly evolving domains, where manual approaches often struggle to overcome knowledge acquisition bottlenecks. To overcome these limitations, we developed an automated framework, AutOnto, for knowledge extraction and ontology conceptualization that leverages Large Language Models (LLMs) and natural language processing (NLP) techniques. AutOnto integrates BERT-based topic modeling with LLMs to automate the extraction of concepts and relationships from text corpora, facilitating the construction of taxonomies and the generation of domain ontologies. We applied AutOnto to a dataset of NLP-specific articles from OpenAlex and compared the resulting ontology generated by our automated process against a well-established gold-standard ontology. The results indicate that AutOnto achieves comparable levels of quality and correctness while significantly reducing the amount of data required and the dependence on domain-specific expertise. These findings highlight AutOnto’s efficiency and effectiveness in knowledge extraction and ontology generation. This work has significant implications for rapid ontology development in large, evolving domains, potentially mitigating the knowledge acquisition bottleneck in ontology engineering. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Arevalo, Kiara Marnitt Ascencion and Ambre, Shruti and Dorsch, Rene},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge acquisition, Ontology engineering, Large language model, Ontology, Natural language processing, Language model, Domain ontologies, Knowledge extraction, Modeling languages, Knowledge ontology, Taxonomies, Language processing, Natural languages, Domain Knowledge, Natural language processing systems, Knowledge acquisition bottlenecks},
	pages = {225 -- 241},
	annote = {Type: Conference paper}
}

@article{armary2024IdentifyingLogicalPatterns,
	file = {References/pdf/armary2024IdentifyingLogicalPatterns.pdf},
	title = {Identifying {Logical} {Patterns} in {Text} for {Reasoning}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217432359&doi=10.1109%2FICTAI62512.2024.00122&partnerID=40&md5=57088e55fc285fbc3412ea1f7c228efb},
	doi = {10.1109/ICTAI62512.2024.00122},
	abstract = {Translating unstructured text into logical format is a key challenge for building ontologies automatically and addressing deductive inference. Most of the approaches have tackled the identification of concepts and relations in text, but few of them have addressed the most complex axioms like class expression subsumption. This work proposes DeLIR, a neuro-symbolic approach to identify complex logical patterns in text by combining a grammatical translation of dependency parsing trees and a fine-tuned Large language Model (LLM). DeLIR combines the strength of the parsing accuracy provided by a grammatical approach and pattern flexibility provided by a finetuned LLM. We evaluated our approach on FOLIO dataset for both translation capacity and inference capability. Our grammatical approach has a perfect parsing accuracy and combining the grammatical approach with LLMs improves the LLMS translation capacity: tinyLlama, T5-small-text2logic, Llama-7B and Mistral-7B. We also evaluate the inference capacity of the different LLMs. Mistral-7B, while being smaller than the state-of-the-art approach using GPT-4, presents similar results to predict the correct inference labels.},
	journal = {2024 IEEE 36th International Conference on Tools with Artificial Intelligence (ICTAI)},
	author = {Armary, Pauline and El-Vaigh, Cheikh-Brahim and Spicher, Antoine and Narsis, Ouassila Labbani and Nicolle, Christophe},
	month = oct,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Ontology, Language model, Ontology learning, Large language models, Cognition, Ontology Learning, Natural language inference, Translation, Natural Language Inference, Accuracy, Language inference, Natural languages, Syntactics, Buildings, Zero shot learning, Hands, Translation to Logic, Ontology's, Contrastive Learning, Computer aided language translation, Unstructured texts, Computer circuits, Dependency parsing, State-of-the-art approach, Translation to logic},
	pages = {837--844},
	annote = {ISSN: 2375-0197}
}

@Article{ashburner2000GeneOntologyTool,
	file = {References/pdf/ashburner2000GeneOntologyTool.pdf},
	author = {Ashburner, Michael and Ball, Catherine A. and Blake,
                  Judith A. and Botstein, David and Butler, Heather
                  and Cherry, J. Michael and Davis, Allan P. and
                  Dolinski, Kara and Dwight, Selina S. and Eppig,
                  Janan T. and Harris, Midori A. and Hill, David
                  P. and Issel-Tarver, Laurie and Kasarskis, Andrew
                  and Lewis, Suzanna and Matese, John C. and
                  Richardson, Joel E. and Ringwald, Martin and Rubin,
                  Gerald M. and Sherlock, Gavin},
	title = {Gene Ontology: tool for the unification of biology},
	journal = {Nature Genetics},
	year = 2000,
	volume = 25,
	number = 1,
	month = may,
	pages = {25–29},
	issn = {1546-1718},
	doi = {10.1038/75556},
	url = {http://dx.doi.org/10.1038/75556},
	publisher = {Springer Science and Business Media LLC}
}

@Article{ashraf2015OntologyUsageAnalysis,
	file = {References/pdf/ashraf2015OntologyUsageAnalysis.pdf},
	author = {Jamshaid Ashraf and Elizabeth Chang and Omar Khadeer
                  Hussain and Farookh Khadeer Hussain},
	title = {Ontology usage analysis in the ontology lifecycle:
                  {A} state-of-the-art review},
	journal = {Knowl. Based Syst.},
	year = 2015,
	volume = 80,
	pages = {34-47},
	doi = {10.1016/J.KNOSYS.2015.02.026},
	url = {https://doi.org/10.1016/j.knosys.2015.02.026},
	timestamp = {Tue, 25 Feb 2020 09:02:55 +0100},
	biburl = {https://dblp.org/rec/journals/kbs/AshrafCHH15.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@Article{asim2018SurveyOntologyLearning,
	file = {References/pdf/asim2018SurveyOntologyLearning.pdf},
	author = {Muhammad Nabeel Asim and Muhammad Wasim and Muhammad
                  Usman Ghani Khan and Waqar Mahmood and Hafiza
                  Mahnoor Abbasi},
	title = {A survey of ontology learning techniques and
                  applications},
	journal = {Database J. Biol. Databases Curation},
	year = 2018,
	volume = 2018,
	pages = {bay101},
	doi = {10.1093/DATABASE/BAY101},
	url = {https://doi.org/10.1093/database/bay101},
	timestamp = {Thu, 25 Apr 2024 15:20:43 +0200},
	biburl = {https://dblp.org/rec/journals/biodb/AsimWKMA18.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{ayad2025OntologyPopulationWith,
	title = {Ontology {Population} {With} {Large} {Language} {Models} ({LLMs}): {A} {Case} {Study} on {Asbestos} {Ontology}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009643870&doi=10.1177%2F15705838251334528&partnerID=40&md5=99260599b40b559e791145cd4b880519},
	doi = {10.1177/15705838251334528},
	abstract = {The Asbestos Ontology is a domain application ontology designed for use in an ontology-based approach that estimates the probability of the existence of asbestos products in a building. However, new issues in the building domain, such as predicting the presence of lead in buildings, renovating asbestos floors, or the reuse and recycling of components or parts of buildings as part of the circular economy, require a generalization of this ontology to a building ontology. The lack of relevant data tends to make decision-making difficult. The purpose of our approach is to show how instance-level knowledge graphs can be populated without having to manually create hundreds of instances using large language models (LLMs) and prompt engineering. This paper introduces a novel method for populating ontologies using the latest generative LLMs, such as GPT-3.5. Our method is characterized by an innovative recursive zero-shot prompting technique. The key contributions of this study are: (i) a new strategy for recursively prompting LLMs to elicit pertinent knowledge from the asbestos application domain; (ii) ontology population informed by the ontology metamodel; and (iii) formalization of the results into OWL axioms for the automatic integration of new instances. To evaluate the efficacy of our approach, we employed two main methodologies: (1) querying for instances linked to each entity; and (2) recursively querying for instances to leverage our recursive prompting strategy. Our initial strategy focused on evaluating the effectiveness of zero-shot prompting in retrieving relevant values for entities and data properties. This was facilitated through the development of the PromptGeneration function, which adjusted the input C{\textbackslash}textlessinf{\textbackslash}textgreateri{\textbackslash}textless/inf{\textbackslash}textgreater across various contexts. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Applied Ontology},
	author = {Ayad, Sarah and Khelifa Chibout, Lydia},
	year = {2025},
	note = {Section: 0},
	keywords = {ChatGPT, Large language model, Ontology, Ontology Population, Language model, Knowledge management, Prompt engineering, Decision making, Ontology-based, Buildings, Ontology's, In-buildings, Case-studies, Asbestos, Reuse and recycling, Cannot download},
	annote = {Type: Article}
}

@Article{aydar2020NeuralRelationExtraction,
	file = {References/pdf/aydar2020NeuralRelationExtraction.pdf},
	author = {Mehmet Aydar and Ozge Bozal and Furkan {\"{O}}zbay},
	title = {Neural relation extraction: a survey},
	journal = {CoRR},
	year = 2020,
	volume = {abs/2007.04247},
	eprint = {2007.04247},
	eprinttype = {arXiv},
	url = {https://arxiv.org/abs/2007.04247},
	timestamp = {Mon, 17 May 2021 18:25:11 +0200},
	biburl = {https://dblp.org/rec/journals/corr/abs-2007-04247.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@Book{baezayates1999ModernInformationRetrieval,
	file = {References/pdf/baezayates1999ModernInformationRetrieval.pdf},
	author = {Ricardo A. Baeza{-}Yates and Berthier
                  A. Ribeiro{-}Neto},
	title = {Modern Information Retrieval},
	year = 1999,
	publisher = {{ACM} Press / Addison-Wesley},
	isbn = {0-201-39829-X},
	url = {http://www.dcc.ufmg.br/irbook/},
	timestamp = {Tue, 18 Sep 2012 08:39:46 +0200},
	biburl = {https://dblp.org/rec/books/aw/Baeza-YatesR99.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{baidya2024TowardFineTuning,
	file = {References/pdf/baidya2024TowardFineTuning.pdf},
	title = {Toward {Fine}-{Tuning} {Large} {Language} {Models} in {Ontology} of {Microbial} {Phenotypes} {Construction}},
	doi = {10.1109/BIBM62325.2024.10947604},
	abstract = {Ontologies are crucial for organizing domainspecific knowledge in biomedical fields, but their manual construction is time-consuming. This study explores the automation of ontology learning using large language models (LLMs) like BERT, RoBERTa, and DistilBERT, focusing on the Ontology of Microbial Phenotypes (OMP). We investigate three key tasks: (1) entity extraction, (2) relation extraction between entities, and (3) ontology verification. These tasks align with broader applications in biomedical annotation and named entity recognition (NER) by enabling the identification and structuring of key terms and relationships within microbial phenotypes. We evaluate LLMs in two scenarios: baseline performance using pre-trained models and fine-tuned performance after training on OMP-specific data. Our approach integrates spaCy for entity extraction, Llama 2 for relation identification, and LLMs for ontology verification. Experiments reveal that fine-tuned models significantly improve accuracy, precision, recall, and F1 scores, particularly for ontology verification. This research highlights the potential of LLMs to enhance ontology learning and support related biomedical applications like biofilm analysis, annotation, and NER, while emphasizing the value of expert curation.},
	journal = {2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
	author = {Baidya, Anushuya and Do, Tuyen and Gnimpieba, Etienne Z.},
	month = dec,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Large Language Models, Named entity recognition, Large language models, Annotations, Fine-tuning, Ontology Learning, Data models, Training, Phenotypes, Manuals, Focusing, Biological system modeling, Microbial Phenotypes, Ontology Verification},
	pages = {6913--6920},
	annote = {ISSN: 2156-1133}
}

@Article{bakker2024DynamicKnowledgeGraph,
	file = {References/pdf/bakker2024DynamicKnowledgeGraph.pdf},
	author = {Bakker, Roos M. and Boer, Maaike H T De},
	title = {Dynamic Knowledge Graph Evaluation},
	year = 2024,
	month = jun,
	doi = {10.36227/techrxiv.171779320.04772689/v1},
	url = {http://dx.doi.org/10.36227/techrxiv.171779320.04772689/v1},
	publisher = {Institute of Electrical and Electronics Engineers
                  (IEEE)}
}

@article{banerjee2024CrossLingualOntology,
	file = {References/pdf/banerjee2024CrossLingualOntology.pdf},
	title = {Cross-{Lingual} {Ontology} {Matching} using {Structural} and {Semantic} {Similarity}},
	url = {https://aclanthology.org/2024.ldl-1.2/},
	abstract = {The development of ontologies in various languages is attracting attention as the amount of multilingual data available on the web increases. Cross-lingual ontology matching facilitates interoperability amongst ontologies in different languages. Although supervised machine learning-based methods have shown good performance on ontology matching, their application to the cross-lingual setting is limited by the availability of training data. Current state-of-the-art unsupervised methods for cross-lingual ontology matching focus on lexical similarity between entities. These approaches follow a two-stage pipeline where the entities are translated into a common language using a translation service in the first step followed by computation of lexical similarity between the translations to match the entities in the second step. In this paper we introduce a novel ontology matching method based on the fusion of structural similarity and cross-lingual semantic similarity. We carry out experiments using 3 language pairs and report substantial improvements on the performance of the lexical methods thus showing the effectiveness of our proposed approach. To the best of our knowledge this is the first work which tackles the problem of unsupervised ontology matching in the cross-lingual setting by leveraging both structural and semantic embeddings.},
	journal = {Proceedings of the 9th Workshop on Linked Data in Linguistics @ LREC-COLING 2024},
	author = {Banerjee, Shubhanker and Chakravarthi, Bharathi Raja and McCrae, John Philip},
	editor = {Chiarcos, Christian and Gkirtzou, Katerina and Ionov, Maxim and Khan, Fahad and McCrae, John P. and Ponsoda, Elena Montiel and Chozas, Patricia Martín},
	month = may,
	year = {2024},
	note = {Place: Torino, Italia
Publisher: ELRA and ICCL
Section: 0},
	pages = {11--21},
	annote = {RAYYAN-LABELS: Good for referencing}
}

@article{banerjee2024LargeLanguageModels,
	file = {References/pdf/banerjee2024LargeLanguageModels.pdf},
	title = {Large {Language} {Models} for {Few}-{Shot} {Automatic} {Term} {Extraction}},
	volume = {14762},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205377483&doi=10.1007%2F978-3-031-70239-6_10&partnerID=40&md5=1d8b90d62ef32b8cf5241528fc134779},
	doi = {10.1007/978-3-031-70239-6_10},
	abstract = {Automatic term extraction is the process of identifying domain-specific terms in a text using automated algorithms and is a key first step in ontology learning and knowledge graph creation. Large language models have shown good few-shot capabilities, thus, in this paper, we present a study to evaluate the few-shot in-context learning performance of GPT-3.5-Turbo on automatic term extraction. To benchmark the performance we compare the results with fine-tuning of a BERT-sized model. We also carry out experiments with count-based term extractors to assess their applicability to few-shot scenarios. We quantify prompt sensitivity with experiments to analyze the variation in performance of large language models across different prompt templates. Our results show that in-context learning with GPT-3.5-Turbo outperforms the BERT-based model and unsupervised count-based methods in few-shot scenarios. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Banerjee, Shubhanker and Chakravarthi, Bharathi Raja and Mccrae, John Philip},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graph, Large language model, Ontology, Language model, Ontology learning, Performance, Automatic term extraction, Zero-shot learning, Few-shot, Context learning, In contexts, Contrastive Learning, Domain specific, Automated algorithms},
	pages = {137 -- 150},
	annote = {Type: Conference paper}
}

@article{barros2025LlmBasedApproaches,
	file = {References/pdf/barros2025LlmBasedApproaches.pdf},
	title = {{LLM}-based approaches for automated vocabulary mapping between {SIGTAP} and {OMOP} {CDM} concepts},
	volume = {168},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011174963&doi=10.1016%2Fj.artmed.2025.103204&partnerID=40&md5=1b775df6ed0d57e4182e5af0d7b58848},
	doi = {10.1016/j.artmed.2025.103204},
	abstract = {In the context of global healthcare systems, integrating diverse medical terminologies and classification systems has become a priority due to the adoption of Electronic Health Record (EHR) systems and the imperative for information exchange between healthcare systems. This study addresses the necessity for mapping between the SIGTAP vocabulary used in Brazilian healthcare systems and the broader medical terms of the OMOP CDM terminologies. Two distinct pipelines are evaluated for the vocabulary mapping process, focusing on two subsets of the SIGTAP vocabulary: medicines and medical procedures. The first pipeline utilizes textual embeddings for semantic similarity evaluation, followed by Large Language Models (LLMs) for correspondences selection through a retrieval-augmented generation (RAG) approach. In the second pipeline, LLM agents employ predefined protocols for vocabulary mapping and query refinement. Our results show comparable performance between pipelines in both the Procedures subset (F{\textbackslash}textlessinf{\textbackslash}textgreater1{\textbackslash}textless/inf{\textbackslash}textgreater of 0.684 versus 0.678), and the Medicines subset (F{\textbackslash}textlessinf{\textbackslash}textgreater1{\textbackslash}textless/inf{\textbackslash}textgreater of 0.846 versus 0.839), indicating the viability of the multi-stage filtering approach. The second pipeline demonstrates an advantage over the first in terms of recall, highlighting the efficacy of dynamic query refinement by the agent. These findings provide evidence that LLM-based methods significantly reduce manual effort required by experts, enabling domain specialists to focus on more challenging cases. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Artificial Intelligence in Medicine},
	author = {de Barros Vanzin, Vinícius João and Moreira, Dilvan De Abreu and Marcondes Marcacini, Ricardo},
	year = {2025},
	note = {Section: 0},
	keywords = {large language model, Ontology, Terminology, Language model, Ontology mapping, Semantics, natural language processing, ontology, vocabulary, Natural Language Processing, semantics, Retrieval-augmented generation, Health care, Brazil, Electronic health record, Controlled, Vocabulary, Query processing, electronic health record, Medicine, Thesauri, Mapping, Electronic Health Records, retrieval augmented generation, protocol, human, health care system, Pipelines, article, Humans, female, male, Classification (of information), Medical computing, controlled vocabulary, Electronic document exchange, filtration, Healthcare systems, Large language model agent, Medical classification, Medical information systems, medical specialist, Medical terminologies, medical terminology, Model agents, Model based approach, Query refinement, Vocabulary control},
	annote = {Type: Article}
}

@article{barua2024ConceptInductionUsing,
	file = {References/pdf/barua2024ConceptInductionUsing.pdf},
	title = {Concept {Induction} {Using} {LLMs}},
	volume = {3884},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214839760&partnerID=40&md5=a4f4be096d70304877c43b60b93d8ecf},
	abstract = {In this study, the capability of Large Language Models (LLMs) is explored to automate Concept Induction, a process traditionally reliant on formal logical reasoning using description logic ontologies, within the context of explainable AI (XAI). Initially, a pre-trained LLM like GPT-4 is employed to assess its ability to generate high-level concepts describing data differentials for a scene classification task via prompting. A human assessment study was conducted which revealed that concepts produced by GPT-4 are preferred over those from logical concept induction systems in terms of human understandability, despite some limitations in neuron activation analysis. Building on these insights, further research aims to automate the concept induction system using LLMs, potentially addressing the shortcomings of traditional logical reasoners. This approach has the potential to scale and provide a significant avenue for concept discovery in complex AI models. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Barua, Adrita},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Modeling languages, Description logic, Formal languages, Explainable AI, GPT-4, Concept induction, Logical reasoning, Ontology's, Problem oriented languages, Induction system, Scene classification},
	annote = {Type: Conference paper}
}

@article{bernardini2025AdvancingInternetConnected,
	file = {References/pdf/bernardini2025AdvancingInternetConnected.pdf},
	title = {Advancing {Internet}-{Connected} {Devices} {Posture} {Analysis} with a {Meta}-{Search} {Engine}: {A} {Case} {Study} in {Energy} {Systems}},
	volume = {3962},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005824204&partnerID=40&md5=df494d58a3cac4f953de4dc4f32a9bc7},
	abstract = {In the contemporary digital ecosystem, Internet of Things Search Engines can be used for passive reconnaissance of Internet-connected devices, mapping possible attack surfaces without a direct interaction with the target devices or infrastructures. Each IoT search engine utilizes diverse scanning techniques and analytical methodologies, resulting in metadata with varying levels of coverage, accuracy, and relevance. This research introduces an IoT meta-search engine prototype designed to aggregate and merge metadata from commercial IoT search engines (Shodan, Censys, Netlas, Zoomeye, Binaryedge, Fofa) complemented by Common Vulnerabilities and Exposures (CVE) and Common Weakness Enumeration (CWE) sources. By merging those data, a more comprehensive and detailed perspective of the interconnected device landscape can be provided. Our methodology leverages an ontological framework using Stanford’s Protégé and Python, implementing zero-shot learning with a panel of three Large Language Models (LLMs) under human supervision to map IoT search engine taxonomic structures and quantitatively validate the generated Knowledge Base. The IoT meta-search engine is tested on photovoltaic (PV) energy production and monitoring systems, a domain essential to renewable energy grids. Vulnerabilities in PV systems can be exploited by hackers, causing energy disruptions, data breaches, or manipulation of grid operations. Although the findings are preliminary, they serve as a proof of concept to demonstrate the feasibility of the methodology to provide various types of overviews and insights associated with individual and multiple hosts for security posture evaluation. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Bernardini, Andrea and Lezoche, Mario and Angelini, Simone and Dondossola, Giovanna and Terruggia, Roberta},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge acquisition, Large language model, Ontology, Language model, Knowledge representation, Taxonomies, Security, Vulnerability, Ontology's, Online searching, Inference engines, Case-studies, Energy systems, Internet connected device, Meta search engines, Posture analysis, Sensitive data},
	annote = {Type: Conference paper}
}

@Online{berti2025EmergentAbilitiesIn,
	file = {References/pdf/berti2025EmergentAbilitiesIn.pdf},
	author = {Leonardo Berti AND Flavio Giorgi AND Gjergji
                  Kasneci},
	title = {{Emergent Abilities in Large Language Models: A
                  Survey}},
	year = 2025,
	eprint = {2503.05788v2},
	primaryclass = {cs.LG},
	archiveprefix = {arXiv}
}

@article{bertini2024Concept2textExplainableMultilingual,
	file = {References/pdf/bertini2024Concept2textExplainableMultilingual.pdf},
	title = {{Concept2Text}: an explainable multilingual rewriting of concepts into natural language},
	volume = {3733},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200126703&partnerID=40&md5=e09884c42ba89e9a77cf5bd1e91aab98},
	abstract = {Automated and explainable data interpretation hinges on two critical steps: (i) identifying emerging properties from data and representing them into abstract concepts, and (ii) translating such concepts into natural language. While Large Language Models have recently demonstrated impressive capabilities in generating natural language, their trustworthiness remains difficult to ascertain. The deployment of an explainable pipeline enables its application in high-risk activities, such as decision making. Addressing this demanding requirement is facilitated by the fertile ground of knowledge representation and automated reasoning research. Building upon previous work that explored the first step, we focus on the second step, named Concept2Text. The design of an explainable translation naturally lends itself to a logic-based model, once again highlighting the contribution of declarative programming to achieving explainability in AI. This paper explores a Prolog/CLP-based rewriting system designed to interpret concepts expressed in terms of classes and relations derived from a generic ontology, generating text in natural language. Its key features encompass hierarchical tree rewritings, modular multilingual generation, support for equivalent variants across semantic, grammar, and lexical levels, and a transparent rule-based system. We present the architecture and illustrate a simple working example that allows the generation of hundreds of different and equivalent rewritings relative to the input concept. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Bertini, Flavio and Dal Palú, Alessandro and Fabiano, Francesco and Formisano, Andrea and Zaglio, Federica},
	year = {2024},
	note = {Section: 0},
	keywords = {Language model, Semantics, Knowledge representation, Decision making, Prolog, Explainable AI, Logic programming, Data interpretation, Natural languages, Abstracting, Property, Abstract concept, PROLOG (programming language), Translation (languages), Concept-to-text, Critical steps, ITS applications, Program translators},
	annote = {Type: Conference paper}
}

@article{bhattacharya2024AutomaticOntologyTerm,
	file = {References/pdf/bhattacharya2024AutomaticOntologyTerm.pdf},
	title = {Automatic {Ontology} {Term} {Typing} by {LLMs}: {The} {Impact} of {Prompt} and {Ontology} {Variation}},
	volume = {3967},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006903401&partnerID=40&md5=ed7b3771dc19477cc1c99014f80d8788},
	abstract = {Large Language Models (LLMs) have been applied to a wide variety of ontology engineering tasks. Building on initial progress, further research is needed to explore potential effects of variation over model-specific and ontology-specific factors. We perform a preliminary study on the ability of an LLM to perform term typing using only its own knowledge through concept retrieval and analyse the effect of domain contextualisation, ontology structure and popularity of ontologies on performance. Our findings suggest that LLMs are reasonably adept at identifying correct individual to concept assertions but are less capable of inferring concept hierarchies when used in a zero-shot setting. Domain contextualisation can enhance performance for structurally complex and less-popular ontologies. Our analysis furthers hints at ontology popularity improving concept retrievability while complexity in terms of structural depth and dispersion makes it difficult for LLMs to identify assertions. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Bhattacharya, Upal and de Boer, Maaike H.T. and Sosnovsky, Sergey A.},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Ontology learning, Performance, Contextualization, Ontology's, Ontology evaluations, Automatic ontology, Individual assertion, Term typing},
	annote = {Type: Conference paper}
}

@article{bischof2025LlmBasedGuided,
	file = {References/pdf/bischof2025LlmBasedGuided.pdf},
	title = {{LLM}-{Based} {Guided} {Generation} of {Ontology} {Term} {Definitions}},
	volume = {15344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218454539&doi=10.1007%2F978-3-031-78952-6_13&partnerID=40&md5=1bb87d01dc10ca28ae22f25a611815f1},
	doi = {10.1007/978-3-031-78952-6_13},
	abstract = {This paper describes our approach for leveraging LLMs to generate definitions and descriptions for ontology terms. Our approach is grounded in the need for detailed and accurate representation of (domain-specific) Knowledge Graphs, and it aims at speeding up the process of generating such text. We outline our approach, including the problems that we encountered, and the solution we propose to overcome them. Our approach is currently in use in an industrial setting. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Bischof, Stefan and Filtz, Erwin and Parreira, Josiane Xavier and Steyskal, Simon},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Ontology engineering, Knowledge graph, Large language model, Ontology, Language model, Domain-specific knowledge, Ontology terms, Industrial settings, Knowledge IT, Text generations, Incorrect information},
	pages = {133 -- 137},
	annote = {Type: Conference paper}
}

@article{bombieri2025DoLlmsDream,
	file = {References/pdf/bombieri2025DoLlmsDream.pdf},
	title = {Do {LLMs} {Dream} of {Ontologies}?},
	issn = {2157-6904},
	url = {https://doi.org/10.1145/3725852},
	doi = {10.1145/3725852},
	abstract = {Large Language Models (LLMs) have demonstrated remarkable performance across diverse natural language processing tasks, yet their ability to memorize structured knowledge remains underexplored. In this paper, we investigate the extent to which general-purpose pre-trained LLMs retain and correctly reproduce concept identifier (ID)–label associations from publicly available ontologies. We conduct a systematic evaluation across multiple ontological resources, including the Gene Ontology, Uberon, Wikidata, and ICD-10, using LLMs such as Pythia-12B, Gemini-1.5-Flash, GPT-3.5, and GPT-4. Our findings reveal that only a small fraction of ontological concepts is accurately memorized, with GPT-4 demonstrating the highest performance. To understand why certain concepts are memorized more effectively than others, we analyze the relationship between memorization accuracy and concept popularity on the Web. Our results indicate a strong correlation between the frequency of a concept’s occurrence online and the likelihood of accurately retrieving its ID from the label. This suggests that LLMs primarily acquire such knowledge through indirect textual exposure rather than directly from structured ontological resources. Furthermore, we introduce new metrics to quantify prediction invariance, demonstrating that the stability of model responses across variations in prompt language and temperature settings can serve as a proxy for estimating memorization robustness.},
	journal = {ACM Trans. Intell. Syst. Technol.},
	author = {Bombieri, Marco and Fiorini, Paolo and Ponzetto, Simone Paolo and Rospocher, Marco},
	month = mar,
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Large Language Models, Memorization},
	annote = {Place: New York, NY, USA Publisher: Association for Computing Machinery}
}

@Article{bommasani2023HolisticEvaluationLanguage,
	file = {References/pdf/bommasani2023HolisticEvaluationLanguage.pdf},
	author = {Bommasani, Rishi and Liang, Percy and Lee, Tony},
	title = {Holistic Evaluation of Language Models},
	journal = {Annals of the New York Academy of Sciences},
	year = 2023,
	volume = 1525,
	number = 1,
	month = may,
	pages = {140–146},
	issn = {1749-6632},
	doi = {10.1111/nyas.15007},
	url = {http://dx.doi.org/10.1111/nyas.15007},
	publisher = {Wiley}
}

@article{bora2025VrsilFrameworkVideo,
	file = {References/pdf/bora2025VrsilFrameworkVideo.pdf},
	title = {{VRSIL}: {A} {Framework} for {Video} {Recommendation} {Integrating} {Semantic} {Intelligence} with a {Large} {Language} {Model}},
	volume = {2461},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010813395&doi=10.1007%2F978-3-031-96473-2_2&partnerID=40&md5=e89825e27bd426a69a8c41847958678c},
	doi = {10.1007/978-3-031-96473-2_2},
	abstract = {This framework presents a strategic model for video recommendation in the Web 3.0 era, integrating hybrid machine intelligence, generative AI, and semantic artificial intelligence through advanced semantic reasoning and quantitative semantic measures. The model dynamically generates ontologies from preprocessed query words, which are then used to select features based on linked similarity. These features are employed to classify the dataset from the perspective of the query using a logistic regression classifier. Semantics-oriented reasoning is achieved by computing the Normalized Pointwise Mutual Information (NPMI) to determine quantitative thresholds, and the Jian-Konrad Index is utilized as a criterion function for optimization. This optimization is carried out using the Elephant Optimization algorithm, which is executed only once to maintain the diversity and number of recommended entities. This approach ensures that the recommendations are both relevant and varied, aligning with the dynamic nature of Web 3.0. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Communications in Computer and Information Science},
	author = {Bora, Anubrat and Deepak, Gerard},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology, Language model, Artificial intelligence, Semantic Web, Semantics, Web 3.0, Semantic similarity, Ontology generation, Semantic reasoning, Optimisations, Hybrid machine, Logistic regression, Machine intelligence, Semantic intelligence, Strategic modeling},
	pages = {15 -- 24},
	annote = {Type: Conference paper}
}

@Article{boscariol2025EvaluationLlmsLong,
	file = {References/pdf/boscariol2025EvaluationLlmsLong.pdf},
	author = {Marta Boscariol and Luana Bulla and Lia Draetta and
                  Beatrice Fiuman{\`{o}} and Emanuele Lenzi and
                  Leonardo Piano},
	title = {Evaluation of LLMs on Long-tail Entity Linking in
                  Historical Documents},
	journal = {CoRR},
	year = 2025,
	volume = {abs/2505.03473},
	doi = {10.48550/ARXIV.2505.03473},
	eprint = {2505.03473},
	eprinttype = {arXiv},
	url = {https://doi.org/10.48550/arXiv.2505.03473},
	timestamp = {Fri, 20 Jun 2025 20:58:49 +0200},
	biburl = {https://dblp.org/rec/journals/corr/abs-2505-03473.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{bouas2025KnowledgeExtractionOntology,
	file = {References/pdf/bouas2025KnowledgeExtractionOntology.pdf},
	title = {Knowledge {Extraction} and {Ontology} {Modeling} in the {SALLY} {Chatbot}},
	volume = {754},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010208274&doi=10.1007%2F978-3-031-97313-0_8&partnerID=40&md5=f8721ca170bf3fe1df83fa69419470c1},
	doi = {10.1007/978-3-031-97313-0_8},
	abstract = {Reception and social integration of Third Country Nationals (TCNs) remains a pressing challenge in contemporary societies shaped by migration. The SALLY project supports the integration of migrants in Greece through a multilingual conversational agent designed to assist users in accessing information related to legal, healthcare, employment, and social services. This paper presents preliminary work on a knowledge extraction framework that captures key elements from natural language conversations—such as topics, entities, and relationships—using Large Language Models (LLMs). These are structured as RDF Knowledge Graphs guided by an ontology that reflects the dynamics of user-agent interaction. By translating informal dialogue into semantically meaningful representations, the system offers a foundation for better understanding user needs and behavior, while enhancing the transparency and responsiveness of the SALLY conversational agent. © 2025 Elsevier B.V., All rights reserved.},
	journal = {IFIP Advances in Information and Communication Technology},
	author = {Bouas, Christos and Papoutsoglou, Maria C. and Tassios, Alexandros and Tegos, Stergios D. and Manousaridis, Konstantinos and Mavropoulos, Thanassis and Vrochidis, Stefanos and Meditskos, Georgios},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Large language model, Ontology, Ontology model, Language model, Knowledge extraction, Knowledge management, Modeling languages, Integration, Knowledge ontology, Information systems, Human computer interaction, Extraction, Conversational agents, Chatbots, Information use, Multi agent systems, User interfaces, Natural language processing systems, Behavioral research, Human engineering, Extraction modeling, Migrant integration},
	pages = {95 -- 103},
	annote = {Type: Conference paper {\textbar} RAYYAN-LABELS: ontology-supported application}
}

@article{bouchouras2024LlmsEngineeringParkinson,
	file = {References/pdf/bouchouras2024LlmsEngineeringParkinson.pdf},
	title = {{LLMs} for the {Engineering} of a {Parkinson} {Disease} {Monitoring} and {Alerting} {Ontology}},
	volume = {3749},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203587310&partnerID=40&md5=6cf0a5bc51abfa68aafd9a5fe1f9d3ea},
	abstract = {This paper investigates the integration of Large Language Models (LLMs) in the engineering of a Parkinson's Disease (PD) monitoring and alerting ontology. The focus is on the ontology engineering methodology which combines the capabilities of LLMs and human expertise to develop more robust and comprehensive domain ontologies, faster than humans do alone. Evaluating models like ChatGPT-3.5, ChatGPT4, Gemini, and Llama2, this study explores various LLM based ontology engineering methods. The findings reveal that the proposed hybrid approach (both LLM and human involvement), namely X-HCOME, consistently excelled in class generation and F-1 score, indicating its efficiency in creating valid and comprehensive ontologies faster than humans do alone. The study underscores the potential of the combined LLMs and human intelligence to enrich PD domain knowledge and enhance expert-generated PD ontologies. In overall, the presented approach exemplifies a promising collaboration between machine capabilities and human expertise in developing ontologies for complex domains. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Bouchouras, Georgios and Bitilis, Pavlos and Kotis, Konstantinos I. and Vouros, George A.},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, Neurodegenerative diseases, Parkinson's disease, Ontology's, Human engineering, Ontology Engineering Methodologies, Disease control, Disease monitoring, Human expertise, Human-large language model teaming},
	annote = {Type: Conference paper}
}

@article{bowles2025ComparativeAnalysisNlp,
	file = {References/pdf/bowles2025ComparativeAnalysisNlp.pdf},
	title = {Comparative {Analysis} of {NLP} {Models} for {Automatic} {LOINC} {Document} {Ontology} {Named} {Entity} {Recognition} in {Clinical} {Note} {Titles}},
	volume = {329},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013326994&doi=10.3233%2FSHTI250944&partnerID=40&md5=1f8db405df3dc83d8eef1b9e31cbf3a0},
	doi = {10.3233/SHTI250944},
	abstract = {In order to utilize clinical notes for research studies, it is necessary to identify the most relevant notes. Mapping to the LOINC Document Ontology makes this process easier by reducing the variability of note types. We experimented with three models to automatically identify LOINC DO entities in VA note titles. The supervised BERT model performed best, but the open-source large language models (LLMs) performed well despite a lack of fine-tuning. Future work will aim to improve note classification by including additional note metadata and contents, hybridizing with rule-based approaches, testing fine-tuned LLMs, and mapping to exact LOINC codes. This record is sourced from MEDLINE/PubMed, a database of the U.S. National Library of Medicine},
	journal = {Studies in Health Technology and Informatics},
	author = {Bowles, Annie E. and Gan, Qiwei and Hanchrow, Elizabeth E. and DuVall, Scott L. and Alba, Patrick R. and Shi, Jianlin},
	year = {2025},
	note = {Section: 0},
	keywords = {natural language processing, Natural Language Processing, classification, electronic health record, Electronic Health Records, procedures, comparative study, Automated, automated pattern recognition, Logical Observation Identifiers Names and Codes, Pattern Recognition},
	pages = {769 -- 773},
	annote = {Type: Article}
}

@InProceedings{brank2005SurveyOntologyEvaluation,
	file = {References/pdf/brank2005SurveyOntologyEvaluation.pdf},
	title = {A survey of ontology evaluation techniques},
	author = {Brank, Janez and Grobelnik, Marko and Mladenic, Dunja},
	booktitle = {Proceedings of the conference on data mining and data warehouses (SiKDD 2005)},
	pages = {166--170},
	year = {2005}
}

@article{buehler2024AcceleratingScientificDiscovery,
	file = {References/pdf/buehler2024AcceleratingScientificDiscovery.pdf},
	title = {Accelerating scientific discovery with generative knowledge extraction, graph-based representation, and multimodal intelligent graph reasoning},
	volume = {5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206499137&doi=10.1088%2F2632-2153%2Fad7228&partnerID=40&md5=21a0937dc10d125ed87c7888c5c0d635},
	doi = {10.1088/2632-2153/ad7228},
	abstract = {Leveraging generative Artificial Intelligence (AI), we have transformed a dataset comprising 1000 scientific papers focused on biological materials into a comprehensive ontological knowledge graph. Through an in-depth structural analysis of this graph, we have calculated node degrees, identified communities along with their connectivities, and evaluated clustering coefficients and betweenness centrality of pivotal nodes, uncovering fascinating knowledge architectures. We find that the graph has an inherently scale-free nature, shows a high level of connectedness, and can be used as a rich source for downstream graph reasoning by taking advantage of transitive and isomorphic properties to reveal insights into unprecedented interdisciplinary relationships that can be used to answer queries, identify gaps in knowledge, propose never-before-seen material designs, and predict material behaviors. Using a large language embedding model we compute deep node representations and use combinatorial node similarity ranking to develop a path sampling strategy that allows us to link dissimilar concepts that have previously not been related. One comparison revealed detailed structural parallels between biological materials and Beethoven’s 9th Symphony, highlighting shared patterns of complexity through isomorphic mapping. In another example, the algorithm proposed an innovative hierarchical mycelium-based composite based on integrating path sampling with principles extracted from Kandinsky’s ‘Composition VII’ painting. The resulting material integrates an innovative set of concepts that include a balance of chaos and order, adjustable porosity, mechanical strength, and complex patterned chemical functionalization. We uncover other isomorphisms across science, technology and art, revealing a nuanced ontology of immanence that reveal a context-dependent heterarchical interplay of constituents. Because our method transcends established disciplinary boundaries through diverse data modalities (graphs, images, text, numerical data, etc), graph-based generative AI achieves a far higher degree of novelty, explorative capacity, and technical detail, than conventional approaches and establishes a widely useful framework for innovation by revealing hidden connections. © 2024 Elsevier B.V., All rights reserved.},
	number = {3},
	journal = {Machine Learning: Science and Technology},
	author = {Buehler, Markus J.},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graph, Ontology, Natural language processing, Language model, Knowledge extraction, Generative artificial intelligence, Scientific discovery, Language processing, Biomaterials, Natural languages, Generative adversarial networks, Biological materials, Chaos theory, Crystalline materials, Material Informatics, Material science, Path sampling},
	annote = {Type: Article}
}

@article{buitelaar2005OntologyLearningText,
	file = {References/pdf/buitelaar2005OntologyLearningText.pdf},
	title = {Ontology learning from text: An overview},
	author = {Buitelaar, Paul and Cimiano, Philipp and Magnini, Bernardo},
	journal = {Ontology learning from text: Methods, evaluation and applications},
	volume = {123},
	pages = {3--12},
	year = {2005},
	publisher = {IOS press Amsterdam}
}

@article{cappelli2025MethodologicalExplorationOntology,
	file = {References/pdf/cappelli2025MethodologicalExplorationOntology.pdf},
	title = {Methodological {Exploration} of {Ontology} {Generation} with a {Dedicated} {Large} {Language} {Model}},
	volume = {14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011611837&doi=10.3390%2Felectronics14142863&partnerID=40&md5=bba003bc82fccbcb202e71d79931bc06},
	doi = {10.3390/electronics14142863},
	abstract = {Ontologies are essential tools for representing, organizing, and sharing knowledge across various domains. This study presents a methodology for ontology construction supported by large language models (LLMs), with an initial application in the automotive sector. Specifically, a user preference ontology for adaptive interfaces in autonomous machines was developed using ChatGPT-4o. Based on this case study, the results were generalized into a reusable methodology. The proposed workflow integrates classical ontology engineering methodologies with the generative and analytical capabilities of LLMs. Each phase follows well-established steps: domain definition, term elicitation, class hierarchy construction, property specification, formalization, population, and validation. A key innovation of this approach is the use of a guiding table that translates domain knowledge into structured prompts, ensuring consistency across iterative interactions with the LLM. Human experts play a continuous role throughout the process, refining definitions, resolving ambiguities, and validating outputs. The ontology was evaluated in terms of logical consistency, structural properties, semantic accuracy, and inferential completeness, confirming its correctness and coherence. Additional validation through SPARQL queries demonstrated its reasoning capabilities. This methodology is generalizable to other domains, if domain experts adapt the guiding table to the specific context. Despite the support provided by LLMs, domain expertise remains essential to guarantee conceptual rigor and practical relevance. © 2025 Elsevier B.V., All rights reserved.},
	number = {14},
	journal = {Electronics (Switzerland)},
	author = {Cappelli, Maria Assunta and Di Marzo Serugendo, Giovanna},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Semantics, Generative AI, Knowledge representation, Knowledge management, Ontology development, Automotive industry, Query processing, Autonomous vehicles, Human-in-the-loop, Evaluation metrics, Iterative methods, Domain Knowledge, Ontology's, Knowledge-representation, Ontology evaluations, Adaptive interface, Automotive domains, Autonomous car, Computer software reusability, Ontology evaluation metric},
	annote = {Type: Article}
}

@article{capshaw2024LintextVisualTool,
	file = {References/pdf/capshaw2024LintextVisualTool.pdf},
	title = {{LINTEXT}: {A} {Visual} {Tool} for {Exploring} and {Modeling} {Knowledge} in {Text} {Documents}},
	volume = {3967},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006925553&partnerID=40&md5=8445ff346393a09f7d1bd79907c48606},
	abstract = {A large part of knowledge is commonly encoded into text documents. While extracting this information into a Knowledge Graph (KG) is a common approach, it suffers from challenges when texts are added, removed, or changed, or when the schema of the intended KG changes. Instead we advocate an approach where text and models evolve together in an interactive manner. We present LINTEXT, a system accompanying a published method which allows users to jointly explore and model the information held within text documents. The modeling is accomplished by specifying fill-in-the-blank prompts along with some metadata which are then recorded as specifications for simple relations that can be used to generate an ontology. The exploration aspect is accomplished by having the system complete each prompt with entities identified from the text and presenting the completions as a ranked list to the user, allowing users to verify the quality of the extracted triples. By elevating the development of the ontology to a visual and interactive level, it has an immediate text connection and users can be more certain that the documents they wish to model contain the information they wish to extract or query. Additionally, our system is designed to support the development of relation extraction (RE) pipelines underlying the document analysis, with a particular focus on supporting methods for improving vector representations of the extracted entities. To this end, users can choose to analyze documents from pre-annotated RE data sets to understand how changes in different elements of the pipeline affect the results. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Capshaw, Riley and Blomqvist, Eva},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Language model, Relation extraction, Embeddings, Knowledge model, Entity embedding, Masked language model, Document-level relation extraction, Machine reading, Interactive knowledge modeling},
	annote = {Type: Conference paper}
}

@article{capshaw2025ContextualizingEntityRepresentations,
	file = {References/pdf/capshaw2025ContextualizingEntityRepresentations.pdf},
	title = {Contextualizing {Entity} {Representations} for {Zero}-{Shot} {Relation} {Extraction} with {Masked} {Language} {Models}},
	volume = {15370},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210848015&doi=10.1007%2F978-3-031-77792-9_24&partnerID=40&md5=45282001afe6225ccaee18bde89df536},
	doi = {10.1007/978-3-031-77792-9_24},
	abstract = {Knowledge graphs (KGs) and their related ontologies constitute a key component in modern knowledge-based systems. However, hand-crafting these is not scalable, particularly due to the rate at which knowledge changes in many real-world applications. Partially automating the process of extracting and even modelling knowledge has therefore been a subject of research for many years. Nevertheless, accurate and reliable KG construction from natural language documents still remains a difficult task with many challenges, even in light of the impressive recent advances in language modelling. This paper focuses on one of those challenges, namely the extraction of accurate entity representations from text documents in order to facilitate relation extraction (RE). We present a novel method for generating document-contextualized input representations for entities using a masked language model (MLM) without the need for any sort of fine-tuning. These representations are then used as inputs to the same MLM that generated them, alleviating the need to include entire documents when prompting. Our results show that these representations 1) improve the ability of the MLMs BERT and RoBERTa to identify statements that represent correct relations between two entities; and 2) allow BERT to perform on par with the fine-tuned MLMs BioBERT and PubMedBERT. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Capshaw, Riley and Blomqvist, Eva},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Relation extraction, Modeling languages, Knowledge-based systems, Embeddings, Graph embeddings, Entity embedding, Ontology's, Natural language processing systems, Masked language model, Document-level relation extraction, Machine reading},
	pages = {399 -- 415},
	annote = {Type: Conference paper}
}

@article{carta2024TowardsZeroShot,
	file = {References/pdf/carta2024TowardsZeroShot.pdf},
	series = {{UMAP} {Adjunct} '24},
	title = {Towards {Zero}-shot {Knowledge} {Graph} building: {Automated} {Schema} {Inference}},
	url = {https://doi.org/10.1145/3631700.3665234},
	doi = {10.1145/3631700.3665234},
	abstract = {In the current Digital Transformation scenario, Knowledge Graphs are essential for comprehending, representing, and exploiting complex information in a structured form. The main paradigm in automatically generating proper Knowledge Graphs relies on predefined schemas or ontologies. Such schemas are typically manually constructed, requiring an intensive human effort, and are often sensitive to information loss due to negligence, incomplete analysis, or human subjectivity or inclination. Limiting human bias and the resulting information loss in creating proper Knowledge Graphs is paramount, particularly for user modeling in various sectors, such as education or healthcare. To this end, we propose a novel approach to automatically generating a proper entity schema. The devised methodology combines the language understanding capabilities of LLM with classical machine learning methods such as clustering to properly build an entity schema from a set of documents. This solution eliminates the need for human intervention and fosters a more efficient and comprehensive knowledge representation. The assessment of our proposal concerns adopting a state-of-the-art entity extraction model (UniNER) to estimate the relevance of the extracted entities based on the generated schema. Results confirm the potential of our approach, as we observed a negligible difference between the topic similarity score obtained with the ground truth and with the automatically generated schema (less than 1\% on average on three different datasets). Such an outcome confirms that the proposed approach may be valuable in automatically creating an entity schema from a set of documents.},
	journal = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
	author = {Carta, Salvatore and Giuliani, Alessandro and Manca, Marco Manolo and Piano, Leonardo and Tiddia, Sandro Gabriele},
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Knowledge graphs, Large Language Models, Knowledge graph, Large language model, Ontology, Language model, Ontology learning, Named entity recognition, Semantics, User profile, Digital transformation, Ontology Learning, Named Entity Recognition, Zero-shot learning, Learning systems, 'current, Complex information, Schema inference, Information loss},
	pages = {467--473},
	annote = {event-place: Cagliari, Italy}
}

@Article{casey2017AdvancingCoordinatedCyber,
	file = {References/pdf/casey2017AdvancingCoordinatedCyber.pdf},
	author = {Eoghan Casey and Sean Barnum and Ryan Griffith and
                  Jonathan Snyder and Harm M. A. van Beek and Alex
                  Nelson},
	title = {Advancing coordinated cyber-investigations and tool
                  interoperability using a community developed
                  specification language},
	journal = {Digit. Investig.},
	year = 2017,
	volume = 22,
	pages = {14-45},
	doi = {10.1016/J.DIIN.2017.08.002},
	url = {https://doi.org/10.1016/j.diin.2017.08.002},
	timestamp = {Fri, 07 Mar 2025 20:53:42 +0100},
	biburl = {https://dblp.org/rec/journals/di/CaseyBGSBN17.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InBook{casey2018EvolutionExpressingExchanging,
	file = {References/pdf/casey2018EvolutionExpressingExchanging.pdf},
	title = {The Evolution of Expressing and Exchanging
                  Cyber-Investigation Information in a Standardized
                  Form},
	year = 2018,
	author = {Casey, Eoghan and Barnum, Sean and Griffith, Ryan
                  and Snyder, Jonathan and van Beek, Harm and Nelson,
                  Alex},
	booktitle = {Handling and Exchanging Electronic Evidence Across
                  Europe},
	publisher = {Springer International Publishing},
	isbn = 9783319748726,
	pages = {43–58},
	doi = {10.1007/978-3-319-74872-6_4},
	url = {http://dx.doi.org/10.1007/978-3-319-74872-6_4},
	ISSN = {2352-1910}
}

@Article{caufield2024StructuredPromptInterrogation,
	file = {References/pdf/caufield2024StructuredPromptInterrogation.pdf},
	author = {J. Harry Caufield and Harshad Hegde and Vincent
                  Emonet and Nomi L. Harris and Marcin P. Joachimiak
                  and Nicolas Matentzoglu and Hyeongsik Kim and Sierra
                  A. T. Moxon and Justin T. Reese and Melissa
                  A. Haendel and Peter N. Robinson and Christopher
                  J. Mungall},
	title = {Structured Prompt Interrogation and Recursive
                  Extraction of Semantics {(SPIRES):} a method for
                  populating knowledge bases using zero-shot learning},
	journal = {Bioinform.},
	year = 2024,
	volume = 40,
	number = 3,
	doi = {10.1093/BIOINFORMATICS/BTAE104},
	url = {https://doi.org/10.1093/bioinformatics/btae104},
	timestamp = {Sun, 19 Jan 2025 13:43:13 +0100},
	biburl = {https://dblp.org/rec/journals/bioinformatics/CaufieldHEHJMKMRHRM24.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{cauter2024OntologyGuidedKnowledge,
	file = {References/pdf/cauter2024OntologyGuidedKnowledge.pdf},
	author = {Cauter, Zeno and Yakovets, Nikolay},
	title = {Ontology-guided Knowledge Graph Construction from
                  Maintenance Short Texts},
	year = 2024,
	booktitle = {Proceedings of the 1st Workshop on Knowledge Graphs
                  and Large Language Models (KaLLM 2024)},
	publisher = {Association for Computational Linguistics},
	pages = {75–84},
	doi = {10.18653/v1/2024.kallm-1.8},
	url = {http://dx.doi.org/10.18653/v1/2024.kallm-1.8}
}

@article{cauter2024OntologyGuidedKnowledgeb,
	file = {References/pdf/cauter2024OntologyGuidedKnowledge.pdf},
	title = {Ontology-guided {Knowledge} {Graph} {Construction} from {Maintenance} {Short} {Texts}},
	url = {https://aclanthology.org/2024.kallm-1.8/},
	doi = {10.18653/v1/2024.kallm-1.8},
	abstract = {Large-scale knowledge graph construction remains infeasible since it requires significant human-expert involvement. Further complications arise when building graphs from domain-specific data due to their unique vocabularies and associated contexts. In this work, we demonstrate the ability of open-source large language models (LLMs), such as Llama-2 and Llama-3, to extract facts from domain-specific Maintenance Short Texts (MSTs). We employ an approach which combines ontology-guided triplet extraction and in-context learning. By using only 20 semantically similar examples with the Llama-3-70B-Instruct model, we achieve performance comparable to previous methods that relied on fine-tuning techniques like SpERT and REBEL. This indicates that domain-specific fact extraction can be accomplished through inference alone, requiring minimal labeled data. This opens up possibilities for effective and efficient semi-automated knowledge graph construction for domain-specific data.},
	journal = {Proceedings of the 1st Workshop on Knowledge Graphs and Large Language Models (KaLLM 2024)},
	author = {van Cauter, Zeno and Yakovets, Nikolay},
	editor = {Biswas, Russa and Kaffee, Lucie-Aimée and Agarwal, Oshin and Minervini, Pasquale and Singh, Sameer and de Melo, Gerard},
	month = aug,
	year = {2024},
	note = {Place: Bangkok, Thailand
Publisher: Association for Computational Linguistics
Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Semantics, Computational linguistics, Adversarial machine learning, Graph construction, Domain Knowledge, Ontology's, In contexts, Contrastive Learning, Large-scales, Domain specific, Human expert, Open-source, Short texts},
	pages = {75--84},
	annote = {Type: Conference paper}
}

@Online{chalmers2023CouldLargeLanguage,
	file = {References/pdf/chalmers2023CouldLargeLanguage.pdf},
	author = {David J. Chalmers},
	title = {{Could a Large Language Model be Conscious?}},
	year = 2023,
	eprint = {2303.07103v3},
	primaryclass = {cs.AI},
	archiveprefix = {arXiv}
}

@Article{chen2023ContextualSemanticEmbeddings,
	file = {References/pdf/chen2023ContextualSemanticEmbeddings.pdf},
	author = {Jiaoyan Chen and Yuan He and Yuxia Geng and Ernesto
                  Jim{\'{e}}nez{-}Ruiz and Hang Dong and Ian Horrocks},
	title = {Contextual semantic embeddings for ontology
                  subsumption prediction},
	journal = {World Wide Web {(WWW)}},
	year = 2023,
	volume = 26,
	number = 5,
	pages = {2569-2591},
	doi = {10.1007/S11280-023-01169-9},
	url = {https://doi.org/10.1007/s11280-023-01169-9},
	timestamp = {Tue, 14 Oct 2025 19:49:45 +0200},
	biburl = {https://dblp.org/rec/journals/www/ChenHGJDH23.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{chen2023OpalOntologyAware,
	file = {References/pdf/chen2023OpalOntologyAware.pdf},
	title = {{OPAL}: {Ontology}-{Aware} {Pretrained} {Language} {Model} for {End}-to-{End} {Task}-{Oriented} {Dialogue}},
	volume = {11},
	url = {https://aclanthology.org/2023.tacl-1.5/},
	doi = {10.1162/tacl_a_00534},
	abstract = {This paper presents an ontology-aware pretrained language model (OPAL) for end-to-end task-oriented dialogue (TOD). Unlike chit-chat dialogue models, task-oriented dialogue models fulfill at least two task-specific modules: Dialogue state tracker (DST) and response generator (RG). The dialogue state consists of the domain-slot-value triples, which are regarded as the user's constraints to search the domain-related databases. The large-scale task-oriented dialogue data with the annotated structured dialogue state usually are inaccessible. It prevents the development of the pretrained language model for the task-oriented dialogue. We propose a simple yet effective pretraining method to alleviate this problem, which consists of two pretraining phases. The first phase is to pretrain on large-scale contextual text data, where the structured information of the text is extracted by the information extracting tool. To bridge the gap between the pretraining method and downstream tasks, we design two pretraining tasks: ontology-like triple recovery and next-text generation, which simulates the DST and RG, respectively. The second phase is to fine-tune the pretrained model on the TOD data. The experimental results show that our proposed method achieves an exciting boost and obtains competitive performance even without any TOD data on CamRest676 and MultiWOZ benchmarks.},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Chen, Zhi and Liu, Yuncong and Chen, Lu and Zhu, Su and Wu, Mengyue and Yu, Kai},
	year = {2023},
	note = {Section: 0},
	keywords = {Ontology, Language model, Pre-training, Benchmarking, Computational linguistics, Bridges, Ontology's, Large-scales, Simple++, Task-oriented, Dialogue models, End-to-end task, Modeling task, Task-specific modules},
	pages = {68--84},
	annote = {Place: Cambridge, MA Publisher: MIT Press}
}

@article{chen2024ExtractingStructureInformation,
	file = {References/pdf/chen2024ExtractingStructureInformation.pdf},
	title = {Extracting {Structure} {Information} from {Narrative} {Medical} {Reports} based on {LLMs}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217280093&doi=10.1109%2FBIBM62325.2024.10822688&partnerID=40&md5=2ef76c9f7b1b72efc12493a0c6955074},
	doi = {10.1109/BIBM62325.2024.10822688},
	abstract = {Extracting structured information and key details from medical report narratives is crucial to support healthcare data management, analysis and decision-making. However, the specialized nature of the reports, the complexity of the contents, and the high accuracy requirements of the results pose significant challenges to the structuring task. In this paper, we develop an LLM-based method to extract structure information from medical report narratives. Defining the structuring problem as mapping the narrative reports to the domain ontology, we design a framework to develop specialized LLMs that automatically learn and establish the mappings. At the core of this framework are report partitioning and interactive training data generation modules are. By separating complete reports into logically independent segments and training the LLMs on these segments independently, the trained LLMs can accurately capture the semantic relationships within each segment. Additionally, we explore different LLMs and formulate a simplistic scoring method to compare their accuracy, enabling us to select the best-performing model. Experimental evaluation on a real-world breast ultrasound report dataset demonstrates that our method achieves high accuracy with a small training dataset (400 samples). Specifically, the accuracy of structural information extraction and the attribute-value matching accuracy both exceed 96\%.},
	journal = {2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
	author = {Chen, Dehua and Shen, Zijian and Wang, Mei and Dong, Na and Pan, Qiao and Su, Jianwen},
	month = dec,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Large language model, Ontology, Language model, Large language models, Semantics, Information retrieval, Data mining, Standards, Training, Accuracy, Training data, Medical services, Medical examination reports, Report structuring, Ultrasonic imaging, Data accuracy, High-accuracy, Structured information, Data decision, Management analysis, Management decisions, Medical examination report, Structure information},
	pages = {5616--5623},
	annote = {ISSN: 2156-1133}
}

@article{chen2024OntologyTextAlignment,
	file = {References/pdf/chen2024OntologyTextAlignment.pdf},
	title = {Ontology {Text} {Alignment}: {Aligning} {Textual} {Content} to {Terminological} {Axioms}},
	volume = {392},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213316349&doi=10.3233%2FFAIA240639&partnerID=40&md5=2c1c97aa38f8bdd7b3fb3b8b1d142d78},
	doi = {10.3233/FAIA240639},
	abstract = {Despite the impressive advancements in Large Language Models (LLMs), their ability to perform reasoning and provide explainable outcomes remains a challenge, underscoring the continued relevance of ontologies in certain areas, particularly due to the reasoning and validation capabilities of ontologies. Ontology modelling and semantic search, due to their inherent complexity, still demand considerable human effort and expertise. Addressing this gap, our paper introduces the problem of ontology text alignment, which involves finding the most relevant axioms with respect to the given reference text. We propose an advanced Retrieval Augmented Generation framework that leverages BERT models and generative LLMs, together with ontology semantic enhancement based on atomic decomposition. Additionally, we have developed benchmarks in geology and biomedical areas. Our evaluation demonstrates the positive impact of our framework. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Frontiers in Artificial Intelligence and Applications},
	author = {Chen, Jieying and Dong, Hang and Chen, Jiaoyan and Horrocks, Ian},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology, Ontology model, Language model, Semantics, Semantic search, Benchmarking, Ontology's, Ontology semantics, Validation capability, Model search, Reasoning capabilities, Text alignments, Textual content},
	pages = {1389 -- 1396},
	annote = {Type: Conference paper}
}

@article{chen2024OptimizingAutomatedCompliance,
	file = {References/pdf/chen2024OptimizingAutomatedCompliance.pdf},
	title = {Optimizing automated compliance checking with ontology-enhanced natural language processing: {Case} in the fire safety domain},
	volume = {371},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208974479&doi=10.1016%2Fj.jenvman.2024.123320&partnerID=40&md5=566f7641e4047b28f4e4b1a1b9c5439d},
	doi = {10.1016/j.jenvman.2024.123320},
	abstract = {The fire safety compliance checking (FSCC) plays a crucial role in ensuring the quality of fire engineering design and eliminating inherent fire hazards. It requires an objective and rational interpretation of fire regulations. However, the texts of fire regulations are filled with numerous rules related to spatial limitations, which pose a significant challenge in interpreting them. The current method of interpreting these rules mostly relies on manual translation, which is not efficient. To address this issue, this study proposes an innovative automated framework for interpreting rules by combining ontology technology with natural language processing (NLP). Through the utilization of pre-trained language models (PLMs), concepts and relationships are extracted from sentences, a domain-specific ontology is established, spatial knowledge is transformed into language-agnostic tree structures based on the ontology, and the semantic components of spatial relationships are extracted. The tree structure is then mapped to logical clauses based on semantic consistency, thereby improving the efficiency of interpretation. Experimental results demonstrate that the architecture achieves an F1 score of 86.27 for entity extraction and 81.81 for spatial relationship joint extraction tasks, with an accuracy of 96.26\% in the formalization of logical rules, highlighting its proficiency in automatically interpreting fire spatial rules. This study offers technical support to enhance public understanding of fire safety management and fire prevention predictions, thereby promoting the intelligent management of the building safety environment. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Journal of Environmental Management},
	author = {Chen, Yian and Jiang, Huixian},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology, Language model, Named entity recognition, Ontology automatic construction, Pre-trained language model, Relationship extraction, Rule interpretation, Semantics, natural language processing, ontology, diagnosis, Natural Language Processing, Automated compliance checking, knowledge, prediction, language model, human, optimization, language, compliance, extraction method, article, Ontology's, Natural language processing systems, Fire hazards, Fires, clinical article, Agnostic, Automatic construction, compliance (physical), design method, fire, Fire extinguishers, fire protection, Fireproofing},
	annote = {Type: Article {\textbar} RAYYAN-LABELS: ontology-supported application}
}

@article{chen2024TowardControllableGenerative,
	file = {References/pdf/chen2024TowardControllableGenerative.pdf},
	title = {Toward {Controllable} {Generative} {Design}: {A} {Conceptual} {Design} {Generation} {Approach} {Leveraging} the {Function}-{Behavior}-{Structure} {Ontology} and {Large} {Language} {Models}},
	volume = {146},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199391540&doi=10.1115%2F1.4065562&partnerID=40&md5=bda3860dd2a3fca92a8532621c58deba},
	doi = {10.1115/1.4065562},
	abstract = {Recent research in the field of design engineering is primarily focusing on using AI technologies such as Large Language Models (LLMs) to assist early-stage design. The engineer or designer can use LLMs to explore, validate, and compare thousands of generated conceptual stimuli and make final choices. This was seen as a significant stride in advancing the status of the generative approach in computer-aided design. However, it is often difficult to instruct LLMs to obtain novel conceptual solutions and requirement-compliant in real design tasks, due to the lack of transparency and insufficient controllability of LLMs. This study presents an approach to leverage LLMs to infer Function-Behavior-Structure (FBS) ontology for high-quality design concepts. Prompting design based on the FBS model decomposes the design task into three sub-tasks including functional, behavioral, and structural reasoning. In each sub-task, prompting templates and specification signifiers are specified to guide the LLMs to generate concepts. User can determine the selected concepts by judging and evaluating the generated function-structure pairs. A comparative experiment has been conducted to evaluate the concept generation approach. According to the concept evaluation results, our approach achieves the highest scores in concept evaluation, and the generated concepts are more novel, useful, functional, and low cost compared to the baseline. © 2024 Elsevier B.V., All rights reserved.},
	number = {12},
	journal = {Journal of Mechanical Design},
	author = {Chen, Liuqing and Zuo, Haoyu and Cai, Zebin and Yin, Yuan and Zhang, Yuan and Sun, Lingyun and Childs, Peter R.N.},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Machine learning, Conceptual design, Computer aided design, Computational linguistics, Generative design, Structural design, Architectural design, Machine-learning, Concept generation, Creativity and concept generation, Design tasks, Function evaluation, Function-behavior-structure model, Function-Behaviour-Structure ontologies, Subtask},
	annote = {Type: Article}
}

@article{chepurova2024PromptMeOne,
	file = {References/pdf/chepurova2024PromptMeOne.pdf},
	title = {Prompt {Me} {One} {More} {Time}: {A} {Two}-{Step} {Knowledge} {Extraction} {Pipeline} with {Ontology}-{Based} {Verification}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200615475&partnerID=40&md5=0c13b89310c5035073d1803f66af5f52},
	abstract = {This study explores a method for extending real-world knowledge graphs (specifically, Wikidata) by extracting triplets from texts with the aid of Large Language Models (LLMs). We propose a two-step pipeline that includes the initial extraction of entity candidates, followed by their refinement and linkage to the canonical entities and relations of the knowledge graph. Finally, we utilize Wikidata relation constraints to select only verified triplets. We compare our approach to a model that was fine-tuned on a machine-generated dataset and demonstrate that it performs better on natural data. Our results suggest that LLM-based triplet extraction from texts, with subsequent verification, is a viable method for real-world applications. © 2024 Elsevier B.V., All rights reserved.},
	author = {Chepurova, Alla and Kuratov, Yuri M. and Bulatov, Aydar and Burtsev, Mikhail S.},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Knowledge extraction, Ontology-based, Computational linguistics, Model-based OPC, Real-world, World knowledge},
	pages = {61 -- 77},
	annote = {Type: Conference paper}
}

@article{chow2024SemanticSearchUsing,
	file = {References/pdf/chow2024SemanticSearchUsing.pdf},
	title = {Semantic {Search} {Using} {LLM}-{Aided} {Topic} {Generation} on {Knowledge} {Graphs} for {Paper} {Discovery}},
	doi = {10.1109/ISCSLP63861.2024.10800417},
	abstract = {The exponential growth of academic papers presents a huge challenge for researchers, exacerbating the already tedious literature review process. Current tools like Google Scholar and Connected Papers offer solutions for text-based and citation-based searches but fail to address the need for finding semantically similar yet terminologically different papers efficiently. This paper proposes an innovative approach to paper discovery using semantic search to create a knowledge graph of topics and papers. By generating a tree of topics using ChatGPT 4o and calculating semantic similarity with SciBERT, this method aims to uncover relevant papers overlooked by traditional citation-based searches. The solution, validated through quantitative evaluation, demonstrates the potential to improve the efficiency and comprehensiveness of paper discovery.},
	journal = {2024 IEEE 14th International Symposium on Chinese Spoken Language Processing (ISCSLP)},
	author = {Chow, Sabrina and Guo, Lilian and Chow, Jonathan and Chia, Chelsea and Li, Sarah and Huang, Dong-Yan},
	month = nov,
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge Graphs, Semantic search, Natural Language Processing (NLP), Semantic Search, Chatbots, Internet, Literature Review, Focusing, Rendering (computer graphics), Navigation, Bibliographies, SciBERT},
	pages = {353--357}
}

@article{chowdhury2025AutomatedFrameworkOntology,
	file = {References/pdf/chowdhury2025AutomatedFrameworkOntology.pdf},
	title = {An {Automated} {Framework} of {Ontology} {Generation} for {Abstract} {Concepts} {Using} {LLMs}},
	volume = {2435},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010069636&doi=10.1007%2F978-3-031-92178-0_14&partnerID=40&md5=798c765c413f4b8dbf5309e30c267d01},
	doi = {10.1007/978-3-031-92178-0_14},
	abstract = {This study introduces an automated framework for constructing ontologies of abstract concepts by integrating Large Language Models (LLMs) with semantic web technologies. The proposed system leverages advanced models, including ChatGPT-4, GPT-4, and Gemini-2.0 flash-exp, to extract entities and relationships from textual data, transforming them into structured ontologies represented in the Web Ontology Language (OWL). By adhering to semantic web standards, the framework ensures the creation of reusable, scalable, and interoperable ontologies that enable advanced applications. This methodology bridges the gap between unstructured data and structured cultural knowledge, enhancing the digital representation and understanding of cultural concepts. As a case study, the framework is applied to extract a cultural ontology from a Wikipedia page, demonstrating its effectiveness in converting unstructured textual data into structured knowledge. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Communications in Computer and Information Science},
	author = {Chowdhury, Rafi Rashid and Goto, Takaaki and Tsuchida, Kensei and Kirishima, Tadaaki and Bandi, Ajay},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Natural language processing, Language model, Knowledge management, OWL, RDF, Data mining, Textual data, Computational linguistics, Resource Description Framework (RDF), Language processing, Natural languages, Ontology's, Natural language processing systems, Computer software reusability, Abstract concept, Websites},
	pages = {170 -- 180},
	annote = {Type: Conference paper}
}

@article{christou2025ArtificialRelationshipsIn,
	file = {References/pdf/christou2025ArtificialRelationshipsIn.pdf},
	title = {Artificial {Relationships} in {Fiction}: {A} {Dataset} for {Advancing} {NLP} in {Literary} {Domains}},
	url = {https://aclanthology.org/2025.latechclfl-1.13/},
	doi = {10.18653/v1/2025.latechclfl-1.13},
	abstract = {Relation extraction (RE) in fiction presents unique NLP challenges due to implicit, narrative-driven relationships. Unlike factual texts, fiction weaves complex connections, yet existing RE datasets focus on non-fiction. To address this, we introduce Artificial Relationships in Fiction (ARF), a synthetically annotated dataset for literary RE. Built from diverse Project Gutenberg fiction, ARF considers author demographics, publication periods, and themes. We curated an ontology for fiction-specific entities and relations, and using GPT-4o, generated artificial relationships to capture narrative complexity. Our analysis demonstrates its value for finetuning RE models and advancing computational literary studies. By bridging a critical RE gap, ARF enables deeper exploration of fictional relationships, enriching NLP research at the intersection of storytelling and AI-driven literary analysis.},
	journal = {Proceedings of the 9th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature (LaTeCH-CLfL 2025)},
	author = {Christou, Despina and Tsoumakas, Grigorios},
	editor = {Kazantseva, Anna and Szpakowicz, Stan and Degaetano-Ortlieb, Stefania and Bizzoni, Yuri and Pagel, Janis},
	month = may,
	year = {2025},
	note = {Place: Albuquerque, New Mexico
Publisher: Association for Computational Linguistics
Section: 0},
	pages = {130--147}
}

@article{ciatto2025LargeLanguageModels,
	file = {References/pdf/ciatto2025LargeLanguageModels.pdf},
	title = {Large language models as oracles for instantiating ontologies with domain-specific knowledge},
	volume = {310},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214522484&doi=10.1016%2Fj.knosys.2024.112940&partnerID=40&md5=52807f55e1c4bc0586b3cb13347e8ed6},
	doi = {10.1016/j.knosys.2024.112940},
	abstract = {Background: Endowing intelligent systems with semantic data commonly requires designing and instantiating ontologies with domain-specific knowledge. Especially in the early phases, those activities are typically performed manually by human experts possibly leveraging on their own experience. The resulting process is therefore time-consuming, error-prone, and often biased by the personal background of the ontology designer. Objective: To mitigate that issue, we propose a novel domain-independent approach to automatically instantiate ontologies with domain-specific knowledge, by leveraging on large language models (LLMs) as oracles. Methods: Starting from (i) an initial schema composed by inter-related classes and properties and (ii) a set of query templates, our method queries the LLM multiple times, and generates instances for both classes and properties from its replies. Thus, the ontology is automatically filled with domain-specific knowledge, compliant to the initial schema. As a result, the ontology is quickly and automatically enriched with manifold instances, which experts may consider to keep, adjust, discard, or complement according to their own needs and expertise. Contribution: We formalise our method in general way and instantiate it over various LLMs, as well as on a concrete case study. We report experiments rooted in the nutritional domain where an ontology of food meals and their ingredients is automatically instantiated from scratch, starting from a categorisation of meals and their relationships. There, we analyse the quality of the generated ontologies and compare ontologies attained by exploiting different LLMs. Experimentally, our approach achieves a quality metric that is up to five times higher than the state-of-the-art, while reducing erroneous entities and relations by up to ten times. Finally, we provide a SWOT analysis of the proposed method. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Knowledge-Based Systems},
	author = {Ciatto, Giovanni and Agiollo, Andrea and Magnini, Matteo and Omicini, Andrea},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Ontology Population, Language model, Domain-specific knowledge, Semantics, Modeling languages, Intelligent systems, Semantic data, Structured Query Language, Domain Knowledge, Ontology's, Property, Error prones, Human expert, Novel domain},
	annote = {Type: Article}
}

@InBook{cimiano2009OntologyLearning,
	file = {References/pdf/cimiano2009OntologyLearning.pdf},
	title = {Ontology Learning},
	year = 2009,
	author = {Cimiano, Philipp and Mädche, Alexander and Staab,
                  Steffen and Völker, Johanna},
	booktitle = {Handbook on Ontologies},
	publisher = {Springer Berlin Heidelberg},
	isbn = 9783540926733,
	pages = {245–267},
	doi = {10.1007/978-3-540-92673-3_11},
	url = {http://dx.doi.org/10.1007/978-3-540-92673-3_11}
}

@article{ciroku2024RevontReverseEngineering,
	file = {References/pdf/ciroku2024RevontReverseEngineering.pdf},
	title = {{RevOnt}: {Reverse} engineering of competency questions from knowledge graphs via language models},
	volume = {82},
	issn = {1570-8268},
	url = {https://www.sciencedirect.com/science/article/pii/S1570826824000088},
	doi = {https://doi.org/10.1016/j.websem.2024.100822},
	abstract = {The process of developing ontologies – a formal, explicit specification of a shared conceptualisation – is addressed by well-known methodologies. As for any engineering development, its fundamental basis is the collection of requirements, which includes the elicitation of competency questions. Competency questions are defined through interacting with domain and application experts or by investigating existing datasets that may be used to populate the ontology i.e. its knowledge graph. The rise in popularity and accessibility of knowledge graphs provides an opportunity to support this phase with automatic tools. In this work, we explore the possibility of extracting competency questions from a knowledge graph. This reverses the traditional workflow in which knowledge graphs are built from ontologies, which in turn are engineered from competency questions. We describe in detail RevOnt, an approach that extracts and abstracts triples from a knowledge graph, generates questions based on triple verbalisations, and filters the resulting questions to yield a meaningful set of competency questions; the WDV dataset. This approach is implemented utilising the Wikidata knowledge graph as a use case, and contributes a set of core competency questions from 20 domains present in the WDV dataset. To evaluate RevOnt, we contribute a new dataset of manually-annotated high-quality competency questions, and compare the extracted competency questions by calculating their BLEU score against the human references. The results for the abstraction and question generation components of the approach show good to high quality. Meanwhile, the accuracy of the filtering component is above 86\%, which is comparable to the state-of-the-art classifications.},
	journal = {Journal of Web Semantics},
	author = {Ciroku, Fiorela and Berardinis, Jacopo de and Kim, Jongmo and Meroño-Peñuela, Albert and Presutti, Valentina and Simperl, Elena},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Ontology development, Knowledge engineering, Data mining, Competency question extraction, Extraction, Ontology's, Abstracting, High quality, Work-flows, And filters, Automatic tools, Engineering development, Filtration},
	pages = {100822},
	annote = {Type: Article}
}

@article{corey1998AveragingCorrelationsExpected,
	author = {David M. Corey and William P. Dunlap and Michael J. Burke},
	title = {Averaging Correlations: Expected Values and Bias in Combined Pearson rs and Fisher's z Transformations},
	journal = {The Journal of General Psychology},
	volume = {125},
	number = {3},
	pages = {245--261},
	year = {1998},
	publisher = {Routledge},
	doi = {10.1080/00221309809595548},
	URL = { 
    
        https://doi.org/10.1080/00221309809595548
    
    

},
	eprint = { 
    
        https://doi.org/10.1080/00221309809595548
    
    

},
	abstract = { R. A. Fisher's z (z'; 1958) essentially normalizes the sampling distribution of Pearson r and can thus be used to obtain an average correlation that is less affected by sampling distribution skew, suggesting a less biased statistic. Analytical formulae, however, indicate less expected bias in average r than in average z' back-converted to average rz'
. In large part because of this fact, J. E. Hunter and F. L. Schmidt (1990) have argued that average r is preferable to average rz'
. In the present study, bias in average r and average rz'
 was empirically examined. When correlations from a matrix were averaged, the use of z' decreased bias. For independent correlations, contrary to analytical expectations, average rz'
 was also generally the less biased statistic. It is concluded that (a) average rz'
 is a less biased estimate of the population correlation than average r and (b) expected values formulae do not adequately predict bias in average rz'
 when a small number of correlations are averaged. }
}

@article{crum2024EnrichingOntologiesWith,
	file = {References/pdf/crum2024EnrichingOntologiesWith.pdf},
	title = {Enriching {Ontologies} with {Disjointness} {Axioms} using {Large} {Language} {Models}},
	volume = {3853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212711225&partnerID=40&md5=8e4efddbdf745c0480df90e78e4b6d2b},
	abstract = {Ontologies often lack explicit disjointness declarations between classes, despite their usefulness for sophisticated reasoning and consistency checking in Knowledge Graphs. In this study, we explore the potential of Large Language Models (LLMs) to enrich ontologies by identifying and asserting class disjointness axioms. Our approach aims at leveraging the implicit knowledge embedded in LLMs, using prompt engineering to elicit this knowledge for classifying ontological disjointness. We validate our methodology on the DBpedia ontology, focusing on open-source LLMs. Our findings suggest that LLMs, when guided by effective prompt strategies, can reliably identify disjoint class relationships, thus streamlining the process of ontology completion without extensive manual input. For comprehensive disjointness enrichment, we propose a process that takes logical relationships between disjointness and subclass statements into account in order to maintain satisfiability and reduce the number of calls to the LLM. This work provides a foundation for future applications of LLMs in automated ontology enhancement and offers insights into optimizing LLM performance through strategic prompt design. Our code is publicly available on GitHub at https://github.com/n28div/llm-disjointness. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Crum, Elias and De Santis, Antonio and Ovide, Manon and Pan, Jiaxin and Pisu, Alessia and Lazzari, Nicolas and Rudolph, Sebastian},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Ontology enrichment, Consistency checking, Ontology's, Contrastive Learning, Dbpedia, Disjointness, Disjointness learning, Implicit knowledge},
	annote = {Type: Conference paper}
}

@article{davies1979ClusterSeparationMeasure,
	author = {Davies, David L. and Bouldin, Donald W.},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	title = {A Cluster Separation Measure},
	year = {1979},
	volume = {PAMI-1},
	number = {2},
	pages = {224-227},
	keywords = {Dispersion;Density measurement;Algorithm design and analysis;Clustering algorithms;Partitioning algorithms;Multidimensional systems;Data analysis;Performance analysis;Humans;Missiles;Cluster;data partitions;multidimensional data analysis;parametric clustering;partitions;similarity measure},
	doi = {10.1109/TPAMI.1979.4766909}
}

@Article{deepseekai2024DeepseekV3Technical,
	file = {References/pdf/deepseekai2024DeepseekV3Technical.pdf},
	author = {DeepSeek{-}AI and Aixin Liu and Bei Feng and Bing
                  Xue and Bingxuan Wang and Bochao Wu and Chengda Lu
                  and Chenggang Zhao and Chengqi Deng and Chenyu Zhang
                  and Chong Ruan and Damai Dai and Daya Guo and Dejian
                  Yang and Deli Chen and Dongjie Ji and Erhang Li and
                  Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo
                  Hao and Guanting Chen and Guowei Li and H. Zhang and
                  Han Bao and Hanwei Xu and Haocheng Wang and Haowei
                  Zhang and Honghui Ding and Huajian Xin and Huazuo
                  Gao and Hui Li and Hui Qu and J. L. Cai and Jian
                  Liang and Jianzhong Guo and Jiaqi Ni and Jiashi Li
                  and Jiawei Wang and Jin Chen and Jingchang Chen and
                  Jingyang Yuan and Junjie Qiu and Junlong Li and
                  Junxiao Song and Kai Dong and Kai Hu and Kaige Gao
                  and Kang Guan and Kexin Huang and Kuai Yu and Lean
                  Wang and Lecong Zhang and Lei Xu and Leyi Xia and
                  Liang Zhao and Litong Wang and Liyue Zhang and Meng
                  Li and Miaojun Wang and Mingchuan Zhang and Minghua
                  Zhang and Minghui Tang and Mingming Li and Ning Tian
                  and Panpan Huang and Peiyi Wang and Peng Zhang and
                  Qiancheng Wang and Qihao Zhu and Qinyu Chen and
                  Qiushi Du and R. J. Chen and R. L. Jin and Ruiqi Ge
                  and Ruisong Zhang and Ruizhe Pan and Runji Wang and
                  Runxin Xu and Ruoyu Zhang and Ruyi Chen and S. S. Li
                  and Shanghao Lu and Shangyan Zhou and Shanhuang Chen
                  and Shaoqing Wu and Shengfeng Ye and Shirong Ma and
                  Shiyu Wang and Shuang Zhou and Shuiping Yu and
                  Shunfeng Zhou and Shuting Pan and T. Wang and Tao
                  Yun and Tian Pei and Tianyu Sun and W. L. Xiao and
                  Wangding Zeng},
	title = {DeepSeek-V3 Technical Report},
	journal = {CoRR},
	year = 2024,
	volume = {abs/2412.19437},
	doi = {10.48550/ARXIV.2412.19437},
	eprint = {2412.19437},
	eprinttype = {arXiv},
	url = {https://doi.org/10.48550/arXiv.2412.19437},
	timestamp = {Wed, 06 Aug 2025 13:38:20 +0200},
	biburl = {https://dblp.org/rec/journals/corr/abs-2412-19437.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@Article{deepseekai2025DeepseekR1Incentivizing,
	file = {References/pdf/deepseekai2025DeepseekR1Incentivizing.pdf},
	author = {DeepSeek{-}AI and Daya Guo and Dejian Yang and
                  Haowei Zhang and Junxiao Song and Ruoyu Zhang and
                  Runxin Xu and Qihao Zhu and Shirong Ma and Peiyi
                  Wang and Xiao Bi and Xiaokang Zhang and Xingkai Yu
                  and Yu Wu and Z. F. Wu and Zhibin Gou and Zhihong
                  Shao and Zhuoshu Li and Ziyi Gao and Aixin Liu and
                  Bing Xue and Bingxuan Wang and Bochao Wu and Bei
                  Feng and Chengda Lu and Chenggang Zhao and Chengqi
                  Deng and Chenyu Zhang and Chong Ruan and Damai Dai
                  and Deli Chen and Dongjie Ji and Erhang Li and
                  Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo
                  Hao and Guanting Chen and Guowei Li and H. Zhang and
                  Han Bao and Hanwei Xu and Haocheng Wang and Honghui
                  Ding and Huajian Xin and Huazuo Gao and Hui Qu and
                  Hui Li and Jianzhong Guo and Jiashi Li and Jiawei
                  Wang and Jingchang Chen and Jingyang Yuan and Junjie
                  Qiu and Junlong Li and J. L. Cai and Jiaqi Ni and
                  Jian Liang and Jin Chen and Kai Dong and Kai Hu and
                  Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu
                  and Lean Wang and Lecong Zhang and Liang Zhao and
                  Litong Wang and Liyue Zhang and Lei Xu and Leyi Xia
                  and Mingchuan Zhang and Minghua Zhang and Minghui
                  Tang and Meng Li and Miaojun Wang and Mingming Li
                  and Ning Tian and Panpan Huang and Peng Zhang and
                  Qiancheng Wang and Qinyu Chen and Qiushi Du and
                  Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji
                  Wang and R. J. Chen and R. L. Jin and Ruyi Chen and
                  Shanghao Lu and Shangyan Zhou and Shanhuang Chen and
                  Shengfeng Ye and Shiyu Wang and Shuiping Yu and
                  Shunfeng Zhou and Shuting Pan and S. S. Li},
	title = {DeepSeek-R1: Incentivizing Reasoning Capability in
                  LLMs via Reinforcement Learning},
	journal = {CoRR},
	year = 2025,
	volume = {abs/2501.12948},
	doi = {10.48550/ARXIV.2501.12948},
	eprint = {2501.12948},
	eprinttype = {arXiv},
	url = {https://doi.org/10.48550/arXiv.2501.12948},
	timestamp = {Wed, 06 Aug 2025 13:38:20 +0200},
	biburl = {https://dblp.org/rec/journals/corr/abs-2501-12948.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{dew2025DevelopingComprehensiveTask,
	file = {References/pdf/dew2025DevelopingComprehensiveTask.pdf},
	series = {{WWW} '25},
	title = {Developing a {Comprehensive} {Task} {Framework} for {Effective} {Workforce} {Analysis}},
	url = {https://doi.org/10.1145/3701716.3715172},
	doi = {10.1145/3701716.3715172},
	abstract = {Effective workforce analysis, planning, and management require a deep understanding of the tasks and skills associated with different roles. This paper introduces a novel methodology for developing a comprehensive task framework that leverages Large Language Models (LLMs) and large-scale job ads data. We first propose an innovative approach to task taxonomy design, which involves the decomposition and reconstruction of tasks into a hierarchical structure based on action-object pairings, systematically refined using LLMs. The methodology extends to integrating the taxonomy with occupation and skill linkages derived from job ads, ensuring alignment with real-world workforce dynamics. Finally, we demonstrate the practical value of this framework through a visual analytics system that enables interactive exploration and analysis of tasks, occupations, and associated skills, highlighting its potential to transform workforce analysis. Demo video: https://bit.ly/41txBZK},
	journal = {Companion Proceedings of the ACM on Web Conference 2025},
	author = {Dew, Rebecca and Li, Mingzhao and Liu, Weidong and Baratha Raj, Sandya},
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {large language model, visual analytics, gpt, workforce analysis},
	pages = {2819--2822},
	annote = {event-place: Sydney NSW, Australia}
}

@article{dimitrakopoulos2025EnhancedOntologyExtraction,
	file = {References/pdf/dimitrakopoulos2025EnhancedOntologyExtraction.pdf},
	series = {{WSC} '24},
	title = {Enhanced {Ontology} {Extraction}: {Integrating} {GPT} {AI} with {Human} {Knowledge} on the {Example} of {EU} {Standards} {Related} to {Semiconductor} {Supply} {Chains}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217617379&doi=10.1109%2FWSC63780.2024.10838760&partnerID=40&md5=8e67c6383c556395af5749406deb7bf3},
	doi = {10.1109/WSC63780.2024.10838760},
	abstract = {This paper addresses challenges in creating ontologies for the semiconductor supply chain. Ontologies are crucial for seamless data exchange within the semantic web, enabling initiatives like GAIA-X and CatenA-X. Traditionally, ontology creation is complex. Here, we propose a novel AI-assisted method using large language models (LLMs) like ChatGPT 4 Turbo to support human experts. This collaboration aims to expedite ontology generation while maintaining quality. While initial tests show promise, refining the human-AI interface for clear content generation remains a focus. By improving this collaboration, we expect to create more accurate and complete ontologies, fostering efficient information sharing and strengthening the meaningfulness of standards within the semiconductor supply chain.},
	journal = {Proceedings of the Winter Simulation Conference},
	author = {Dimitrakopoulos, George and Ehm, Hans and Tsaousi, Eleni},
	year = {2025},
	note = {Place: Orlando, Florida, USA
Publisher: IEEE Press
Section: 0},
	keywords = {Ontologies, Knowledge graphs, Ontology, Language model, Semantic Web, Semantics, Modeling languages, Reliability, Ontology generation, Standards, Collaboration, Accuracy, Chatbots, Ontology Extraction, Supply chains, Information sharing, Ontology's, Semantic-Web, Human knowledge, Human expert, Ontology creations, Semiconducting indium phosphide, Semiconductor supply chain, Web-enabling},
	pages = {1955--1965},
	annote = {Type: Conference paper}
}

@article{dina2025LargeLanguageModels,
	file = {References/pdf/dina2025LargeLanguageModels.pdf},
	title = {Large {Language} {Models} for {Automated} {Characterization} of {Cybersecurity} {Vulnerabilities} using {N}-{Shot} {Learning}},
	volume = {38},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007898507&doi=10.32473%2Fflairs.38.1.138858&partnerID=40&md5=48fad2183b3a68b68e563f3a6dbd030a},
	doi = {10.32473/flairs.38.1.138858},
	abstract = {The US National Vulnerability Database is a public repository of cybersecurity vulnerabilities in software and hardware. This repository is maintained by the National Institute of Standards and Technology (NIST) that developed a Vulnerability Description Ontology framework for characterizing vulnerabilities. Despite advancements in secure software development and vulnerability detection techniques, the number of registered cybersecurity vulnerabilities continues to grow. Characterizing vulnerabilities is essential for selecting effective protection mechanisms to prevent or mitigate cybersecurity vulnerabilities in software and hardware and reduce cyber risks. Manual characterization of vulnerabilities is both time-consuming and costly. While many researchers employ Machine Learning (ML)-based methods to predict characterizations, these methods heavily rely on large amounts of labeled training data. To overcome the challenge of limited labeled data, this paper proposes a solution utilizing three Large Language Models (LLMs) - GPT-4o, Llama-3.1-405B, and Gemini-1.5-flash - to automate the characterization of vulnerabilities across 27 categories, grouped into five noun groups. We use both few-shot and zero-shot learning to prompt the LLMs. Our experimental results show that GPT-4o achieves F1-scores of 80\%, 90\%, 90\%, and 73\% in the context, impact-method, attack theater, and logical impact noun groups, respectively, using a few labeled samples. Additionally, Llama achieves an F1-score of 83\% in the mitigation noun group. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Proceedings of the International Florida Artificial Intelligence Research Society Conference, FLAIRS},
	author = {Dina, Ayesha Siddiqua and Needham, Elijah and Ulybyshev, Denis},
	year = {2025},
	note = {Section: 0},
	keywords = {Language model, Cyber security, Cybersecurity, Computational linguistics, Zero-shot learning, Labeling, Learning systems, Ontology's, Labeled data, Network security, F1 scores, Hardware security, National Institute of Standards and Technology, National security, National vulnerability database, Public repositories, Secure software development, Software and hardwares, Vulnerability description},
	annote = {Type: Conference paper}
}

@article{dong2023OntologyEnrichmentTexts,
	file = {References/pdf/dong2023OntologyEnrichmentTexts.pdf},
	series = {{CIKM} '23},
	title = {Ontology {Enrichment} from {Texts}: {A} {Biomedical} {Dataset} for {Concept} {Discovery} and {Placement}},
	url = {https://doi.org/10.1145/3583780.3615126},
	doi = {10.1145/3583780.3615126},
	abstract = {Mentions of new concepts appear regularly in texts and require automated approaches to harvest and place them into Knowledge Bases (KB), e.g., ontologies and taxonomies. Existing datasets suffer from three issues, (i) mostly assuming that a new concept is pre-discovered and cannot support out-of-KB mention discovery; (ii) only using the concept label as the input along with the KB and thus lacking the contexts of a concept label; and (iii) mostly focusing on concept placement w.r.t a taxonomy of atomic concepts, instead of complex concepts, i.e., with logical operators. To address these issues, we propose a new benchmark, adapting MedMentions dataset (PubMed abstracts) with SNOMED CT versions in 2014 and 2017 under the Diseases sub-category and the broader categories of Clinical finding, Procedure, and Pharmaceutical / biologic product. We provide usage on the evaluation with the dataset for out-of-KB mention discovery and concept placement, adapting recent Large Language Model based methods.},
	journal = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
	author = {Dong, Hang and Chen, Jiaoyan and He, Yuan and Horrocks, Ian},
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Ontology, Language model, text mining, Ontology enrichment, Taxonomies, language models, SNOMED CT, Biomedical ontologies, biomedical ontologies, SNOMED-CT, Computational linguistics, Entity linking, ontology enrichment, entity linking, Text-mining, concept placement, Natural language processing systems, Concept discoveries, Concept placement, Automated approach, Knowledge taxonomies, Large dataset},
	pages = {5316--5320},
	annote = {event-place: Birmingham, United Kingdom}
}

@article{dong2024LanguageModelBased,
	file = {References/pdf/dong2024LanguageModelBased.pdf},
	title = {A {Language} {Model} {Based} {Framework} for {New} {Concept} {Placement} in {Ontologies}},
	volume = {14664},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194222248&doi=10.1007%2F978-3-031-60626-7_5&partnerID=40&md5=7646da39abb6a08ff3ab8c32975bb31e},
	doi = {10.1007/978-3-031-60626-7_5},
	abstract = {We investigate the task of inserting new concepts extracted from texts into an ontology using language models. We explore an approach with three steps: edge search which is to find a set of candidate locations to insert (i.e., subsumptions between concepts), edge formation and enrichment which leverages the ontological structure to produce and enhance the edge candidates, and edge selection which eventually locates the edge to be placed into. In all steps, we propose to leverage neural methods, where we apply embedding-based methods and contrastive learning with Pre-trained Language Models (PLMs) such as BERT for edge search, and adapt a BERT fine-tuning-based multi-label Edge-Cross-encoder, and Large Language Models (LLMs) such as GPT series, FLAN-T5, and Llama 2, for edge selection. We evaluate the methods on recent datasets created using the SNOMED CT ontology and the MedMentions entity linking benchmark. The best settings in our framework use fine-tuned PLM for search and a multi-label Cross-encoder for selection. Zero-shot prompting of LLMs is still not adequate for the task, and we propose explainable instruction tuning of LLMs for improved performance. Our study shows the advantages of PLMs and highlights the encouraging performance of LLMs that motivates future studies. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Dong, Hang and Chen, Jiaoyan and He, Yuan and Gao, Yongsheng and Horrocks, Ian},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Pre-trained language model, Ontology enrichment, SNOMED-CT, Computational linguistics, Zero-shot learning, Ontology's, Signal encoding, Concept placement, Edge searches, Edge selection},
	pages = {79 -- 99},
	annote = {Type: Conference paper}
}

@article{doumanas2024IntegratingLlmsIn,
	file = {References/pdf/doumanas2024IntegratingLlmsIn.pdf},
	title = {Integrating {LLMs} in the {Engineering} of a {SAR} {Ontology}},
	volume = {714},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197341155&doi=10.1007%2F978-3-031-63223-5_27&partnerID=40&md5=1c65f9035a3b5087fefbfddea2be3ff9},
	doi = {10.1007/978-3-031-63223-5_27},
	abstract = {In Search and Rescue (SAR) missions, the integration of multiple sources of information may enhance operational efficiency and increase responsiveness significantly, improving situation awareness and aiding decision-making to save lives and mitigate incident impact. Ontologies are crucial for integrating and reasoning with data from diverse sources. Engineering a domain ontology for SAR can be better supported from an agile, collaborative, and iterative ontology engineering methodology (OEM), incorporating the interests of several stakeholders. Large Language Models (LLMs) can play a significant role in completing OEM processes. The goal of this work is to identify how ontology engineering (OE) tasks can be completed with the collaboration of LLMs and humans. The objectives of this paper are, a) to present preliminary exploration of LLMs to generate domain ontologies for the modeling of SAR missions in wildfire incidents b) to propose and evaluate an LLM-enhanced OE approach. In overall, the main contribution of the work presented in this paper is the analysis of LLMs capabilities to ontology engineering, and the evaluation of the synergy between humans and machines to efficiently represent knowledge, with specific focus in the SAR domain. © 2024 Elsevier B.V., All rights reserved.},
	journal = {IFIP Advances in Information and Communication Technology},
	author = {Doumanas, Dimitrios and Soularidis, Andreas and Kotis, Konstantinos I. and Vouros, George A.},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, Domain ontologies, Decision making, Computational linguistics, Iterative methods, Ontology's, Search and rescue, Ontology Engineering Methodologies, Multiple source, Rescue missions, Search missions},
	pages = {360 -- 374},
	annote = {Type: Conference paper}
}

@article{doumanas2025FineTuningLarge,
	file = {References/pdf/doumanas2025FineTuningLarge.pdf},
	title = {Fine-{Tuning} {Large} {Language} {Models} for {Ontology} {Engineering}: {A} {Comparative} {Analysis} of {GPT}-4 and {Mistral}},
	volume = {15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218624656&doi=10.3390%2Fapp15042146&partnerID=40&md5=cd9c184dfaf18e7296ecdf2772a70ee0},
	doi = {10.3390/app15042146},
	abstract = {Ontology engineering (OE) plays a critical role in modeling and managing structured knowledge across various domains. This study examines the performance of fine-tuned large language models (LLMs), specifically GPT-4 and Mistral 7B, in efficiently automating OE tasks. Foundational OE textbooks are used as the basis for dataset creation and for feeding the LLMs. The methodology involved segmenting texts into manageable chapters, generating question–answer pairs, and translating visual elements into description logic to curate fine-tuned datasets in JSONL format. This research aims to enhance the models’ abilities to generate domain-specific ontologies, with hypotheses asserting that fine-tuned LLMs would outperform base models, and that domain-specific datasets would significantly improve their performance. Comparative experiments revealed that GPT-4 demonstrated superior accuracy and adherence to ontology syntax, albeit with higher computational costs. Conversely, Mistral 7B excelled in speed and cost efficiency but struggled with domain-specific tasks, often generating outputs that lacked syntactical precision and relevance. The presented results highlight the necessity of integrating domain-specific datasets to improve contextual understanding and practical utility in specialized applications, such as Search and Rescue (SAR) missions in wildfire incidents. Both models, despite their limitations, exhibited potential in understanding OE principles. However, their performance underscored the importance of aligning training data with domain-specific knowledge to emulate human expertise effectively. This study, based on and extending our previous work on the topic, concludes that fine-tuned LLMs with targeted datasets enhance their utility in OE, offering insights into improving future models for domain-specific applications. The findings advocate further exploration of hybrid solutions to balance accuracy and efficiency. © 2025 Elsevier B.V., All rights reserved.},
	number = {4},
	journal = {Applied Sciences (Switzerland)},
	author = {Doumanas, Dimitrios and Soularidis, Andreas and Spiliotopoulos, Dimitris and Vassilakis, Costas and Kotis, Konstantinos I.},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology engineering, Ontology, Language model, Domain-specific knowledge, Performance, Syntactics, Domain Knowledge, Domain specific, Fine tuning, Large language model fine-tuning, Search and rescue},
	annote = {Type: Article}
}

@Article{du2024ShortReviewOntology,
	file = {References/pdf/du2024ShortReviewOntology.pdf},
	author = {Rick Du and Huilong An and Keyu Wang and Weidong
                  Liu},
	title = {A Short Review for Ontology Learning from Text:
                  Stride from Shallow Learning, Deep Learning to Large
                  Language Models Trend},
	journal = {CoRR},
	year = 2024,
	volume = {abs/2404.14991},
	doi = {10.48550/ARXIV.2404.14991},
	eprint = {2404.14991},
	eprinttype = {arXiv},
	url = {https://doi.org/10.48550/arXiv.2404.14991},
	timestamp = {Sat, 25 May 2024 18:35:27 +0200},
	biburl = {https://dblp.org/rec/journals/corr/abs-2404-14991.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@Article{dubey2024Llama3Herd,
	file = {References/pdf/dubey2024Llama3Herd.pdf},
	author = {Abhimanyu Dubey and Abhinav Jauhri and Abhinav
                  Pandey and Abhishek Kadian and Ahmad Al{-}Dahle and
                  Aiesha Letman and Akhil Mathur and Alan Schelten and
                  Amy Yang and Angela Fan and Anirudh Goyal and
                  Anthony Hartshorn and Aobo Yang and Archi Mitra and
                  Archie Sravankumar and Artem Korenev and Arthur
                  Hinsvark and Arun Rao and Aston Zhang and
                  Aur{\'{e}}lien Rodriguez and Austen Gregerson and
                  Ava Spataru and Baptiste Rozi{\`{e}}re and Bethany
                  Biron and Binh Tang and Bobbie Chern and Charlotte
                  Caucheteux and Chaya Nayak and Chloe Bi and Chris
                  Marra and Chris McConnell and Christian Keller and
                  Christophe Touret and Chunyang Wu and Corinne Wong
                  and Cristian Canton Ferrer and Cyrus Nikolaidis and
                  Damien Allonsius and Daniel Song and Danielle Pintz
                  and Danny Livshits and David Esiobu and Dhruv
                  Choudhary and Dhruv Mahajan and Diego Garcia{-}Olano
                  and Diego Perino and Dieuwke Hupkes and Egor
                  Lakomkin and Ehab AlBadawy and Elina Lobanova and
                  Emily Dinan and Eric Michael Smith and Filip
                  Radenovic and Frank Zhang and Gabriel Synnaeve and
                  Gabrielle Lee and Georgia Lewis Anderson and Graeme
                  Nail and Gr{\'{e}}goire Mialon and Guan Pang and
                  Guillem Cucurell and Hailey Nguyen and Hannah
                  Korevaar and Hu Xu and Hugo Touvron and Iliyan Zarov
                  and Imanol Arrieta Ibarra and Isabel M. Kloumann and
                  Ishan Misra and Ivan Evtimov and Jade Copet and
                  Jaewon Lee and Jan Geffert and Jana Vranes and Jason
                  Park and Jay Mahadeokar and Jeet Shah and Jelmer van
                  der Linde and Jennifer Billock and Jenny Hong and
                  Jenya Lee and Jeremy Fu and Jianfeng Chi and Jianyu
                  Huang and Jiawen Liu and Jie Wang and Jiecao Yu and
                  Joanna Bitton and Joe Spisak and Jongsoo Park and
                  Joseph Rocca and Joshua Johnstun and Joshua Saxe and
                  Junteng Jia and Kalyan Vasuden Alwala and Kartikeya
                  Upasani and Kate Plawiak and Ke Li and Kenneth
                  Heafield and Kevin Stone and et al.},
	title = {The Llama 3 Herd of Models},
	journal = {CoRR},
	year = 2024,
	volume = {abs/2407.21783},
	doi = {10.48550/ARXIV.2407.21783},
	eprint = {2407.21783},
	eprinttype = {arXiv},
	url = {https://doi.org/10.48550/arXiv.2407.21783},
	timestamp = {Tue, 08 Jul 2025 07:36:33 +0200},
	biburl = {https://dblp.org/rec/journals/corr/abs-2407-21783.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{díaz2024AutomaticKnowledgeGraph,
	file = {References/pdf/díaz2024AutomaticKnowledgeGraph.pdf},
	title = {Automatic knowledge-graph creation from historical documents: {The} {Chilean} dictatorship as a case study},
	volume = {3853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212705684&partnerID=40&md5=d0fcc6d861c72eaca0134114f37b278e},
	abstract = {We present our results regarding the construction of a knowledge graph from historical documents related to the Chilean dictatorship period (1973-1990). Our approach uses LLMs to automatically recognize entities and relations between them and resolve conflicts between these values. To prevent hallucination, the interaction with the LLM is grounded in a simple ontology with four types of entities and seven types of relations. To evaluate our architecture, we use a gold standard graph constructed using a small subset of the documents, and compare this to the graph obtained from our approach when processing the same set of documents. Results show that the automatic construction manages to recognize a good portion of all the entities in the gold standard and that those not recognized are explained mainly by the level of granularity in which the information is structured in the graph and not because the automatic approach misses an important entity in the graph. Looking forward, we expect this report to encourage work on other similar projects focused on enhancing research in humanities and social science. However, we remark that better evaluation metrics are needed to accurately fine-tune these types of architectures. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Díaz, Camila and Dunstan, Jocelyn and Etcheverry, Lorena and Fonck, Antonia and Grez, Alejandro and Mery, Domingo and Reutter, Juan L. and Rojas, Hugo},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, History, Ontology's, Case-studies, Simple++, Automatic construction, Automatic approaches, Gold standards, Historical documents, Humanities and social science, Types of relations},
	annote = {Type: Conference paper {\textbar} RAYYAN-LABELS: ontology-supported application}
}

@article{farmer2025DevelopmentEvaluation4m,
	file = {References/pdf/farmer2025DevelopmentEvaluation4m.pdf},
	title = {Development and evaluation of a {4M} taxonomy from nursing home staff text messages using a fine-tuned generative language model},
	volume = {32},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218408518&doi=10.1093%2Fjamia%2Focaf006&partnerID=40&md5=7e676688b8f034794501b78761b5c3b1},
	doi = {10.1093/jamia/ocaf006},
	abstract = {Objective: This study aimed to explore the utilization of a fine-tuned language model to extract expressions related to the Age-Friendly Health Systems 4M Framework (What Matters, Medication, Mentation, and Mobility) from nursing home worker text messages, deploy automated mapping of these expressions to a taxonomy, and explore the created expressions and relationships. Materials and Methods: The dataset included 21 357 text messages from healthcare workers in 12 Missouri nursing homes. A sample of 860 messages was annotated by clinical experts to form a "Gold Standard"dataset. Model performance was evaluated using classification metrics including Cohen's Kappa (κ), with κ ≥ 0.60 as the performance threshold. The selected model was fine-tuned. Extractions were clustered, labeled, and arranged into a structured taxonomy for exploration. Results: The fine-tuned model demonstrated improved extraction of 4M content (κ = 0.73). Extractions were clustered and labeled, revealing large groups of expressions related to care preferences, medication adjustments, cognitive changes, and mobility issues. Discussion: The preliminary development of the 4M model and 4M taxonomy enables knowledge extraction from clinical text messages and aids future development of a 4M ontology. Results compliment themes and findings in other 4M research. Conclusion: This research underscores the need for consensus building in ontology creation and the role of language models in developing ontologies, while acknowledging their limitations in logical reasoning and ontological commitments. Further development and context expansion with expert involvement of a 4M ontology are necessary. © 2025 Elsevier B.V., All rights reserved.},
	number = {3},
	journal = {Journal of the American Medical Informatics Association},
	author = {Farmer, Matthew Steven and Popescu, Mihail and Powell, Kimberly Ryan},
	year = {2025},
	note = {Section: 0},
	keywords = {natural language processing, ontology, Natural Language Processing, taxonomy, cognition, language model, human, benchmarking, ontology development, article, Humans, information processing, clinical decision making, consensus, Datasets as Topic, elderly care, health care personnel, home for the aged, interpersonal communication, logical reasoning, Missouri, nursing home, nursing home personnel, Nursing Homes, pattern recognition, text messaging, Text Messaging},
	pages = {535 -- 544},
	annote = {Type: Article}
}

@article{fathallah2025NeonGptLarge,
	file = {References/pdf/fathallah2025NeonGptLarge.pdf},
	title = {{NeOn}-{GPT}: {A} {Large} {Language} {Model}-{Powered} {Pipeline} for {Ontology} {Learning}},
	volume = {15344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218469990&doi=10.1007%2F978-3-031-78952-6_4&partnerID=40&md5=071c0cc79dd4a7986f0497d28a7e43be},
	doi = {10.1007/978-3-031-78952-6_4},
	abstract = {We address the task of ontology learning by combining the structured NeOn methodology framework with Large Language Models (LLMs) for translating natural language domain descriptions into Turtle syntax ontologies. The main contribution of the paper is a prompt pipeline tailored for domain-agnostic modeling, exemplified through the application to a domain-specific case study: the wine ontology. The resulting pipeline is used to develop NeOn-GPT, a workflow for automatic ontology modeling, and its proof of concept implementation, integrated on top of the metaphactory platform. NeOn-GPT leverages the systematic approach of the NeOn methodology and LLMs’ generative capabilities to facilitate a more efficient ontology development process. We evaluate the proposed approach by conducting comprehensive evaluations using the Stanford wine ontology as the gold standard. The obtained results show, that LLMs are not fully equipped to perform procedural tasks required for ontology development, and lack the reasoning skills and domain expertise needed. Overall, LLMs require integration with the workflow or trajectory tools for continuous knowledge engineering tasks. Nevertheless, LLMs can significantly alleviate the time and expertise needed. Our code base is publicly available for research and development purposes, accessible at: https://github.com/andreamust/NEON-GPT. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Fathallah, Nadeen and Das, Arunav and de Giorgis, Stefano and Poltronieri, Andrea and Haase, Peter and Kovriguina, Liubov},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Ontology model, Language model, Ontology learning, Information management, Ontology development, Knowledge engineering, Natural languages, Syntactics, Ontology's, Natural language processing systems, Domain description, Neon methodology, Work-flows, Incorrect information},
	pages = {36 -- 50},
	annote = {Type: Conference paper}
}

@article{fathallah2025TamingHallucinationsSemantic,
	file = {References/pdf/fathallah2025TamingHallucinationsSemantic.pdf},
	title = {Taming {Hallucinations}: {A} {Semantic} {Matching} {Evaluation} {Framework} for {LLM}-{Generated} {Ontologies}},
	volume = {3979},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009068954&partnerID=40&md5=b4220ec10d18b3bc6039a3c2da02ba9d},
	abstract = {Ontology learning using Large Language Models (LLMs) has shown promise yet remains challenged by hallucinations-spurious or inaccurate concepts and relationships that undermine domain validity. This issue is particularly critical in highly specialized fields such as life sciences, where ontology accuracy directly impacts knowledge representation and decision-making. In this work, we introduce an automated evaluation framework that systematically assesses the quality of LLM-generated ontologies by comparing their concepts and relationship triples against domain knowledge (i.e. expert-curated domain ontologies). Our approach leverages transformer-based semantic similarity methods to detect hallucinations, ensuring that generated ontologies align with real-world knowledge. We evaluate our framework using six LLM-generated ontologies, validating them against three reference ontologies with increasing domain specificity. This work establishes a scalable, automated approach for validating LLM-generated ontologies, paving the way for their broader adoption in complex, knowledge-intensive domains. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Fathallah, Nadeen and Staab, Steffen and Algergawy, Alsayed},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Ontology learning, Semantics, Ontology matching, Knowledge representation, Knowledge management, Decision making, Human computer interaction, Semantic matching, Evaluation framework, Learning systems, Domain Knowledge, Ontology's, Copyrights, Life science domain, Life-sciences, Neon-GPT},
	annote = {Type: Conference paper}
}

@article{feng2024ConstructionApplicationKnowledge,
	file = {References/pdf/feng2024ConstructionApplicationKnowledge.pdf},
	title = {Construction and {Application} of {Knowledge} {Graph} for {Water} {Engineering} {Scheduling} {Based} on {Large} {Language} {Model}},
	volume = {18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195585807&doi=10.3778%2Fj.issn.1673-9418.2311098&partnerID=40&md5=09fbfb1b464d422201314ff64ff1a36b},
	doi = {10.3778/j.issn.1673-9418.2311098},
	abstract = {With the growth of water conservancy and the increasing demand for information, handling and representing large volumes of water-related data has become complex. Particularly, scheduling textual data often exists in natural language form, lacking clear structure and standardization. Processing and utilizing such diverse data necessitates extensive domain knowledge and professional expertise. To tackle this challenge, a method based on large language model has been proposed to construct a knowledge graph for water engineering scheduling. This approach involves collecting and preprocessing scheduling rule data at the data layer, leveraging large language models to extract embedded knowledge, constructing the ontology at the conceptual layer, and extracting the“three- step”method prompt strategy at the instance layer. Under the interaction of the data, conceptual, and instance layers, high-performance extraction of rule texts is achieved, and the construction of the dataset and knowledge graph is completed. Experimental results show that the F1 value of the extraction method in this paper reaches 85.5\%, and the effectiveness and rationality of the modules of the large language model are validated through ablation experiments. This graph integrates dispersed water conservancy rule information, effectively handles unstructured textual data, and offers visualization querying and functionality tracing. It aids professionals in assessing water conditions and selecting appropriate scheduling schemes, providing valuable support for conservancy decision-making and intelligent reasoning. © 2024 Elsevier B.V., All rights reserved.},
	number = {6},
	journal = {Journal of Frontiers of Computer Science and Technology},
	author = {Feng, Jun and Chang, Yanghong and Lu, Jiamin and Tang, Hailin and Lyu, Zhipeng and Qiu, Yuchun},
	year = {2024},
	note = {Section: 0},
	pages = {1637 -- 1647},
	annote = {Type: Article}
}

@article{feng2024OntologyGroundedAutomatic,
	file = {References/pdf/feng2024OntologyGroundedAutomatic.pdf},
	title = {Ontology-grounded {Automatic} {Knowledge} {Graph} {Construction} by {LLM} under {Wikidata} schema},
	volume = {3841},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210894055&partnerID=40&md5=42721ceb91e4dca1bd023f200ae069d5},
	abstract = {We propose an ontology-grounded approach to Knowledge Graph (KG) construction using Large Language Models (LLMs) on a knowledge base. An ontology is authored by generating Competency Questions (CQ) on knowledge base to discover knowledge scope, extracting relations from CQs, and attempt to replace equivalent relations by their counterpart in Wikidata. To ensure consistency and interpretability in the resulting KG, we ground generation of KG with the authored ontology based on extracted relations. Evaluation on benchmark datasets demonstrates competitive performance in knowledge graph construction task. Our work presents a promising direction for scalable KG construction pipeline with minimal human intervention, that yields high quality and human-interpretable KGs, which are interoperable with Wikidata semantics for potential knowledge base expansion. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Feng, Xiaohan and Wu, Xixin and Meng, Helen Mei Ling},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Relation extraction, Semantics, Wikidata, Interpretability, Interpretable AI, Graph construction, Ontology's, Equivalent relation},
	pages = {117 -- 135},
	annote = {Type: Conference paper}
}

@article{ferraz2025CanLanguageModels,
	file = {References/pdf/ferraz2025CanLanguageModels.pdf},
	title = {Can {Language} {Models} {Align} {Biomedical} {Ontologies}?: {Evaluating} {Retrieval}-{Augmented} {Prompt} {Strategies} in {Bio}-{ML}},
	volume = {4001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012127875&partnerID=40&md5=644ab89c151aee621af0eef8183870b8},
	abstract = {Aligning biomedical ontologies presents a significant challenge due to their complexity and the highly domain-specific nature of their vocabulary. Recent advancements in Language Models (LMs) have led to their increasing application in ontology alignment tasks, offering promising results. However, a systematic evaluation of semantics-based prompting strategies for leveraging LMs in this context remains unexplored. This study investigates the effectiveness of different prompting techniques to enhance biomedical ontology alignment performance. We have developed a framework to support the design of LM-based queries to assess the semantic similarity between ontology classes. The framework interrogates the ontologies to align to extract relevant contextual information to inject into the LM prompts allowing the use of Retrieval Augmented Generation (RAG). We conduct preliminary experiments on selected hard cases from biomedical ontologies that compose the Ontology Alignment Evaluation Initiative Bio-ML track and provide some insights into the effectiveness, reliability, and limitations of prompt-based approaches in ontology matching. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Ferraz, Lucas and Cotovio, Pedro Giesteira and Pesquita, Cátia},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology, Language model, Semantics, Knowledge representation, Ontology alignment, Query processing, Biomedical ontologies, Performance, Alignment, Computational linguistics, Ontology's, Knowledge-representation, Model-based OPC, Domain specific, Specific nature, Systematic evaluation},
	annote = {Type: Conference paper}
}

@article{funk2023TowardsOntologyConstruction,
	file = {References/pdf/funk2023TowardsOntologyConstruction.pdf},
	title = {Towards {Ontology} {Construction} with {Language} {Models}},
	volume = {3577},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179559244&partnerID=40&md5=33969446bee8becffb8a2e0211cb3651},
	abstract = {We present a method for automatically constructing a concept hierarchy for a given domain by querying a large language model. We apply this method to various domains using OpenAI’s GPT 3.5. Our experiments indicate that LLMs can be of considerable help for constructing concept hierarchies. © 2023 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Funk, Maurice and Hosemann, Simon and Jung, Jean Christoph and Lutz, Carsten},
	year = {2023},
	note = {Section: 0},
	keywords = {Language model, Ontology construction, Computational linguistics, Concept hierarchies},
	annote = {Type: Conference paper}
}

@inproceedings{gangemi2005OntologyEvaluationValidation,
	file = {References/pdf/gangemi2005OntologyEvaluationValidation.pdf},
	title = {Ontology evaluation and validation An integrated formal model for the quality diagnostic task},
	author = {Aldo Gangemi and Carola Catenacci and Massimiliano Ciaramita and Jos Lehmann},
	year = {2005},
	url = {https://api.semanticscholar.org/CorpusID:3087032}
}

@Article{ganino2018OntologyPopulationOpen,
	file = {References/pdf/ganino2018OntologyPopulationOpen.pdf},
	author = {Giulio Ganino and Domenico Lembo and Massimo Mecella
                  and Federico Scafoglieri},
	title = {Ontology population for open-source intelligence:
                  {A} GATE-based solution},
	journal = {Softw. Pract. Exp.},
	year = 2018,
	volume = 48,
	number = 12,
	pages = {2302-2330},
	doi = {10.1002/SPE.2640},
	url = {https://doi.org/10.1002/spe.2640},
	timestamp = {Mon, 26 Oct 2020 09:03:03 +0100},
	biburl = {https://dblp.org/rec/journals/spe/GaninoLMS18.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{georgakopoulos2024TextKnowledgeLeveraging,
	file = {References/pdf/georgakopoulos2024TextKnowledgeLeveraging.pdf},
	title = {From {Text} to {Knowledge}: {Leveraging} {LLMs} and {RAG} for {Relationship} {Extraction} in {Ontologies} and {Thesauri}},
	volume = {3967},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006913033&partnerID=40&md5=ea70a64b726d1dc660804bf58efadf08},
	abstract = {Ontologies, vocabularies, and thesauri provide a shared conceptualisation for a domain. Manually maintaining and updating such knowledge systems when knowledge changes, does not scale for large domains, such as in biomedicine. Recently, large language models (LLMs) have been increasingly used as tools in knowledge engineering processes, offering new possibilities for the automatic creation and maintenance of knowledge systems. This work explores how LLMs can be leveraged for the automated extension of such knowledge systems. Specifically, we build on the DRAGON-AI framework, which integrates Retrieval-Augmented Generation (RAG) to provide LLMs with access to external knowledge sources for more faithful outputs. We investigate the ability of the framework to predict relationships between a given knowledge system and a novel concept. We do so for both an ontology and a thesaurus, and analyse the impact of (i) enriching prompts with contextual information as well as more clear instructions, (ii) an alternative retrieval approach, and (iii) using a conversational model versus an instruction-following model. The results show superior quality in the ontology generations for all models and approaches compared to the thesaurus. The two models show varied performance across the different experiment configurations with only the conversational model showing notably improved performance, in terms of F1, for the ontology with the custom retrieval approach. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Georgakopoulos, Antonios and Van Ossenbruggen, Jacco and Stork, Lise},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge acquisition, Large language model, Language model, Relationship extraction, Retrieval-augmented generation, Prompting, Performance, Knowledge system, Ontology's, Conversational model, DRAGON-AI},
	annote = {Type: Conference paper}
}

@article{ghazouani2025LlmDrivenCase,
	file = {References/pdf/ghazouani2025LlmDrivenCase.pdf},
	title = {{LLM}-{Driven} {Case}-{Base} {Populating} for {Structuring} and {Integrating} {Restoration} {Experiences}},
	volume = {15662},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010815398&doi=10.1007%2F978-3-031-96559-3_5&partnerID=40&md5=5edd9a3da5bfa66a6d0f852e64dcbc6c},
	doi = {10.1007/978-3-031-96559-3_5},
	abstract = {In Case-Based Reasoning (CBR), a case-base is a structured knowledge collection, often represented as an ontology with a TBox (conceptual structure) and ABox (concrete cases). This work emphasizes the need for a case-base to integrate knowledge from unstructured texts describing hydro-ecosystem restoration experiences, forming the foundation for a CBR framework to address new restoration challenges. However, populating the case-base from unstructured texts presents challenges due to fragmented, inconsistent, and implicit information. Therefore, we propose leveraging large language models (LLMs) to extract knowledge from unstructured texts, where the ontology population is approached as a generative knowledge extraction task. The results demonstrate that LLMs can effectively extract structured knowledge, facilitating the creation of a case-base for future projects. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Ghazouani, Fethi and Giustozzi, Franco and Le Ber, Florence},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge acquisition, Large language model, Ontology, Language model, Knowledge management, Computational linguistics, Model-driven, Ecosystems, Ontology's, Conceptual structures, Structured knowledge, Case based reasoning, Unstructured texts, Case base, Casebased reasonings (CBR), Hydro-ecosystems, Restoration},
	pages = {67 -- 80},
	annote = {Type: Conference paper}
}

@article{giglou2023Llms4olLargeLanguageb,
	file = {References/pdf/giglou2023Llms4olLargeLanguage.pdf},
	title = {{LLMs4OL}: {Large} {Language} {Models} for {Ontology} {Learning}},
	volume = {14265},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177183557&doi=10.1007%2F978-3-031-47240-4_22&partnerID=40&md5=0304490aebf9532fcf8f18d22aa760bf},
	doi = {10.1007/978-3-031-47240-4_22},
	abstract = {We propose the LLMs4OL approach, which utilizes Large Language Models (LLMs) for Ontology Learning (OL). LLMs have shown significant advancements in natural language processing, demonstrating their ability to capture complex language patterns in different knowledge domains. Our LLMs4OL paradigm investigates the following hypothesis: Can LLMs effectively apply their language pattern capturing capability to OL, which involves automatically extracting and structuring knowledge from natural language text? To test this hypothesis, we conduct a comprehensive evaluation using the zero-shot prompting method. We evaluate nine different LLM model families for three main OL tasks: term typing, taxonomy discovery, and extraction of non-taxonomic relations. Additionally, the evaluations encompass diverse genres of ontological knowledge, including lexicosemantic knowledge in WordNet, geographical knowledge in GeoNames, and medical knowledge in UMLS. The obtained empirical results show that foundational LLMs are not sufficiently suitable for ontology construction that entails a high degree of reasoning skills and domain expertise. Nevertheless, when effectively fine-tuned they just might work as suitable assistants, alleviating the knowledge acquisition bottleneck, for ontology construction. © 2023 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Giglou, Hamed Babaei and D’Souza, Jennifer and Auer, Sören},
	year = {2023},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Ontology learning, Data mining, Prompting, Ontology construction, Computational linguistics, Language patterns, Zero-shot learning, Learning systems, Ontology's, Natural language processing systems, Prompt-based learning},
	pages = {408 -- 427},
	annote = {Type: Conference paper}
}

@article{giglou2025Llms4omMatchingOntologies,
	file = {References/pdf/giglou2025Llms4omMatchingOntologies.pdf},
	title = {{LLMs4OM}: {Matching} {Ontologies} with {Large} {Language} {Models}},
	volume = {15344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218455564&doi=10.1007%2F978-3-031-78952-6_3&partnerID=40&md5=c3c4db12909f8024518974717c695310},
	doi = {10.1007/978-3-031-78952-6_3},
	abstract = {Ontology Matching (OM), is a critical task in knowledge integration, where aligning heterogeneous ontologies facilitates data interoperability and knowledge sharing. Traditional OM systems often rely on expert knowledge or predictive models, with limited exploration of the potential of Large Language Models (LLMs). We present the LLMs4OM framework, a novel approach to evaluate the effectiveness of LLMs in OM tasks. This framework utilizes two modules for retrieval and matching, respectively, enhanced by zero-shot prompting across three ontology representations: concept, concept-parent, and concept-children. Through comprehensive evaluations using 20 OM datasets from various domains, we demonstrate that LLMs, under the LLMs4OM framework, can match and even surpass the performance of traditional OM systems, particularly in complex matching scenarios. Our results highlight the potential of LLMs to significantly contribute to the field of OM. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Giglou, Hamed Babaei and D’Souza, Jennifer and Engel, Felix C. and Auer, Sören},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Ontology matching, Retrieval augmented generation, Ontology alignment, Expert systems, Zero-shot learning, Ontology's, Matching system, Matchings, Critical tasks, Zero-shot testing},
	pages = {25 -- 35},
	annote = {Type: Conference paper}
}

@article{gosselin2022SebmatcherResultsOaei,
	file = {References/pdf/gosselin2022SebmatcherResultsOaei.pdf},
	title = {{SEBMatcher} {Results} for {OAEI} 2022},
	volume = {3324},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146435366&partnerID=40&md5=304b1763207ce915a1271adf09143f62},
	abstract = {This paper presents the results of the Structural Embeddings with BERT Matcher (SEBMatcher) in the OAEI 2022 competition. SEBMatcher is a novel schema matching system that employs a 2 step approach: An unsupervised pretraining of a Masked Language Modeling BERT fed with random walks, followed by a supervised training of a BERT for sequence classification fed with positive and negative mappings. This is the first year of participation in the OAEI for SEBMatcher and it has obtained promising results in participating tracks. © 2023 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Gosselin, Francis and Zouaq, Amal},
	year = {2022},
	note = {Section: 0},
	keywords = {Language model, Ontology alignment, Modeling languages, Pre-training, Embeddings, Representation learning, Schema matching, Matching system, ISWC-2022, Random Walk, Supervised trainings, Might exclude},
	pages = {202 -- 209},
	annote = {Type: Conference paper}
}

@article{grattafiori2024Llama,
	title = {The llama 3 herd of models},
	author = {Grattafiori, Aaron and Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Vaughan, Alex and others},
	journal = {arXiv preprint arXiv:2407.21783},
	year = {2024}
}

@article{groza2023OntologyAgeRelated,
	file = {References/pdf/groza2023OntologyAgeRelated.pdf},
	title = {An ontology for {Age}-{Related} {Macular} {Degeneration} using ophthalmologists and language models},
	volume = {3415},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165747761&partnerID=40&md5=4afe6edcf9e1b17885effdbede323f78},
	abstract = {We aim to support monitoring of the current guidelines and scientific evidence in the management of Age-Related Macular Degeneration (AMD) in order to augment retinal specialists to develop a clinically oriented and consensual protocol for therapeutic approaches for AMD. First, we are engineering an ontology for AMD retinal condition using information from literature, related medical ontologies and domain knowledge from ophthalmologists. Second, we augment the knowledge engineer capabilities to populate and enrich the ontology using structured knowledge extracted from medical literature with the GPT-3 language model. Third, we perform reasoning to signal to the ophthalmologist differences or inconsistencies among different clinical studies, protocols or therapeutic approaches. © 2023 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Groza, Adrian Petru and Marginean, Anca Nicoleta and Delia Nicoara, Simona},
	year = {2023},
	note = {Section: 0},
	keywords = {Ontology, Language model, Reasoning, Medical ontology, Computational linguistics, Conflict detection, Ophthalmology, Domain Knowledge, Ontology's, 'current, Medical domains, Condition, Age-related macular degeneration, Scientific evidence},
	pages = {141 -- 142},
	annote = {Type: Conference paper}
}

@Article{gu2023SystematicSurveyPrompt,
	file = {References/pdf/gu2023SystematicSurveyPrompt.pdf},
	author = {Jindong Gu and Zhen Han and Shuo Chen and Ahmad
                  Beirami and Bailan He and Gengyuan Zhang and Ruotong
                  Liao and Yao Qin and Volker Tresp and Philip
                  H. S. Torr},
	title = {A Systematic Survey of Prompt Engineering on
                  Vision-Language Foundation Models},
	journal = {CoRR},
	year = 2023,
	volume = {abs/2307.12980},
	doi = {10.48550/ARXIV.2307.12980},
	eprint = {2307.12980},
	eprinttype = {arXiv},
	url = {https://doi.org/10.48550/arXiv.2307.12980},
	timestamp = {Mon, 17 Mar 2025 15:51:42 +0100},
	biburl = {https://dblp.org/rec/journals/corr/abs-2307-12980.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{guo2025DeepSeek,
	title = {Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
	author = {Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
	journal = {arXiv preprint arXiv:2501.12948},
	year = {2025}
}

@article{gupta2024EchoEnvironmentalSound,
	file = {References/pdf/gupta2024EchoEnvironmentalSound.pdf},
	title = {{ECHO}: {Environmental} {Sound} {Classification} with {Hierarchical} {Ontology}-guided {Semi}-{Supervised} {Learning}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205825848&doi=10.1109%2FCONECCT62155.2024.10677303&partnerID=40&md5=dd9414b66e627f0744370228215bd482},
	doi = {10.1109/CONECCT62155.2024.10677303},
	abstract = {Environment Sound Classification has been a well-studied research problem in the field of signal processing and till now more focus has been laid on fully supervised approaches. Recently, the focus has moved towards semi-supervised methods which concentrate on utilizing unlabeled data, and self-supervised methods which learn the intermediate representation through pretext tasks or contrastive learning. However, both approaches require a vast amount of unlabelled data to improve performance. In this work, we propose a novel framework called Environmental Sound Classification with Hierarchical Ontology-guided semi-supervised Learning (ECHO) that utilizes label ontology-based hierarchy to learn semantic representation by defining a novel pretext task. The model tries to predict coarse labels represented by the Large Language Model (LLM) based on ground truth label ontology, then further fine-tuned in a supervised way to predict the actual task. ECHO achieves a 1\% to 8\% accuracy improvement over baseline systems across UrbanSound8K, ESC-10, and ESC-50 datasets.},
	journal = {2024 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)},
	author = {Gupta, Pranav and Sharma, Raunak and Kumari, Rashmi and Aditya, Sri Krishna and Choudhary, Shwetank and Kumar, Sumit and M, Kanchana and R, Thilagavathy},
	month = jul,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Ontology, Large language models, Semantics, semi-supervised learning, Contrastive learning, Federated learning, Self-supervised learning, Semi-supervised learning, Accuracy, Adversarial machine learning, Signal processing, Environment Sound Classification, Label ontology, Semisupervised learning, Ontology's, Contrastive Learning, Learn+, Environment sound classification, Environmental sound classifications, Research problems, Signal-processing, Sound classification, Unlabeled data},
	pages = {1--5},
	annote = {ISSN: 2766-2101}
}

@article{guryanov2025ApproachAutomatedOntology,
	file = {References/pdf/guryanov2025ApproachAutomatedOntology.pdf},
	title = {An {Approach} to {Automated} {Ontology} {Extraction} {From} {Technological} {Documentation} {Using} {NLP} and {LLM}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009220232&doi=10.1109%2FICIEAM65163.2025.11028174&partnerID=40&md5=ae8cbf6929836ebcd5106cf7818cd65b},
	doi = {10.1109/ICIEAM65163.2025.11028174},
	abstract = {The paper presents an approach to constructing a formal description of a subject area using automated analysis of technological documentation. The first stage of the proposed approach is extracting data (terms, objects of the subject area) from technical documentation on the subject area. Then, a natural language query is formed for a large language model (LLM), which helps to extract relations between the extracted terms. At the final stage, an OWL ontology is formed by postprocessing the obtained data. Evaluation experiments were conducted on 16 documents (ISO) on the topic of “Space industry”. Experiments were also conducted to compare algorithms for extracting terms and relations using LLM and the C-value algorithm. The proposed approach has proven its effectiveness on strictly formalized texts.},
	journal = {2025 International Conference on Industrial Engineering, Applications and Manufacturing (ICIEAM)},
	author = {Guryanov, A. V. and Moshkin, V. S. and Dyrnochkin, A. A.},
	month = may,
	year = {2025},
	note = {Section: 0},
	keywords = {large language model, Ontologies, Large language model, Ontology, Natural language processing, Language model, Large language models, Manufacturing, natural language processing, ontology, OWL, Term, Language processing, Ontology Extraction, Documentation, Natural languages, Prototypes, Industries, design documentation, Industrial engineering, ISO Standards, technical documentation, term, Ontology's, Natural language processing systems, Query languages, C (programming language), Design documentation, Technical documentations},
	pages = {1011--1016},
	annote = {ISSN: 2993-4060}
}

@article{hannah2025LargeLanguageModels,
	file = {References/pdf/hannah2025LargeLanguageModels.pdf},
	title = {Large {Language} {Models} as {Knowledge} {Evaluation} {Agents}},
	volume = {3977},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008495455&partnerID=40&md5=522713b4c09e34210bf1335f60193335},
	abstract = {With the recent rise of large language models, there has been a growing interest in employing LLMs in different knowledge engineering tasks, such as supporting the semi-automatic creation of KG schemata. This is the case also when leveraging semi-structured data by translating XML schemata into ontologies, where there is a need to inject additional knowledge that makes explicit the relationships between different entities. We investigate the viability of using LLMs as knowledge evaluation agents to assess the suitability of the injected knowledge; by using Gemini as an LLM-based proxy for a human evaluator, and we configure it with different parameter settings and prompt structures. The responses (i.e. the LLM-based assessment of the relationships) are compared against the set of assessments or evaluations carried out by domain experts. We find that despite encountering some issues, the use of LLMs as a proxy expert shows promise in their ability to understand complex domains and evaluate relationships with respect to that domain. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Hannah, George and de Berardinis, Jacopo and Payne, Terry R. and Tamma, Valentina A.M. and Mitchell, Andrew and Piercy, Ellen and Johnson, Ewan and Ng, Andrew and Rostron, Harry and Konev, Boris Yu},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology engineering, Ontology, Language model, Knowledge management, Knowledge engineering, Prompt engineering, LLM evaluation, Agents, Domain Knowledge, Engineering tasks, Automatic creations, Knowledge evaluations, Semi-automatics, Semistructured data, XML-Schema},
	annote = {Type: Conference paper}
}

@article{hao2024AnalyzingLlama3,
	file = {References/pdf/hao2024AnalyzingLlama3.pdf},
	title = {Analyzing {Llama} 3-based {Approach} for {Axiom} {Translation} from {Ontologies}},
	volume = {3853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212688634&partnerID=40&md5=2bb61c3b90845531b2a9b19696705ec7},
	abstract = {Ontology development involves a top-down approach where ontology engineers and domain experts collaboratively define and evaluate ontological elements and axioms. Translating ontology axioms into natural language can significantly aid in ontology evaluation by making the content more understandable to subject matter experts who may lack a background in knowledge engineering. In this preliminary study, we investigate the potential of large language models (LLMs) in axiom translation from ontologies to facilitate ontology evaluation. We utilize Llama 3 to translate 1,192 ontology axioms across 19 distinct axiom types from five published ontologies. Results show that 163 (13.67\%) of the Llama 3 translation of the axiom are accurately represented, 268 (22.48\%) are not accurately represented, and 761 (63.84\%) are partially accurate. Our manual evaluation of the Llama 3 translation indicates some competency in producing hierarchical natural language equivalents while revealing some limitations when translating complex axioms. Nonetheless, there are opportunities to improve the results with few-shot training or using LLMs to provide support in knowledge engineering for ontologies. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Hao, Xubing and Cui, Licong and Tao, Cui and Roberts, Kirk E. and Amith, Muhammad Tuan},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology, Language model, Ontology development, Knowledge engineering, Natural languages, Subject matter experts, Ontology's, Ontology evaluations, Domain experts, Translation (languages), Ontological elements, Ontology axioms, Top down approaches},
	annote = {Type: Conference paper}
}

@article{haque2024UtilizingStructuralMetrics,
	file = {References/pdf/haque2024UtilizingStructuralMetrics.pdf},
	title = {Utilizing {Structural} {Metrics} from {Knowledge} {Graphs} to {Enhance} the {Robustness} {Quantification} of {Large} {Language} {Models}},
	doi = {10.1109/DSAA61799.2024.10722791},
	abstract = {The goal of this study is to determine whether large language models (LLMs) like CodeLlama, Mistral, and Vicuna can be used to build knowledge graphs (KGs) from textual data. We create class descriptions for well-known KGs such as DBpedia, YAGO, and Google Knowledge Graph, from which we extract RDF triples and enhance these graphs using different preprocessing methods. Six structural quality measures are used in the study to compare the constructed and existing KGs. Our results demonstrate how important LLMs are to improving KG construction and provide insightful information for KG construction researchers. Moreover, an in-depth analysis of popular open-source LLM models enables researchers to identify the most efficient model for various tasks, ensuring optimal performance in specific applications.},
	journal = {2024 IEEE 11th International Conference on Data Science and Advanced Analytics (DSAA)},
	author = {Haque, Mohd Ariful and Kamal, Marufa and George, Roy and Gupta, Kishor Datta},
	month = oct,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Knowledge graphs, Large language models, Resource description framework, Data science, Robustness, Measurement, Internet, Analytical models},
	pages = {1--2},
	annote = {ISSN: 2766-4112}
}

@article{haris2024SemanticPerspectivesLake,
	file = {References/pdf/haris2024SemanticPerspectivesLake.pdf},
	title = {Semantic {Perspectives} on the {Lake} {District} {Writing}: {Spatial} {Ontology} {Modeling} and {Relation} {Extraction} for {Deeper} {Insights}},
	volume = {315},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205767309&doi=10.4230%2FLIPIcs.COSIT.2024.11&partnerID=40&md5=72fff5300bf9859aec90a94affa75bee},
	doi = {10.4230/LIPIcs.COSIT.2024.11},
	abstract = {Extracting spatial details from historical texts can be difficult, hindering our understanding of past landscapes. The study addresses this challenge by analyzing the Corpus of the Lake District Writing, focusing on the English Lake District region. We systematically link the theoretical notions from the core concepts of spatial information to provide basis for the problem domain. The conceptual foundation is further complemented with a spatial ontology and a custom gazetteer, allowing a formal and insightful semantic exploration of the massive unstructured corpus. The other contrasting side of the framework is the usage of LLMs for spatial relation extraction. We formulate prompts leveraging understanding of the LLMs of the intended task, curate a list of spatial relations representing the most recurring proximity or vicinity relations terms and extract semantic triples for the top five place names appearing in the corpus. We compare the extraction capabilities of three benchmark LLMs for a scholarly significant historical archive, representing their potential in a challenging and interdisciplinary research problem. Finally, the network comprising the semantic triples is enhanced by incorporating a gazetteer-based classification of the objects involved thus improving their spatial profiling. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Leibniz International Proceedings in Informatics, LIPIcs},
	author = {Haris, Erum and Cohn, Anthony G. and Stell, John G.},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Ontology model, Language model, Relation extraction, Semantics, Text mining, Modeling languages, Benchmarking, Spatial relations, Ontology's, Classification (of information), Economic and social effects, Ontology relations, Spatial humanity, Spatial narratives, Spatial ontologies},
	annote = {Type: Conference paper}
}

@inproceedings{hayashi2025EvaluatingLlmsCapability,
	file = {References/pdf/hayashi2025EvaluatingLlmsCapability.pdf},
	title = "Evaluating {LLM}s' Capability to Identify Lexical Semantic Equivalence: Probing with the Word-in-Context Task",
	author = "Hayashi, Yoshihiko",
	editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
	booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
	month = jan,
	year = "2025",
	address = "Abu Dhabi, UAE",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2025.coling-main.466/",
	pages = "6985--6998",
	abstract = "This study proposes a method to evaluate the capability of large language models (LLMs) in identifying lexical semantic equivalence. The Word-in-Context (WiC) task, a benchmark designed to determine whether the meanings of a target word remain identical across different contexts, is employed as a probing task. Experiments are conducted with several LLMs, including proprietary GPT models and open-source models, using zero-shot prompting with adjectives that represent varying levels of semantic equivalence (e.g., ``the same'') or inequivalence (e.g., ``different''). The fundamental capability to identify lexical semantic equivalence in context is measured using standard accuracy metrics. Consistency across different levels of semantic equivalence is assessed via rank correlation with the expected canonical ranking of precision and recall, reflecting anticipated trends in performance across prompts. The proposed method demonstrates its effectiveness, highlighting the superior capability of GPT-4o, as it consistently outperforms other explored LLMs. Analysis of the WiC dataset, the discriminative properties of adjectives (i.e., their ability to differentiate between levels of semantic equivalence), and linguistic patterns in erroneous cases offer insights into the LLM{'}s capability and sensitivity. These findings could inform improvements in WiC task performance, although performance enhancement is not the primary focus of this study."
}

@article{he2023ExploringLargeLanguage,
	file = {References/pdf/he2023ExploringLargeLanguage.pdf},
	title = {Exploring {Large} {Language} {Models} for {Ontology} {Alignment}},
	volume = {3632},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184375684&partnerID=40&md5=43d321af25029eca4ea303b161851303},
	abstract = {This work investigates the applicability of recent generative Large Language Models (LLMs), such as the GPT series and Flan-T5, to ontology alignment for identifying concept equivalence mappings across ontologies. To test the zero-shot$^{\textrm{1}}$ performance of Flan-T5-XXL and GPT-3.5-turbo, we leverage challenging subsets from two equivalence matching datasets of the OAEI Bio-ML track, taking into account concept labels and structural contexts. Preliminary findings suggest that LLMs have the potential to outperform existing ontology alignment systems like BERTMap, given careful framework and prompt design. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {He, Yuan and Chen, Jiaoyan and Dong, Hang and Horrocks, Ian},
	year = {2023},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, GPT, Ontology matching, Ontology alignment, Performance, Computational linguistics, Ontology's, Matchings, Concept equivalences, Flan-t5},
	annote = {Type: Conference paper}
}

@article{he2023LanguageModelAnalysis,
	file = {References/pdf/he2023LanguageModelAnalysis.pdf},
	title = {Language {Model} {Analysis} for {Ontology} {Subsumption} {Inference}},
	url = {https://aclanthology.org/2023.findings-acl.213/},
	doi = {10.18653/v1/2023.findings-acl.213},
	abstract = {Investigating whether pre-trained language models (LMs) can function as knowledge bases (KBs) has raised wide research interests recently. However, existing works focus on simple, triple-based, relational KBs, but omit more sophisticated, logic-based, conceptualised KBs such as OWL ontologies. To investigate an LM's knowledge of ontologies, we propose OntoLAMA, a set of inference-based probing tasks and datasets from ontology subsumption axioms involving both atomic and complex concepts. We conduct extensive experiments on ontologies of different domains and scales, and our results demonstrate that LMs encode relatively less background knowledge of Subsumption Inference (SI) than traditional Natural Language Inference (NLI) but can improve on SI significantly when a small number of samples are given. We will open-source our code and datasets.},
	journal = {Findings of the Association for Computational Linguistics: ACL 2023},
	author = {He, Yuan and Chen, Jiaoyan and Jimenez-Ruiz, Ernesto and Dong, Hang and Horrocks, Ian},
	editor = {Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki},
	month = jul,
	year = {2023},
	note = {Place: Toronto, Canada
Publisher: Association for Computational Linguistics
Section: 0},
	keywords = {Ontology, Language model, Background knowledge, Computational linguistics, Language inference, Natural languages, Ontology's, Modeling analyzes, Open systems, Different domains, Simple++, OWL ontologies, Open source software, Research interests},
	pages = {3439--3453},
	annote = {Type: Conference paper}
}

@article{he2025StaticDynamicEmbedding,
	file = {References/pdf/he2025StaticDynamicEmbedding.pdf},
	title = {Static and {Dynamic} {Embedding} {Approaches} to {Identify} {Is}-{A} {Relations} in {SNOMED} {CT}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012760706&doi=10.1109%2FICHI64645.2025.00050&partnerID=40&md5=483223ede657cc39d5d7756f354e5d48},
	doi = {10.1109/ICHI64645.2025.00050},
	abstract = {Systematized Nomenclature of Medicine - Clinical Terms (SNOMED CT) is a comprehensive clinical terminology with over 350,000 unique concepts and 1 million relationships. It serves as an essential resource for both clinical practice and medical research. Approximately 40\% of these relationships are of the is-a type, which is key to classifying concepts as subtypes or subclasses within broader categories and is fundamental for decision support systems and automated reasoning in clinical environments. Identifying is-a relationships in SNOMED CT is crucial for enhancing the accuracy of patient cohort queries, which form the backbone of clinical and research applications. Our study aims to use deep learning-based neural networks to determine whether a relationship between two concepts falls under the is-a or non-is-a categories. This approach can help detect misclassified or undefined is-a concept pairs, ultimately improving the quality of SNOMED CT ontology. We construct a node-edge-node structure for concept pairs and their relationships, which we then split into two categories: is-a and non-is-a classes. In this study, we propose two classification approaches. In the first approach using embeddingBag, the data are mapped into vector representations and used as input for a fully connected neural network to learn the patterns of the is-a relationship. During model training, 80\% of the data is used for training and the remaining 20\% for testing.We achieved a precision of 0.903, recall of 0.894, and F1 Score of 0.898 in predicting the is-a relation among the associated medical concepts. The second approach involved transformer-based models like BERT(Bidirectional Encoder Representations from Transformers), introduced by Devlin et al. [1], which dramatically advanced various natural language processing (NLP) tasks by offering deeply contextualized word embeddings. And RoBERTa(Robustly optimized BERT approach)[2], both BERT and RoBERTa models have significantly advanced the field of NLP. This work uses them as encoders connected to a classifier head to predict is-a or non-is-a categories. We fine-tune our models using a historical SNOMED CT dataset from 2017, while evaluation is carried out on new data introduced after 2023 in the 2024 release. With a recall of 0.933, precision of 0.933, F1 score of 0.932, accuracy of 0.933, and ROC of 0.972, RoBERTa outperforms the other baseline models (Support Vector Machine(SVM), K-Nearest Neighbors(KNN), Naive Bayes, and Multilayer Perceptron(MLP)) across all metrics. This work demonstrates that our implementation can effectively identify unknown is-a relations in future datasets.},
	journal = {2025 IEEE 13th International Conference on Healthcare Informatics (ICHI)},
	author = {He, Bofan and Cheng, Jerry Q. and Gu, Huanying},
	month = jun,
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Large language model, Ontology, Terminology, Natural language processing, Language model, BERT, Deep learning, Information retrieval, Deep Learning, Natural Language Processing, Large Language Model, Neural networks, Transformers, Clinical terms, Data models, Training, SNOMED-CT, Deep neural networks, Computational linguistics, Information Retrieval, Accuracy, Medical imaging, Language processing, Bidirectional encoder representation from transformer, Encoding, Natural languages, Bidirectional control, Classification of Multi Sentence, Vectors, Learning systems, Natural language processing systems, Classification (of information), Clinical research, Learning algorithms, Classification of multi sentence},
	pages = {369--378},
	annote = {ISSN: 2575-2634}
}

@article{hertling2021MatchingWithTransformers,
	file = {References/pdf/hertling2021MatchingWithTransformers.pdf},
	title = {Matching with {Transformers} in {MELT}},
	volume = {3063},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122652126&partnerID=40&md5=9cc2e930a5549028dc272c54d43b20a6},
	abstract = {One of the strongest signals for automated matching of on- tologies and knowledge graphs are the textual descriptions of the con- cepts. The methods that are typically applied (such as character- or token-based comparisons) are relatively simple, and therefore do not cap- ture the actual meaning of the texts. With the rise of transformer-based language models, text comparison based on meaning (rather than lexical features) is possible. In this paper, we model the ontology matching task as classification problem and present approaches based on transformer models. We further provide an easy to use implementation in the MELT framework which is suited for ontology and knowledge graph matching. We show that a transformer-based filter helps to choose the correct cor- respondences given a high-recall alignment and already achieves a good result with simple alignment post-processing methods.3 © 2022 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Hertling, Sven and Portisch, Jan Philipp and Paulheim, Heiko},
	year = {2021},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Ontology matching, Optimisations, Transformer, Matchings, Textual description, Simple++, Automated matching, Matcher optimization, Strong signal},
	pages = {13 -- 24},
	annote = {Type: Conference paper}
}

@article{hertling2023OlalaOntologyMatching,
	file = {References/pdf/hertling2023OlalaOntologyMatching.pdf},
	series = {K-{CAP} '23},
	title = {{OLaLa}: {Ontology} {Matching} with {Large} {Language} {Models}},
	url = {https://doi.org/10.1145/3587259.3627571},
	doi = {10.1145/3587259.3627571},
	abstract = {Ontology (and more generally: Knowledge Graph) Matching is a challenging task where information in natural language is one of the most important signals to process. With the rise of Large Language Models, it is possible to incorporate this knowledge in a better way into the matching pipeline. A number of decisions still need to be taken, e.g., how to generate a prompt that is useful to the model, how information in the KG can be formulated in prompts, which Large Language Model to choose, how to provide existing correspondences to the model, how to generate candidates, etc. In this paper, we present a prototype that explores these questions by applying zero-shot and few-shot prompting with multiple open Large Language Models to different tasks of the Ontology Alignment Evaluation Initiative (OAEI). We show that with only a handful of examples and a well-designed prompt, it is possible to achieve results that are en par with supervised matching systems which use a much larger portion of the ground truth.},
	journal = {Proceedings of the 12th Knowledge Capture Conference 2023},
	author = {Hertling, Sven and Paulheim, Heiko},
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Ontology matching, Ontology alignment, Large Language Model, Ontology Matching, Entity Resolution, Computational linguistics, Zero-shot learning, Natural languages, Ontology's, Matchings, Graph matchings, Entity resolutions},
	pages = {131--139},
	annote = {event-place: Pensacola, FL, USA}
}

@article{hertling2023OlalaResultsOaei,
	file = {References/pdf/hertling2023OlalaResultsOaei.pdf},
	title = {{OLaLa} {Results} for {OAEI} 2023},
	volume = {3591},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180814848&partnerID=40&md5=b8d5fac66dc9350abb833bd534428cf1},
	abstract = {This paper presents the results of the OLaLa matching system participating in the OAEI 2023. The system is based on sentence-transformers as well as large language models. The former is used to generate correspondence candidates which is independent of any overlapping tokens because the comparison is only based on embeddings. To finally select the best mappings, a large language model is used to decide if two given textual representations of the source and target concept are equal or not. Based on positive and negative words that the LLM predicts, a confidence is extracted. Still, there are a lot of decisions that heavily influence the final result like (1) how can each concept be verbalized into text, (2) which prompt to use, and (3) which language model to choose. A lot of combinations were executed and the most useful one is submitted and packaged as a matching system. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Hertling, Sven and Paulheim, Heiko},
	year = {2023},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Ontology matching, Embeddings, Computational linguistics, Matching system, Target concept, Textual representation},
	pages = {170 -- 177},
	annote = {Type: Conference paper}
}

@article{hertling2025OaeiMachineLearning,
	file = {References/pdf/hertling2025OaeiMachineLearning.pdf},
	title = {{OAEI} {Machine} {Learning} {Dataset} for {Online} {Model} {Generation}},
	volume = {15344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218459910&doi=10.1007%2F978-3-031-78952-6_34&partnerID=40&md5=5b80c994decba989f88eb8b7ad8fedd2},
	doi = {10.1007/978-3-031-78952-6_34},
	abstract = {Ontology and knowledge graph matching systems are evaluated annually by the Ontology Alignment Evaluation Initiative (OAEI). More and more systems use machine learning-based approaches, including large language models. The training and validation datasets are usually determined by the system developer and often a subset of the reference alignments are used. This sampling is against the OAEI rules and makes a fair comparison impossible. Furthermore, those models are trained offline (a trained and optimized model is packaged into the matcher) and therefore the systems are specifically trained for those tasks. In this paper, we introduce a dataset that contains training, validation, and test sets for most of the OAEI tracks. Thus, online model learning (the systems must adapt to the given input alignment without human intervention) is made possible to enable a fair comparison for ML-based systems. We showcase the usefulness of the dataset by fine-tuning the confidence thresholds of popular systems. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Hertling, Sven and Norouzi, Ebrahim and Sack, Harald},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology matching, Ontology alignment, Model generation, Federated learning, Adversarial machine learning, Machine-learning, Ontology graphs, Contrastive Learning, Graph matching systems, Learning dataset, On-line modelling, Online model generation, Incorrect information},
	pages = {239 -- 243},
	annote = {Type: Conference paper}
}

@InProceedings{hlomani2014ApproachesMethodsMetrics,
	file = {References/pdf/hlomani2014ApproachesMethodsMetrics.pdf},
	title = {Approaches , methods , metrics , measures , and subjectivity in ontology evaluation : A survey},
	author = {Hlomani Hlomani and Deborah A. Stacey},
	year = {2014},
	url = {https://api.semanticscholar.org/CorpusID:51371006}
}

@article{ho2024LeveragingMultiAgent,
	file = {References/pdf/ho2024LeveragingMultiAgent.pdf},
	title = {Leveraging {Multi}-{Agent} {Systems} and {Large} {Language} {Models} for {Diabetes} {Knowledge} {Graphs}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218046486&doi=10.1109%2FBigData62323.2024.10825608&partnerID=40&md5=c77248afa42583f64d40767d76a92524},
	doi = {10.1109/BigData62323.2024.10825608},
	abstract = {This paper presents a novel framework for constructing a diabetes-specific knowledge graph (KG) using a streamlined multi-agent system powered by Gemini-based Large Language Models (LLMs). Leveraging insights from the 2016 National Diabetes Survey (NNDS) conducted by the National Diabetes Education Program (NDEP), the framework extracts critical variables related to diagnosis, risk perception, medical advice, and self-management practices across diverse U.S. populations. By processing data from the NNDS’s extensive 94-question survey, the methodology performs adaptive ontology mapping using APIs for six major medical standards (e.g., SNOMED CT, ICD-11), ensuring semantic interoperability. Relationships between variables are identified and structured using RDF, RDFS, and OWL standards. The integration of LLMs with ontology tools like Protégé enhances automation and scalability. Results demonstrate the framework’s effectiveness in generating contextually rich and clinically relevant knowledge graphs, providing a robust foundation for advancing healthcare informatics and personalized diabetes management.},
	journal = {2024 IEEE International Conference on Big Data (BigData)},
	author = {Ho, Duy H. and Das, Udiptaman and Ho, Regina and Lee, Yugyung},
	month = dec,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Knowledge graphs, Large Language Models, Knowledge graph, Large language model, Ontology, Language model, Ontology mapping, AI, OWL, RDF, Resource description framework, Medical education, Knowledge Graph, Multi-agent systems, Diagnosis, Standards, Ontology Mapping, Multi-Agent System, Scalability, Healthcare Informatics, Surveys, Diabetes, Medical diagnostic imaging, Medical services, Diseases, Health care informatics, Multiagent systems (MASs), Specific knowledge, Education programmes},
	pages = {3401--3410},
	annote = {ISSN: 2573-2978}
}

@article{hofer2024TowardsSelfConfiguring,
	file = {References/pdf/hofer2024TowardsSelfConfiguring.pdf},
	title = {Towards self-configuring {Knowledge} {Graph} {Construction} {Pipelines} using {LLMs} - {A} {Case} {Study} with {RML}},
	volume = {3718},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198642897&partnerID=40&md5=371a1c9b734a0892d1b084ed8ffefc48},
	abstract = {This paper explores using large language models (LLMs) to generate RDF mapping language (RML) files in the RDF turtle format as a key step towards self-configuring RDF knowledge graph construction pipelines. Our case study involves mapping a subset of the Internet Movie Database (IMDB) in JSON format given a target Movie ontology (selection of DBpedia Ontology OWL statements). We define and compute several scores to assess both the generated mapping files and the resulting graph using a manually created reference. Our findings demonstrate the promising potential of the state-of-the-art commercial LLMs in a zero-shot scenario. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Hofer, Marvin and Frey, Johannes and Rahm, Erhard},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Semantics, Knowledge graph construction, Mapping, Resource Description Framework (RDF), Zero-shot learning, Graph construction, Pipelines, Mapping generations, Automated RDF mapping language mapping generation, Language mapping, Large language model-KG-engineering, Mapping Language, RDF mapping},
	annote = {Type: Conference paper}
}

@article{huang2024LargeLanguageModel,
	file = {References/pdf/huang2024LargeLanguageModel.pdf},
	title = {Large {Language} {Model} for {Ontology} {Learning} in {Drinking} {Water} {Distribution} {Network} {Domain}},
	volume = {3967},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006919338&partnerID=40&md5=481aaad47de18ac4cf4a517059109b8b},
	abstract = {Currently, most ontologies are created manually, which is time-consuming and labour-intensive. Meanwhile, the advanced capabilities of Large Language Models (LLMs) have proven beneficial in various domains, significantly improving the efficiency of text processing and text generation. Therefore, this paper focuses on the use of LLMs for ontology learning. It uses a manual ontology construction method as a basis to facilitate the LLMs for ontology learning. The proposed approach is based on Retrieval Augmented Generation (RAG), and passed queries to LLMs are based upon the manual ontology method - UPON Lite ontology. Two different variants of LLMs have been experimented with, and they all demonstrate the capability of ontology learning to varying degrees. This approach shows promising initial results in the direction of (semi-) automated ontology learning using LLMs and makes the ontology construction process easier for people without prior domain expertise.The final ontology was evaluated by the domain expert and ranked according to the defined criteria. Based on the evaluation results, the final ontology could be used as a base version, but it requires further fine-tuning by domain experts to ensure its accuracy and completeness. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Huang, Yiwen and Karabulut, Erkan and Degeler, Victoria},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Ontology learning, Ontology construction, Ontology's, Domain experts, Labour-intensive, Text-processing, Drinking water distribution networks, Network domains},
	annote = {Type: Conference paper}
}

@Article{huang2025SurveyHallucinationIn,
	file = {References/pdf/huang2025SurveyHallucinationIn.pdf},
	author = {Lei Huang and Weijiang Yu and Weitao Ma and Weihong
                  Zhong and Zhangyin Feng and Haotian Wang and
                  Qianglong Chen and Weihua Peng and Xiaocheng Feng
                  and Bing Qin and Ting Liu},
	title = {A Survey on Hallucination in Large Language Models:
                  Principles, Taxonomy, Challenges, and Open
                  Questions},
	journal = {{ACM} Trans. Inf. Syst.},
	year = 2025,
	volume = 43,
	number = 2,
	pages = {42:1--42:55},
	doi = {10.1145/3703155},
	url = {https://doi.org/10.1145/3703155},
	timestamp = {Wed, 11 Jun 2025 21:01:33 +0200},
	biburl = {https://dblp.org/rec/journals/tois/HuangYMZFWCPFQL25.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@Article{hurst2024Gpt4oSystem,
	file = {References/pdf/hurst2024Gpt4oSystem.pdf},
	author = {Aaron Hurst and Adam Lerer and Adam P. Goucher and
                  Adam Perelman and Aditya Ramesh and Aidan Clark and
                  AJ Ostrow and Akila Welihinda and Alan Hayes and
                  Alec Radford and Aleksander Madry and Alex
                  Baker{-}Whitcomb and Alex Beutel and Alex Borzunov
                  and Alex Carney and Alex Chow and Alex Kirillov and
                  Alex Nichol and Alex Paino and Alex Renzin and Alex
                  Tachard Passos and Alexander Kirillov and Alexi
                  Christakis and Alexis Conneau and Ali Kamali and
                  Allan Jabri and Allison Moyer and Allison Tam and
                  Amadou Crookes and Amin Tootoonchian and Ananya
                  Kumar and Andrea Vallone and Andrej Karpathy and
                  Andrew Braunstein and Andrew Cann and Andrew
                  Codispoti and Andrew Galu and Andrew Kondrich and
                  Andrew Tulloch and Andrey Mishchenko and Angela Baek
                  and Angela Jiang and Antoine Pelisse and Antonia
                  Woodford and Anuj Gosalia and Arka Dhar and Ashley
                  Pantuliano and Avi Nayak and Avital Oliver and
                  Barret Zoph and Behrooz Ghorbani and Ben Leimberger
                  and Ben Rossen and Ben Sokolowsky and Ben Wang and
                  Benjamin Zweig and Beth Hoover and Blake Samic and
                  Bob McGrew and Bobby Spero and Bogo Giertler and
                  Bowen Cheng and Brad Lightcap and Brandon Walkin and
                  Brendan Quinn and Brian Guarraci and Brian Hsu and
                  Bright Kellogg and Brydon Eastman and Camillo
                  Lugaresi and Carroll L. Wainwright and Cary Bassin
                  and Cary Hudson and Casey Chu and Chad Nelson and
                  Chak Li and Chan Jun Shern and Channing Conger and
                  Charlotte Barette and Chelsea Voss and Chen Ding and
                  Cheng Lu and Chong Zhang and Chris Beaumont and
                  Chris Hallacy and Chris Koch and Christian Gibson
                  and Christina Kim and Christine Choi and Christine
                  McLeavey and Christopher Hesse and Claudia Fischer
                  and Clemens Winter and Coley Czarnecki and Colin
                  Jarvis and Colin Wei and Constantin Koumouzelis and
                  Dane Sherburn},
	title = {GPT-4o System Card},
	journal = {CoRR},
	year = 2024,
	volume = {abs/2410.21276},
	doi = {10.48550/ARXIV.2410.21276},
	eprint = {2410.21276},
	eprinttype = {arXiv},
	url = {https://doi.org/10.48550/arXiv.2410.21276},
	timestamp = {Mon, 02 Dec 2024 10:22:59 +0100},
	biburl = {https://dblp.org/rec/journals/corr/abs-2410-21276.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{höltgen2025UtilizingLargeLanguage,
	file = {References/pdf/höltgen2025UtilizingLargeLanguage.pdf},
	title = {Utilizing large language models for semantic enrichment of infrastructure condition data: a comparative study of {GPT} and {Llama} models},
	volume = {4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010910273&doi=10.1007%2Fs43503-025-00055-9&partnerID=40&md5=b3c8e5c70382506c88926aeba1af7937},
	doi = {10.1007/s43503-025-00055-9},
	abstract = {Relational databases containing construction-related data are widely used in the Architecture, Engineering, and Construction (AEC) industry to manage diverse datasets, including project management and building-specific information. This study explores the use of large language models (LLMs) to convert construction data from relational databases into formal semantic representations, such as the resource description framework (RDF). Transforming this data into RDF-encoded knowledge graphs enhances interoperability and enables advanced querying capabilities. However, existing methods like R2RML and Direct Mapping face significant challenges, including the need for domain expertise and scalability issues. LLMs, with their advanced natural language processing capabilities, offer a promising solution by automating the conversion process, reducing the reliance on expert knowledge, and semantically enriching data through appropriate ontologies. This paper evaluates the potential of four LLMs (two versions of GPT and Llama) to enhance data enrichment workflows in the construction industry and examines the limitations of applying these models to large-scale datasets. © 2025 Elsevier B.V., All rights reserved.},
	number = {1},
	journal = {AI in Civil Engineering},
	author = {Höltgen, L. and Zentgraf, Sven and Hagedorn, Philipp and König, Markus},
	year = {2025},
	note = {Section: 0},
	annote = {Type: Article}
}

@article{incitti2024LeveragingLlmsKnowledge,
	file = {References/pdf/incitti2024LeveragingLlmsKnowledge.pdf},
	title = {Leveraging {LLMs} for {Knowledge} {Engineering} from {Technical} {Manuals}: {A} {Case} {Study} in the {Medical} {Prosthesis} {Manufacturing} {Domain}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207690564&doi=10.23919%2FFUSION59988.2024.10706469&partnerID=40&md5=a81498f29b7325e537a3070f58f46227},
	doi = {10.23919/FUSION59988.2024.10706469},
	abstract = {Ontologies are nowadays widely used to organize information across specific domains, being effective due to their hierarchical structure and the ability to explicitly represent relationships between concepts. Knowledge engineering, like compiling companies’ vast bodies of knowledge into these structures, however, still represents a time-consuming, largely manually performed process, esp. with significant amounts of knowledge often only recorded within unstructured text documents. Since the recently introduced Large Language Models (LLMs) excel on text summarization, this raises the question whether these could be exploited within dedicated knowledge fusion architectures to assist human knowledge engineers by automatically suggesting relevant classes, instances and relations extracted from textual corpora. We therefore propose a novel approach that leverages the taxonomic structure of a partially defined ontology to prompt LLMs for hierarchical knowledge organization. Unlike conventional methods that rely solely on static ontologies, our methodology dynamically generates prompts based on the ontology’s existing class taxonomy, prompting the LLM to generate responses that extract supplementary information from unstructured documents. It thus introduces the concept of using ontologies as scaffolds for guiding LLMs, in order to realize a mutual interplay between structured ontological knowledge and the soft fusion capabilities of LLMs. We evaluate our proposed algorithm on a real-world case study, performing a knowledge fusion task on heterogeneous technical documentation from a medical prosthesis manufacturer.},
	journal = {2024 27th International Conference on Information Fusion (FUSION)},
	author = {Incitti, Francesca and Salfinger, Andrea and Snidaro, Lauro and Challapalli, Sri},
	month = jul,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Large Language Models, Large language model, Ontology, Ontology Population, Natural language processing, Language model, Large language models, Manufacturing, Knowledge engineering, Natural Language Processing, Taxonomies, Taxonomy, Knowledge Engineering, Organizations, Text summarization, Language processing, Documentation, Prosthetics, Manuals, Natural languages, Soft Fusion, Ontology's, Natural language processing systems, Case-studies, Scaffolds, Medical prosthesis, Scaffolds (biology), Soft fusions},
	pages = {1--8},
	annote = {Type: Conference paper}
}

@article{jaradeh2023AremotiveBridgingGap,
	file = {References/pdf/jaradeh2023AremotiveBridgingGap.pdf},
	title = {{ArEmotive} {Bridging} the {Gap}: {Automatic} {Ontology} {Augmentation} {Using} {Zero}-{Shot} {Classification} for {Fine}-{Grained} {Sentiment} {Analysis} of {Arabic} {Text}},
	volume = {11},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2023.3300737},
	abstract = {Human-computer interaction remains one of the final frontiers to conquer while held in perspective with the rapid developments and technology growth over recent years. It is an arduous task to convey the true human intent to the machine in order to generate a computerized relevant decision in a certain field. In recent years, focus has shifted to cover fields of study that relate to Sentiment Analysis (SA) to improve and ease the tasks of our daily lives. We Propose ArEmotive (Arabic Emotive), a fine-grained sentiment analysis system that is human-independent which can automatically grow its source of information allowing for more precision and a greater dataset each time it is used through ontology augmentation and classification. Our proposed architecture relies on multiple data sources running through certain pipelines to generate a central online repository utilized by any mobile system to access this info-base. This system is important because many researchers in the field of automated ontology alignment and ontology mapping achieved a semi-automated approach to map new ontologies out of old ones or to extend already existing ontologies with data from new ones. ArEmotive identifies fine-grained emotions in text based on a dynamic ontology enriched through ontology alignment, mapping and machine learning assisted classification, resulting in a structure that contributes in: a centralized dataset ever growing to fit the need of the users, a sustainable structure able to allocate new data sources without the need to modify the system, ability to generate appropriate information even with the absence of “parent” sources.},
	journal = {IEEE Access},
	author = {Jaradeh, Amer and Kurdy, Mohamad-Bassam},
	year = {2023},
	note = {Section: 0},
	keywords = {Ontologies, Sentiment analysis, Emotion recognition, Arabic NLP, Bridges, Soft sensors, Blogs, Social networking (online), Task analysis, fine-grained emotions, ontology augmentation},
	pages = {81318--81330}
}

@Book{jurafsky2025SpeechLanguageProcessing,
	file = {References/pdf/jurafsky2025SpeechNaturalProcessing.pdf},
	author = "Daniel Jurafsky and James H. Martin",
	title = "Speech and Language Processing: An Introduction to
                 Natural Language Processing, Computational Linguistics,
                 and Speech Recognition with Language Models",
	year = "2025",
	url = {https://web.stanford.edu/~jurafsky/slp3/},
	note = "Online manuscript released August 24, 2025",
	edition = "3rd"
}

@article{kalisz2024PromptEngineeringDomain,
	file = {References/pdf/kalisz2024PromptEngineeringDomain.pdf},
	title = {Prompt {Engineering} for {Domain}-{Oriented} {AI} {Support} {Tools}: {Ontologies}, {Mind} {Maps}, {Namespaces}, {Source} {Code} {Fragments}},
	volume = {1198},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201017640&doi=10.1007%2F978-3-031-61221-3_22&partnerID=40&md5=3dde669c6d90523827828f3386838acb},
	doi = {10.1007/978-3-031-61221-3_22},
	abstract = {Chat AI systems, recently popularised by ChatGPT, allow interactions by exchanging linear text messages. Graph-like structures introduced by Z.Hedrlín represent and transfer information better than the classical linear form. We examine the possibility of using these structures to improve communication with these AI systems. We show that it is possible to create a simple graph-like structure about a topic that better captures and transfers understanding of the AI system. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Electrical Engineering},
	author = {Kalisz, Vít and Kalisz, Adam},
	year = {2024},
	note = {Section: 0},
	keywords = {ChatGPT, LLM, Graph, Trees (mathematics), Mind maps, Chat AI, Concept maps, Diagram, Free structuring, Google bard, Google+, Graph-like structures, Knowledge tree, Non linear, Non-linear form, Non-linear structuring, Orgpad, Tony buzan, WEB application, Web applications},
	pages = {447 -- 482},
	annote = {Type: Conference paper}
}

@Article{kang2024WhatDoLearning,
	file = {References/pdf/kang2024WhatDoLearning.pdf},
	author = {Katie Kang and Amrith Setlur and Dibya Ghosh and
                  Jacob Steinhardt and Claire J. Tomlin and Sergey
                  Levine and Aviral Kumar},
	title = {What Do Learning Dynamics Reveal About
                  Generalization in {LLM} Reasoning?},
	journal = {CoRR},
	year = 2024,
	volume = {abs/2411.07681},
	doi = {10.48550/ARXIV.2411.07681},
	eprint = {2411.07681},
	eprinttype = {arXiv},
	url = {https://doi.org/10.48550/arXiv.2411.07681},
	timestamp = {Wed, 01 Jan 2025 11:02:43 +0100},
	biburl = {https://dblp.org/rec/journals/corr/abs-2411-07681.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@Article{kaplan2020ScalingLawsNeural,
	file = {References/pdf/kaplan2020ScalingLawsNeural.pdf},
	author = {Jared Kaplan and Sam McCandlish and Tom Henighan and
                  Tom B. Brown and Benjamin Chess and Rewon Child and
                  Scott Gray and Alec Radford and Jeffrey Wu and Dario
                  Amodei},
	title = {Scaling Laws for Neural Language Models},
	journal = {CoRR},
	year = 2020,
	volume = {abs/2001.08361},
	eprint = {2001.08361},
	eprinttype = {arXiv},
	url = {https://arxiv.org/abs/2001.08361},
	timestamp = {Wed, 03 Jun 2020 10:55:13 +0200},
	biburl = {https://dblp.org/rec/journals/corr/abs-2001-08361.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{karmakar2024UnstructuredDataKnowledge,
	file = {References/pdf/karmakar2024UnstructuredDataKnowledge.pdf},
	title = {From {Unstructured} {Data} to {Knowledge} {Graphs}: {An} {Application} for {Compliance} {Checking} {Problem}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199652264&doi=10.22260%2FISARC2024%2F0112&partnerID=40&md5=6ede5ec9b90cd0b85d18aebed8162b28},
	doi = {10.22260/ISARC2024/0112},
	abstract = {The rule requirements of a building code are frequently violated to create financially viable designs. These deviations are subjected to condonation by the municipal commissioner if recognizable hardships are faced. The historical concession applications for similar cases are stored in an unstructured manner, creating a barrier to knowledge transfer. The subjective statements given by applicants are composed of logical structure, language, and embedded knowledge that requires years of experience from the domain expert to decipher. A knowledge graph (KG) representation of the problem can capture concepts and represent them visually, which is easy for novice stakeholders to understand. A Large Language Model (LLM)-based method is used in this study for ontology extraction in the form of concepts and relationships. Also, unstructured input preprocessing and entity disambiguation were performed to evaluate the applicability of KG in this domain. The performance of the proposed method was checked qualitatively in a case study from real-life project examples. The limitations and scopes for improvements were also highlighted. The outcome of this study indicates KG as a potential candidate for knowledge generation from the unstructured archival data of compliance checking. The target audience for this application can be the new architects, reviewers, and programmers working on developing the end-to-end automated compliance checking systems. Finally, applying these Artificial Intelligence (AI)-based knowledge transfer mechanisms can ignite future research on automated concession applications and approvals, laying a path to the digital transformation of the industry. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Proceedings of the International Symposium on Automation and Robotics in Construction},
	author = {Karmakar, Ankan and Patel, Chintan and Delhi, Venkata Santosh Kumar},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Compliance checking, Knowledge management, Unstructured data, Graph representation, Code compliance checking, Knowledge transfer, Domain experts, Compliance control, Code compliance, Logical structure, Similar case},
	pages = {863 -- 871},
	annote = {Type: Conference paper}
}

@article{katyshev2023UsingTransformerModels,
	file = {References/pdf/katyshev2023UsingTransformerModels.pdf},
	series = {{SIGCSE} 2023},
	title = {Using {Transformer} {Models} for {Knowledge} {Graph} {Construction} in {Computer} {Science} {Education}},
	url = {https://doi.org/10.1145/3545947.3576365},
	doi = {10.1145/3545947.3576365},
	abstract = {The volume of information that can be used in the development of knowledge bases that can be used in education is constantly increasing. Also, this amount of data is very difficult to process and store. When designing a knowledge base to optimize the educational process, it is important to use ontologies. At the moment, the creation of an ontological knowledge model is the most promising option for storing and processing information. The article describes effective approaches for generating an ontological model using machine learning models based on the Transformer model.},
	journal = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
	author = {Katyshev, Alexander and Anikin, Anton and Sychev, Oleg},
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {machine learning, ontologies, semantics, transformers, neural networks, concepts, ontological graph, relations between concepts},
	pages = {1421},
	annote = {event-place: Toronto ON, Canada}
}

@Article{keet2018IntroductionOntologyEngineering,
	file = {References/pdf/keet2018IntroductionOntologyEngineering.pdf},
	title = {An introduction to ontology engineering},
	author = {Keet, C Maria},
	year = {2018},
	publisher = {University of Cape Town}
}

@Article{khadir2021OntologyLearningGrand,
	file = {References/pdf/khadir2021OntologyLearningGrand.pdf},
	author = {Ahlem Ch{\'{e}}rifa Khadir and Hassina Aliane and
                  Ahmed Guessoum},
	title = {Ontology learning: Grand tour and challenges},
	journal = {Comput. Sci. Rev.},
	year = 2021,
	volume = 39,
	pages = 100339,
	doi = {10.1016/J.COSREV.2020.100339},
	url = {https://doi.org/10.1016/j.cosrev.2020.100339},
	timestamp = {Tue, 02 Mar 2021 11:25:32 +0100},
	biburl = {https://dblp.org/rec/journals/csr/KhadirAG21.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{khalov2025AutomaticMappingUpper,
	file = {References/pdf/khalov2025AutomaticMappingUpper.pdf},
	title = {Automatic {Mapping} of {Upper}-{Level} {Ontology} {Classes} ({DOLCE}) and {Domain}-{Specific} {Ontology} {ITSMO}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012762960&doi=10.1109%2FICAIBD64986.2025.11082040&partnerID=40&md5=03a58282e7ad85da2118c7855a3ebada},
	doi = {10.1109/ICAIBD64986.2025.11082040},
	abstract = {This paper proposes a method for extending the top-level ontology DOLCE (DOLCE-lite version, referred to as TLO) to the domain of IT services without expert involvement. The main challenge addressed is the automatic mapping of classes in conditions of a small number of objects ({\textbackslash}textless100) and the absence of annotated data. A review of existing approaches is conducted, their limitations are identified, and novel mapping methods are proposed, integrating embeddings and large language models. The suggested method achieved an 82.35\% mapping accuracy when integrating DOLCE and ITSMO ontologies. As a result, the ITO-seed ontology was developed, containing linked classes from DOLCE and ITSMO, which can be utilized in further research and in building knowledge graphs for IT Service Management (ITSM) systems.},
	journal = {2025 8th International Conference on Artificial Intelligence and Big Data (ICAIBD)},
	author = {Khalov, Andrey and Ataeva, Olga},
	month = may,
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Knowledge graphs, Ontology, Artificial intelligence, Large language models, GPT, BERT, Knowledge management, OWL, RDF, Resource description framework, Transformers, Prompt engineering, Information systems, prompt engineering, Reviews, mapping, clustering, Mapping, Graph neural networks, DOLCE, ITIL, owl2vec, rdf2vec, Ontology's, Birds, Clusterings, Owl2vec, Rdf2vec},
	pages = {795--802},
	annote = {ISSN: 2769-3554}
}

@article{khorashadizadeh2025ConstructionCanonicalizationEconomic,
	file = {References/pdf/khorashadizadeh2025ConstructionCanonicalizationEconomic.pdf},
	title = {Construction and {Canonicalization} of {Economic} {Knowledge} {Graphs} with {LLMs}},
	volume = {15459},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218928651&doi=10.1007%2F978-3-031-81221-7_23&partnerID=40&md5=94c3a938e4ac09f1e4a9b680f71629dc},
	doi = {10.1007/978-3-031-81221-7_23},
	abstract = {Ontology-based knowledge graphs, such as YAGO and Wikidata, rely on pre-defined schemas to organize and connect information. While effective, these systems are inherently domain-specific, requiring tailored ontologies that are costly, time-consuming, and demand expert knowledge to develop. To address these limitations, Open Information Extraction (OpenIE) offers a complementary approach by extracting structured information directly from unstructured text without needing a predefined schema. However, OpenIE results in a vast number of relations, often leading to redundancy and inconsistencies. To overcome this, we propose a novel approach that leverages Large Language Models (LLMs) for constructing a knowledge graph and for canonicalizing relations within it. Our method includes generating question-answer pairs from text, extracting triples from these pairs, and applying a two-step canonicalization process to ensure consistency and reduce redundancy. This paper presents our approach in detail, exploring related work, the construction of the knowledge graph, the canonicalization process, and the evaluation of our methods. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Khorashadizadeh, Hanieh and Mihindukulasooriya, Nandana and Ranji, Nilufar and Ezzabady, Morteza Kamaladdini and Ieng, Frédéric and Groppe, Jinghua and Benamara, Farah and Groppe, Sven Thilo},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Expert knowledge, Ontology-based, Open information extraction, Canonicalization, Ontology's, Domain specific, Economic knowledge},
	pages = {334 -- 343},
	annote = {Type: Conference paper}
}

@article{kim2025LlmAssistedOntology,
	file = {References/pdf/kim2025LlmAssistedOntology.pdf},
	title = {{LLM}-{Assisted} {Ontology} {Restriction} {Verification} {With} {Clustering}-{Based} {Description} {Generation}},
	volume = {13},
	issn = {2169-3536},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003435799&doi=10.1109%2FACCESS.2025.3562560&partnerID=40&md5=7fb7ff39e7103d7aba92020f3d6a17d9},
	doi = {10.1109/ACCESS.2025.3562560},
	abstract = {An ontology is a scheme for structuring relationships between concepts in a domain, promoting data interoperability and system integration. However, poorly designed ontologies can lead to errors and performance issues. While systems engineering has standardized evaluation guidelines (e.g., ISO/IEC), ontology engineering lacks such standards, leading to various independent evaluation methods. One frequent issue among novice developers is the misuse of ontology restrictions, particularly ‘allValuesFrom’ and ‘someValuesFrom’, which can significantly impact the correctness and reliability of ontologies. However, existing studies have not adequately addressed effective methods for detecting such errors. To address this gap, we propose a context-aware verification framework utilizing large language models to detect and correct misuse in ontology restrictions. Unlike conventional methods, our framework integrates contextual descriptions derived from ontological axioms, enabling more accurate verification. Additionally, we introduce a clustering-based description generation method that systematically organizes contextual information, further enhancing verification accuracy. Experimental evaluation conducted on diverse ontology datasets suggests that contextual integration improves verification performance. Moreover, the clustering-based description generation improves restriction misuse detection and correction compared to traditional approaches. By automating ontology restriction verification, this study contributes significantly to enhancing the reliability of ontology evaluation and provides a foundation for developing more scalable and standardized verification techniques.},
	journal = {IEEE Access},
	author = {Kim, Seungyeon and Kim, Donghyun and Hwang, Seokju and Lee, Kyong-Ho and Lee, Kyunghwa},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Interoperability, Ontology, Semantics, Data interoperability, Ontology evaluation, System integration, Reliability, Software, Quality assessment, clustering, Scalability, Translation, Accuracy, text generation, Data systems, ISO Standards, IEC Standards, ontology restriction verification, Ontology's, Relationship between concepts, Ontology evaluations, Text generations, Clusterings, Ontology restriction verification, Performance issues},
	pages = {73603--73618},
	annote = {Type: Article}
}

@article{kollapally2024OntologySocialDeterminants,
	file = {References/pdf/kollapally2024OntologySocialDeterminants.pdf},
	title = {An {Ontology} for {Social} {Determinants} of {Education} ({SDoEd}) {Based} on {Human}-{AI} {Collaborative} {Approach}},
	volume = {40},
	issn = {1937-4771},
	abstract = {The use of computational ontologies is well-established in the field of Medical Informatics. The topic of Social Determinants of Health (SDoH) has also received extensive attention. Work at the intersection of ontologies and SDoH has been published. However, a standardized framework for Social Determinants of Education (SDoEd) is lacking. In this paper, we are closing the gap by introducing an SDoEd ontology for creating a precise conceptualization of the interplay between life circumstances of students and their possible educational achievements. The ontology was developed utilizing suggestions from ChatGPT-3.5-010422 and validated using peer-reviewed research articles. The first version of developed ontology was evaluated by human experts in the field of education and validated using standard ontology evaluation software. This version of the SDoEd ontology contains 231 domain concepts, 10 object properties, and 24 data properties.},
	number = {3},
	journal = {J. Comput. Sci. Coll.},
	author = {Kollapally, Navya Martin and Geller, James and Morreale, Patricia and Kwak, Daehan},
	month = oct,
	year = {2024},
	note = {Section: 0},
	pages = {191--203},
	annote = {Place: Evansville, IN, USA Publisher: Consortium for Computing Sciences in Colleges}
}

@article{kollapally2025OntologyEnrichmentUsing,
	file = {References/pdf/kollapally2025OntologyEnrichmentUsing.pdf},
	title = {Ontology enrichment using a large language model: {Applying} lexical, semantic, and knowledge network-based similarity for concept placement},
	volume = {168},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009015837&doi=10.1016%2Fj.jbi.2025.104865&partnerID=40&md5=048cd0ae96fafa94aebcf8534267778c},
	doi = {10.1016/j.jbi.2025.104865},
	abstract = {Objective: Ontologies are essential for representing the knowledge of a domain. To make ontologies useful, they must encompass a comprehensive domain view. To achieve ontology enrichment, there is a need to discover new concepts to be added, either because they were missed in the first place, or the state-of-the-art has advanced to develop new real-world concepts. Our goal is to develop an automatic enrichment pipeline using a seed ontology, a Large Language Model (LLM), and source of text. The pipeline is applied to the domain of Social Determinants of Health (SDoH), using PubMed as a source of concepts. In this work, the applicability and effectiveness of the enrichment pipeline is demonstrated by extending the SDoH Ontology called SOHOv1, however our methodology could be used in other domains as well. Methods: We first retrieved PubMed abstracts of candidate articles with existing SOHOv1 concepts as search terms. Next, we used GPT-4-1201 to extract semantic triples from the abstracts. We identified concepts from these triples utilizing lexical, semantic, and knowledge network-based filtering. We also compared the granularity of semantic triples extracted with our method to the triples in the SemMedDB (Semantic MEDLINE Database). The results were evaluated by human experts and standard ontology tools for checking consistency and semantic correctness. Results: We expanded SOHOv1, which contained 173 concepts and 585 axioms, including 207 logical axioms to SOHOv2, which contains 572 concepts, 1,542 axioms, including 725 logical axioms. Our methods identified more concepts than those extracted from SemMedDB for the same task. While we have shown the feasibility of our approach for an SDoH ontology, the methodology is generalizable to other ontologies with an existing seed ontology and text corpus. Conclusions: The contributions of this work are: Extracting semantic triples from PubMed abstracts using GPT-4-1201 utilizing prompt chaining; showing the superiority of triples from GPT-4-1201 over triples from SemMedDB for SDoH; using lexical and semantic similarity search techniques with knowledge network-based search to identify the concepts to be added to the ontology; confirming the quality of the new concepts with human experts. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Journal of Biomedical Informatics},
	author = {Kollapally, Navya Martin and Geller, J. and Keloth, Vipina Kuttichi and He, Zhe and Xu, Julia},
	year = {2025},
	note = {Section: 0},
	keywords = {large language model, Large Language Models, Large language model, Ontology, Language model, Semantic Web, Semantics, data extraction, natural language processing, ontology, Search engines, Ontology enrichment, Semantic MEDLINE, Semantic MEDLINE database, Similarity search, Natural Language Processing, semantics, social determinants of health, safety, PubMed, Language, Data mining, Biological Ontologies, education, Knowledge organization, Knowledge based systems, knowledge, Computational linguistics, Database systems, community, ontology enrichment, built environment, depression, human, language, ontology development, Learning systems, Humans, Article, biological ontology, generative pretrained transformer, Medline, Natural language processing systems, Abstracting, academic failure, alcohol consumption, economic instability, health care access, health care disparity, high risk behavior, intermethod comparison, MEDLINE database, natural disaster, neighborhood, Ontology evaluations, Semantic MEDLINE database database, social aspect, Social determinants of healths},
	annote = {Type: Article}
}

@article{komarlu2024OntotypeOntologyGuided,
	file = {References/pdf/komarlu2024OntotypeOntologyGuided.pdf},
	series = {{KDD} '24},
	title = {{OntoType}: {Ontology}-{Guided} and {Pre}-{Trained} {Language} {Model} {Assisted} {Fine}-{Grained} {Entity} {Typing}},
	url = {https://doi.org/10.1145/3637528.3671745},
	doi = {10.1145/3637528.3671745},
	abstract = {Fine-grained entity typing (FET), which assigns entities in text with context-sensitive, fine-grained semantic types, is a basic but important task for knowledge extraction from unstructured text. FET has been studied extensively in natural language processing and typically relies on human-annotated corpora for training, which is costly and difficult to scale. Recent studies explore the utilization of pre-trained language models (PLMs) as a knowledge base to generate rich and context-aware weak supervision for FET. However, a PLM still requires direction and guidance to serve as a knowledge base as they often generate a mixture of rough and fine-grained types, or tokens unsuitable for typing. In this study, we vision that an ontology provides a semantics-rich, hierarchical structure, which will help select the best results generated by multiple PLM models and head words. Specifically, we propose a novel annotation-free, ontology-guided FET method, OntoType, which follows a type ontological structure, from coarse to fine, ensembles multiple PLM prompting results to generate a set of type candidates, and refines its type resolution, under the local context with a natural language inference model. Our experiments on the Ontonotes, FIGER, and NYT datasets using their associated ontological structures demonstrate that our method outperforms the state-of-the-art zero-shot fine-grained entity typing methods as well as a typical LLM method, ChatGPT. Our error analysis shows that refinement of the existing ontology structures will further improve fine-grained entity typing.},
	journal = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
	author = {Komarlu, Tanay and Jiang, Minhao and Wang, Xuan and Han, Jiawei},
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Ontology, Language model, Semantics, Modeling languages, Fine-grained entity typing, Natural language understanding, natural language understanding, fine-grained entity typing, masked language model prompting, zero-shot entity typing, Natural languages, Ontology's, Natural language processing systems, Inference engines, Economic and social effects, Fine grained, Context sensitive languages, Context-sensitive, Masked language model prompting, Ontological structures, Zero-shot entity typing},
	pages = {1407--1417},
	annote = {event-place: Barcelona, Spain}
}

@Article{kommineni2024HumanExpertsMachines,
	file = {References/pdf/kommineni2024HumanExpertsMachines.pdf},
	author = {Vamsi Krishna Kommineni and Birgitta
                  K{\"{o}}nig{-}Ries and Sheeba Samuel},
	title = {From human experts to machines: An {LLM} supported
                  approach to ontology and knowledge graph
                  construction},
	journal = {CoRR},
	year = 2024,
	volume = {abs/2403.08345},
	doi = {10.48550/ARXIV.2403.08345},
	eprint = {2403.08345},
	eprinttype = {arXiv},
	url = {https://doi.org/10.48550/arXiv.2403.08345},
	timestamp = {Fri, 05 Apr 2024 14:02:06 +0200},
	biburl = {https://dblp.org/rec/journals/corr/abs-2403-08345.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{kommineni2024TowardsAutomationKnowledge,
	file = {References/pdf/kommineni2024TowardsAutomationKnowledge.pdf},
	title = {Towards the {Automation} of {Knowledge} {Graph} {Construction} {Using} {Large} {Language} {Models}},
	volume = {3874},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214197878&partnerID=40&md5=c4ce0ae9c8b2f8c98f2364b50cb3c716},
	abstract = {The conventional process of building Ontologies and Knowledge Graphs (KGs) heavily relies on human domain experts to define entities and relationship types, establish hierarchies, maintain relevance to the domain, fill the ABox (i.e., populate with instances), and ensure data quality (including amongst others accuracy and completeness). On the other hand, Large Language Models (LLMs) have recently gained popularity for their ability to understand and generate human-like natural language, offering promising ways to automate aspects of this process. This work explores the (semi-)automatic construction of KGs facilitated by different state-of-the-art LLMs: Mixtral 8x22B Instruct v0.1, GPT-4o, GPT-3.5, and Gemini. Our pipeline involves formulating competency questions (CQs), developing an ontology (TBox) based on these CQs, constructing KGs using the developed ontology, and evaluating the resultant KG with minimal to no involvement of human experts. We showcase the feasibility of our semi-automated pipeline by creating a KG on deep learning methodologies by exploiting scholarly publications. The answers generated via Retrieval-Augmented-Generation (RAG) were evaluated by a domain expert manually, and the KG was evaluated by matching the KG individuals to RAG-generated answers. Our findings suggest that employing LLMs could potentially reduce the human effort involved in the construction of KGs, although a human-in-the-loop approach is recommended to evaluate automatically generated KGs. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Kommineni, Vamsi Krishna and König-Ries, Birgitta and Samuel, Sheeba},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Deep learning, Search engines, Modeling languages, Retrieval-augmented generation, Competency question, Graph construction, Domain Knowledge, Ontology's, Natural language processing systems, Ontology graphs, Domain experts, Human domain},
	pages = {19 -- 34},
	annote = {Type: Conference paper}
}

@article{kordi2025UsageChatgptIntegrating,
	file = {References/pdf/kordi2025UsageChatgptIntegrating.pdf},
	title = {On the {Usage} of {ChatGPT} for {Integrating} {CAPEC} {Attacks} into {ADVISE} {Meta} {Ontology}},
	volume = {3962},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005835334&partnerID=40&md5=f59155512fca30b7fdaed22c4beed35f},
	abstract = {In today’s cybersecurity landscape, robust security assessment methodologies are essential for evaluating and improving systems, networks, applications, and data security. Modeling and simulation play an important role in this process by providing meaningful representations and analyses of attacks and defense strategies, particularly in systems where security breaches could have devastating consequences. The ADversary VIew Security Evaluation (ADVISE) Meta framework offers an ontology-based approach that, starting from a system’s architectural model, automatically generates detailed security models representing the attack steps that adversaries might take to achieve their goals. Manually extending the ADVISE Meta ontology with specific attack patterns is a challenging task that involves a deep understanding of the ontology, and its semantics. It also requires analyzing the attack paths to identify the necessary information in the ontology. To address this challenge we propose a methodology to facilitate the integration of attack patterns into the ADVISE Meta framework using ChatGPT. We focus on the Common Attack Pattern Enumeration and Classification (CAPEC) catalog by MITRE, a popular catalog with more than 500 attack patterns describing the common attributes and approaches used by adversaries to exploit known weaknesses in IT systems. ChatGPT is used as a support tool to interpret the descriptions of the attacks in the CAPEC catalog and systematically integrate the interpreted data into the ADVISE Meta ontology to generate the attack steps. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Kordi, Marzieh and Mariotti, Francesco and Magrini, Roberto and Lollini, Paolo and Bondavalli, Andrea},
	year = {2025},
	note = {Section: 0},
	keywords = {ChatGPT, LLM, Cyber security, Security evaluation, Security modeling, Ontology's, Attack patterns, Common attack pattern enumeration and classification, Cyber attacks, Meta-frameworks, Meta-ontology},
	annote = {Type: Conference paper}
}

@article{kossack2021TomMatcherResults,
	file = {References/pdf/kossack2021TomMatcherResults.pdf},
	title = {{TOM} {Matcher} {Results} for {OAEI} 2021},
	volume = {3063},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122692672&partnerID=40&md5=166ae259e2baee385eae401561937313},
	abstract = {This paper presents the matching system TOM together with its results in the Ontology Alignment Evaluation Initiative 2021 (OAEI 2021). This is the first participation of TOM in the OAEI. Very recently, transformers achieved remarkable results in the natural language processing community on a variety of tasks. The TOM match- ing system exploits a zero-shot transformer-based language model to cal- culate confidences for each instance. The matcher uses the pre-trained transformer model paraphrase-TinyBERT-L6-v2.3 © 2022 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Kossack, Daniel and Borg, Niklas and Knorr, Leon and Portisch, Jan Philipp},
	year = {2021},
	note = {Section: 0},
	keywords = {Ontology, Language model, Ontology matching, Ontology alignment, Transformer, Natural language processing systems, Matching system, Transformer modeling, Language mod- els},
	pages = {193 -- 198},
	annote = {Type: Conference paper}
}

@Article{kotis2020OntologyEngineeringMethodologies,
	file = {References/pdf/kotis2020OntologyEngineeringMethodologies.pdf},
	author = {Konstantinos I. Kotis and George A. Vouros and
                  Dimitris Spiliotopoulos},
	title = {Ontology engineering methodologies for the evolution
                  of living and reused ontologies: status, trends,
                  findings and recommendations},
	journal = {Knowl. Eng. Rev.},
	year = 2020,
	volume = 35,
	pages = {e4},
	doi = {10.1017/S0269888920000065},
	url = {https://doi.org/10.1017/S0269888920000065},
	timestamp = {Sun, 12 Nov 2023 02:18:47 +0100},
	biburl = {https://dblp.org/rec/journals/ker/KotisVS20.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{kougioumtzidou2024EndEndFramework,
	file = {References/pdf/kougioumtzidou2024EndEndFramework.pdf},
	title = {An {End}-to-{End} {Framework} for {Cybersecurity} {Taxonomy} and {Ontology} {Generation} and {Updating}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206170969&doi=10.1109%2FCSR61664.2024.10679346&partnerID=40&md5=6b9b5f05f1f9120cb0652ff6fa09d2ad},
	doi = {10.1109/CSR61664.2024.10679346},
	abstract = {Effective cyber-defense practices often require the use of structured knowledge representations, such as taxonomies and ontologies, to organise vast amounts of data and facili-tate knowledge representation and reasoning. To this end, we present an Artificial Intelligence (AI)-assisted framework for the construction and update of cybersecurity taxonomies and ontologies. The proposed framework can be divided into three main phases: Taxonomy Construction, Ontology Construction, and Taxonomy/Ontology Update, each phase consisting of both information extraction and semantic knowledge representation components. For information extraction, we employ a variety of techniques originating from Natural Language Processing (NLP), particularly Transformer Neural Networks. For constructing ontologies, we propose a conceptual ontology schema based on the STIX 2.1 standard for modeling information related to attacks, threats, and vulnerabilities, and use the Owlready2 Python library. Overall, our framework effectively builds cybersecurity taxonomies and ontologies and updates existing knowledge of both the generated and open-source taxonomies and ontologies.},
	journal = {2024 IEEE International Conference on Cyber Security and Resilience (CSR)},
	author = {Kougioumtzidou, Anna and Papoutsis, Angelos and Kavallieros, Dimitrios and Mavropoulos, Thanassis and Tsikrika, Theodora and Vrochidis, Stefanos and Kompatsiaris, Ioannis},
	month = sep,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Large language model, Natural language processing, Language model, Semantics, artificial intelligence, large language models, natural language processing, ontologies, Cyber security, Knowledge representation, Semantic search, Transformers, Taxonomy, Dynamic update, cybersecurity, Vulnerability, Attack, Language processing, taxonomies, Natural languages, Smart grids, Filtering, attacks, dynamic update, vulnerabilities, Ontology's, Cyber attacks, Phishing},
	pages = {247--254},
	annote = {Type: Conference paper}
}

@article{langer2024CearAutomaticConstruction,
	file = {References/pdf/langer2024CearAutomaticConstruction.pdf},
	title = {{CEAR}: {Automatic} construction of a knowledge graph of chemical entities and roles from scientific literature},
	volume = {3882},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214555647&partnerID=40&md5=04edc0d3b18355b78d45472177627d17},
	journal = {CEUR Workshop Proceedings},
	author = {Langer, Stefan and Neuhaus, Fabian and Nürnberger, Andreas},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Named entity recognition, Ontology's, Automatic construction, Chemical entity, ChEBI, Formal representations, Scientific literature},
	annote = {Type: Conference paper}
}

@InProceedings{levenshtein1966BinaryCodesCapable,
	file = {References/pdf/levenshtein1966BinaryCodesCapable.pdf},
	title = {Binary codes capable of correcting deletions, insertions, and reversals},
	author = {Levenshtein, VI},
	booktitle = {Soviet physics-doklady},
	volume = {10},
	number = {8},
	year = {1966}
}

@article{li2023DistillingSemanticConcept,
	file = {References/pdf/li2023DistillingSemanticConcept.pdf},
	series = {{SIGIR} '23},
	title = {Distilling {Semantic} {Concept} {Embeddings} from {Contrastively} {Fine}-{Tuned} {Language} {Models}},
	url = {https://doi.org/10.1145/3539618.3591667},
	doi = {10.1145/3539618.3591667},
	abstract = {Learning vectors that capture the meaning of concepts remains a fundamental challenge. Somewhat surprisingly, perhaps, pre-trained language models have thus far only enabled modest improvements to the quality of such concept embeddings. Current strategies for using language models typically represent a concept by averaging the contextualised representations of its mentions in some corpus. This is potentially sub-optimal for at least two reasons. First, contextualised word vectors have an unusual geometry, which hampers downstream tasks. Second, concept embeddings should capture the semantic properties of concepts, whereas contextualised word vectors are also affected by other factors. To address these issues, we propose two contrastive learning strategies, based on the view that whenever two sentences reveal similar properties, the corresponding contextualised vectors should also be similar. One strategy is fully unsupervised, estimating the properties which are expressed in a sentence from the neighbourhood structure of the contextualised word embeddings. The second strategy instead relies on a distant supervision signal from ConceptNet. Our experimental results show that the resulting vectors substantially outperform existing concept embeddings in predicting the semantic properties of concepts, with the ConceptNet-based strategy achieving the best results. These findings are furthermore confirmed in a clustering task and in the downstream task of ontology completion.},
	journal = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	author = {Li, Na and Kteich, Hanane and Bouraoui, Zied and Schockaert, Steven},
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Language model, Semantics, language models, Embeddings, Word embedding, Contrastive learning, Computational linguistics, word embedding, ConceptNet, Commonsense knowledge, commonsense knowledge, contrastive learning, Vectors, Property, Down-stream, Word vectors, Semantic properties},
	pages = {216--226},
	annote = {event-place: Taipei, Taiwan}
}

@article{li2024LargeLanguageModel,
	file = {References/pdf/li2024LargeLanguageModel.pdf},
	title = {A {Large} {Language} {Model} {Based} {Knowledge} {Mining} {Method} for {Improving} the {Reliability} of {Fire} {Water} {Systems}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215273182&doi=10.1109%2FSRSE63568.2024.10772514&partnerID=40&md5=0b65baf1820c442bba07118662a1fbd9},
	doi = {10.1109/SRSE63568.2024.10772514},
	abstract = {The fire water system plays a critical role in protecting both infrastructure and human lives. An essential aspect of enhancing the reliability of this system is fault diagnosis. However, the current fault diagnosis methods primarily rely on data-driven approaches, which often result in a high threshold for application due to their lack of interpretability. To tackle this challenge, this paper introduces a novel approach based on large language models for knowledge mining from textual data to extract fault information related to the fire water system, thereby enhancing the interpretability of data-driven fault diagnosis methods. The methodology followed in this paper consists of two main steps: firstly, analyzing the characteristics and principles of fire water system faults to develop a fault ontology, and secondly, creating a knowledge mining model using a large language model guided by the established fault ontology. Experimental findings indicate that the proposed model achieves an F1 score of 0.944, meeting the necessary criteria for effective knowledge mining in fire water system fault analysis. Furthermore, a comparative experiment was conducted to evaluate the performance of various encoder models, including GRU, BiGRU, LSTM, BiLSTM, and pre-trained large language model BERT. The results revealed a significant improvement in performance with the BERT encoder, showing increases in F1 scores of 22.12 \%, 2.27 \%, 17.41 \%, and 3.16 \% compared to the other models, respectively. This study provides valuable interpretative insights that can enhance the engineering applicability and reliability of data-driven fault diagnosis methods in fire water system.},
	journal = {2024 6th International Conference on System Reliability and Safety Engineering (SRSE)},
	author = {Li, Yi and Tian, Liwei and Yi, Chengyi and Li, Jingjing and Qin, Xiaodong and He, Yuxuan and Su, Huai},
	month = oct,
	year = {2024},
	note = {Section: 0},
	keywords = {large language model, Ontologies, Large language model, Language model, Large language models, Fault diagnosis, Data mining, Knowledge based systems, safety engineering, Intelligent systems, Interpretability, Knowledge mining, Water, Accuracy, Encoding, Bidirectional control, Analytical models, Reliability engineering, fire water system, knowledge mining, system reliability, Systems analysis, Data-driven fault diagnosis, Fault diagnosis method, Fire protection, Fire water system, Mine fires, System faults, System reliability, Water system},
	pages = {410--413},
	annote = {Type: Conference paper}
}

@article{li2024LlmDrivenOntology,
	file = {References/pdf/li2024LlmDrivenOntology.pdf},
	title = {{LLM}-{Driven} {Ontology} {Learning} to {Augment} {Student} {Performance} {Analysis} in {Higher} {Education}},
	volume = {14886},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200754108&doi=10.1007%2F978-981-97-5498-4_5&partnerID=40&md5=b38d1eef02307126f549df7cd2a0491c},
	doi = {10.1007/978-981-97-5498-4_5},
	abstract = {In educational settings, a challenge is the lack of linked and labeled data, hindering effective analysis. The integration of ontology facilitates the formulation of educational knowledge concepts, student behaviors, and their relations. Traditional ontology creation requires deep domain knowledge and significant manual effort. However, advancements in Large Language Models (LLMs) have offered a novel opportunity to automate and refine this process. In this paper, we propose an LLMs-driven educational ontology learning approach aimed to enhance student performance predictions. We leverage LLMs to process lecture slide texts to identify knowledge concepts and their interrelations, while question texts are used to associate them with the concepts they assess. This process facilitates the generation of the educational ontology that links knowledge concepts and maps to student interactions. Additionally, we deploy a dual-branch Graph Neural Network (GNN) with distance-weighted pooling to analyze both global and local graph information for student performance prediction. Our empirical results demonstrate the effectiveness of using LLMs for ontology-based enhancements in educational settings. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Li, Gen and Tang, Cheng and Chen, Li and Deguchi, Daisuke and Yamashita, Takayoshi and Shimada, Atsushi},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Knowledge management, Data mining, Performance prediction, Forecasting, Graph neural networks, Student performance prediction, Educational data mining, Students, Model-driven, Domain Knowledge, Ontology's, Education computing, Student performance},
	pages = {57 -- 68},
	annote = {Type: Conference paper}
}

@article{li2025AnchoredSemanticsAugmenting,
	file = {References/pdf/li2025AnchoredSemanticsAugmenting.pdf},
	title = {Anchored {Semantics}: {Augmenting} {Ontologies} via {Competency} {Questions}, {Self}-{Attention}, and {Predictive} {Graph} {Learning}},
	volume = {15906},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010817112&doi=10.1007%2F978-3-031-97635-3_23&partnerID=40&md5=a79006385e5bb752062dec2d382cd7a3},
	doi = {10.1007/978-3-031-97635-3_23},
	abstract = {We propose a framework that enriches ontologies by leveraging competency questions and distant supervision. The process begins by using an LLM to extract domain-relevant entities from the questions, followed by incremental refinement through short definitions anchored to a predefined dictionary. These entities and their hierarchies, along with associated queries, are embedded using a fine-tuned Llama3.2:1b and further processed through a self-attention mechanism to create unified representations. A directed acyclic graph models the dependencies between entities, with additional nodes derived from frequent co-occurrences in queries. A Graph Attention Network (GAT) is used for stable link prediction, discovering latent semantic relationships. These links are then labeled with specific relation types using a fine-tuned RoBERTa module. Evaluations using datasets from HPC training sessions and OpenAlex abstracts show significant improvements in link prediction and ontology enrichment over standard GAT and GraphSage baselines. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Li, Shengqi and Gupta, Amarnath},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology, Semantics, Link prediction, Competency question, Query processing, Distant supervision, Graph embeddings, Latent semantic analysis, Latent semantics, Undirected graphs, Attention mechanisms, Ontology's, Co-occurrence, Directed acyclic graph model, Directed graphs, Ontology augmentation},
	pages = {189 -- 197},
	annote = {Type: Conference paper}
}

@article{li2025ErnieUieAdvancing,
	file = {References/pdf/li2025ErnieUieAdvancing.pdf},
	title = {{ERNIE}-{UIE}: {Advancing} information extraction in {Chinese} medical knowledge graph},
	volume = {20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006545313&doi=10.1371%2Fjournal.pone.0325082&partnerID=40&md5=3597a24d4c3511060023944baefbfb17},
	doi = {10.1371/journal.pone.0325082},
	abstract = {Background The field of information extraction (IE) is currently exploring more versatile and efficient methods for minimization of reliance on extensive annotated datasets and integration of knowledge across tasks and domains. Objective We aim to evaluate and refine the application of the universal IE (UIE) technology in the field of Chinese medical expertise in terms of processing accuracy and efficiency. Methods Our model integrates ontology modeling, web scraping, UIE, fine-tuning strategies, and graph databases, thereby covering knowledge modeling, extraction, and storage techniques. The Enhanced Representation through Knowledge Integration-UIE (ERNIE-UIE) model is fine-tuned and optimized using a small amount of annotated data. A medical knowledge graph is then constructed, followed by validating the graph and conducting knowledge mining on the data stored within it. Results Incorporating the characteristics of whole-course management, we implemented a comprehensive medical knowledge graph–construction model and methodology. Entities and relationships were jointly extracted using the pretrained language model, resulting in 8,525 entity data points and 9,522 triple data points. The accuracy of the knowledge graph was verified using graph algorithms. Conclusion We optimized the construction process of a Chinese medical knowledge graph with minimal annotated data by utilizing a generative extraction paradigm, validating the graph’s efficacy and achieving commendable results. This approach addresses the challenge of insufficient annotated training corpora in low-resource knowledge graph construction, thereby contributing to cost savings in the development of knowledge graphs. © 2025 Elsevier B.V., All rights reserved.},
	number = {5},
	journal = {PLOS ONE},
	author = {Li, Bei and Li, Changbiao and Sun, Jianwei and Zeng, Xu and Chen, Xiaofan and Zheng, Jing},
	year = {2025},
	note = {Section: 0},
	keywords = {ontology, medical informatics, information retrieval, knowledge graph, China, Algorithms, Data Mining, knowledge, data mining, Databases, language model, algorithm, human, mining, article, procedures, drug therapy, open access publishing, cost control, data base, Factual, factual database, Information Storage and Retrieval, Medical Informatics},
	annote = {Type: Article}
}

@Article{li2025ExploringImpactTemperature,
	file = {References/pdf/li2025ExploringImpactTemperature.pdf},
	author = {Lujun Li and Lama Sleem and Niccol{\`{o}} Gentile
                  and Geoffrey Nichil and Radu State},
	title = {Exploring the Impact of Temperature on Large
                  Language Models:Hot or Cold?},
	journal = {CoRR},
	year = 2025,
	volume = {abs/2506.07295},
	doi = {10.48550/ARXIV.2506.07295},
	eprint = {2506.07295},
	eprinttype = {arXiv},
	url = {https://doi.org/10.48550/arXiv.2506.07295},
	timestamp = {Tue, 21 Oct 2025 12:16:23 +0200},
	biburl = {https://dblp.org/rec/journals/corr/abs-2506-07295.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{li2025GenerativeMetaLearning,
	file = {References/pdf/li2025GenerativeMetaLearning.pdf},
	series = {{SIGIR} '25},
	title = {Generative {Meta}-{Learning} for {Zero}-{Shot} {Relation} {Triplet} {Extraction}},
	url = {https://doi.org/10.1145/3726302.3729988},
	doi = {10.1145/3726302.3729988},
	abstract = {Zero-shot Relation Triplet Extraction (ZeroRTE) aims to extract relation triplets from texts containing unseen relation types. This capability benefits various downstream information retrieval (IR) tasks. The primary challenge lies in enabling models to generalize effectively to unseen relation categories. Existing approaches typically leverage the knowledge embedded in pre-trained language models to accomplish the generalization process. However, these methods focus solely on fitting the training data during training, without specifically improving the model's generalization performance, resulting in limited generalization capability. For this reason, we explore the integration of bi-level optimization (BLO) with pre-trained language models for learning generalized knowledge directly from the training data, and propose a generative meta-learning framework which exploits the 'learning-to-learn' ability of meta-learning to boost the generalization capability of generative models.Specifically, we introduce a BLO approach that simultaneously addresses data fitting and generalization. This is achieved by constructing an upper-level loss to focus on generalization and a lower-level loss to ensure accurate data fitting. Building on this, we subsequently develop three generative meta-learning methods, each tailored to a distinct category of meta-learning. Extensive experimental results demonstrate that our framework performs well on the ZeroRTE task. Our code is available at https://github.com/leeworry/TGM-MetaLearning.},
	journal = {Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	author = {Li, Wanli and Qian, Tieyun and Song, Yi and Zhang, Zeyu and Li, Jiawei and Chen, Zhuang and Zou, Lixin},
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {pre-trained language model, meta-learning, zero-shot learning, relation triplet extraction},
	pages = {1371--1381},
	annote = {event-place: Padua, Italy}
}

@Article{li2025LargeLanguageModels,
	file = {References/pdf/li2025LargeLanguageModels.pdf},
	title = {Large Language Models for Ontology Engineering: A Systematic Literature Review},
	author = {Li, Jiayi and Garijo, Daniel and Poveda-Villal{\'o}n, Mar{\'\i}a},
	year = {2025}
}

@article{li2025OntoconsMethodIntelligent,
	file = {References/pdf/li2025OntoconsMethodIntelligent.pdf},
	title = {{OntoCons}: {A} {Method} for {Intelligent} {Construction} of {Domain} {Ontology} {Models} for {Large} {Language} {Models}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012094740&doi=10.1109%2FNNICE64954.2025.11063905&partnerID=40&md5=99fdc72416564aaccebf00ec8b2b1c76},
	doi = {10.1109/NNICE64954.2025.11063905},
	abstract = {With the development of large language models technology, its application in the field of education has been steadily expanding. However, due to limitations in understanding specialized literature in vertical fields, large language models face serious issues of “hallucination” and prior bias when responding to teachers' questions about specialized domains. To address this, this paper proposes an intelligent construction framework for ontology models based on knowledge tuple extraction, called OntoCons, which introduces entity extraction and relation extraction methods into the field of ontology model construction. OntoCons transforms the ontology model construction problem into a knowledge tuple extraction problem, enhancing the transparency and interpretability of ontology model construction methods, and introduces subgraph encoding strategies to improve the accuracy of relation extraction. This research provides a new method for the intelligent construction of ontology models in vertical fields, improving the understanding and response quality of large language models in specialized domains by combining machine learning and manual analysis.},
	journal = {2025 5th International Conference on Neural Networks, Information and Communication Engineering (NNICE)},
	author = {Li, Yi and Lu, Wenxin and Xiang, Xiuzhen},
	month = jan,
	year = {2025},
	note = {Section: 0},
	keywords = {large language model, Ontologies, Large language model, Ontology, Ontology model, Language model, Relation extraction, Large language models, Machine learning, Knowledge extraction, Knowledge engineering, ontology model, Data mining, relation extraction, Extraction, knowledge extraction, entity extraction, Accuracy, Engineering education, Transforms, Encoding, Manuals, Reliability theory, Learning systems, Domain Knowledge, Entity extractions, Teaching, Intelligent constructions, Model construction, Tuples extraction, Vertical fields},
	pages = {706--712},
	annote = {Type: Conference paper}
}

@article{li2025ResearchConstructionDigital,
	file = {References/pdf/li2025ResearchConstructionDigital.pdf},
	series = {{AIIIP} '24},
	title = {Research on the {Construction} of {Digital} {Knowledge} {Graphs} {Based} on {Resources} of {National} {First}-{Class} {Undergraduate} {Programs}},
	url = {https://doi.org/10.1145/3707292.3707389},
	doi = {10.1145/3707292.3707389},
	abstract = {[Purpose/Significance]: The digitalization of education is an essential path to advancing higher education. The construction of knowledge graphs is a key approach to achieving the digitalization and intelligence of education. [Method/Process]: This paper leverages the rich video resources of existing national first-class undergraduate programs and, based on the teaching orientations of different universities, independently designs customized ontologies and extraction principles. These are then integrated into the LLM knowledge graph builder to ensure the hierarchical structure of the overall course framework. The course video content is transformed into text form, and large language models (LLMS) and word segmentation tools are used for core content extraction, text cleaning, and lexical analysis. The structured text is then converted into SPO (Subject-Predicate-Object) triplets database. [Results/Conclusions]: Finally, the database is imported into the LLM knowledge graph builder, which is pre-configured with extraction rules. It will automatically generate the knowledge graph. After the text is imported into the LLM knowledge graph builder, it will be manually checked to ensure it better meets the actual needs of the students. [Innovation/Limitations]: The research team plans to apply the knowledge graph to train a specialized knowledge-based Q\&amp;A assistant. This will support students' understanding and self-assessment of knowledge points in an online learning community. Student feedback will be used to improve and enrich the knowledge graph. Compared to existing methods, this approach better aligns with the constantly evolving digital teaching resources available online, offering more comprehensive and higher-level automation.},
	journal = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Intelligent Information Processing},
	author = {Li, Yanjun and Yang, Ruiting and Guo, Donghao and Song, Yu},
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Ontology construction, Federated learning, Students, personalized learning, A, ontology construction, course resources, intelligent Q\&amp, Hierarchical structures, Graph-based, Ontology's, Course resource, Curricula, High educations, Intelligent Q\&A, Personalized learning, Teaching, Undergraduate projects},
	pages = {353--359},
	annote = {Type: Conference paper}
}

@article{liao2025LargeLanguageModel,
	file = {References/pdf/liao2025LargeLanguageModel.pdf},
	title = {Large language model assisted fine-grained knowledge graph construction for robotic fault diagnosis},
	volume = {65},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215555067&doi=10.1016%2Fj.aei.2025.103134&partnerID=40&md5=90b6374c947ab57f039cf5dc80239c66},
	doi = {10.1016/j.aei.2025.103134},
	abstract = {With the rapid deployment of industrial robots in manufacturing, the demand for advanced maintenance techniques to sustain operational efficiency has become crucial. Fault diagnosis Knowledge Graph (KG) is essential as it interlinks multi-source data related to industrial robot faults, capturing multi-level semantic associations among different fault events. However, the construction and application of fine-grained fault diagnosis KG face significant challenges due to the inherent complexity of nested entities in maintenance texts and the severe scarcity of annotated industrial data. In this study, we propose a Large Language Model (LLM) assisted data augmentation approach, which handles the complex nested entities in maintenance corpora and constructs a more fine-grained fault diagnosis KG. Firstly, the fine-grained ontology is constructed via LLM Assistance in Industrial Nested Named Entity Recognition (assInNNER). Then, an Industrial Nested Label Classification Template (INCT) is designed, enabling the use of nested entities in Attention-map aware keyword selection for the Industrial Nested Language Model (ANLM) data augmentation methods. ANLM can effectively improve the model's performance in nested entity extraction when corpora are scarce. Subsequently, a Confidence Filtering Mechanism (CFM) is introduced to evaluate and select the generated data for enhancement, and assInNNER is further deployed to recall the negative samples corpus again to further improve performance. Experimental studies based on multi-source corpora demonstrate that compared to existing algorithms, our method achieves an average F1 increase of 8.25 \%, 3.31 \%, and 1.96 \% in 5\%, 10 \%, and 25 \% in few-shot settings, respectively. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Advanced Engineering Informatics},
	author = {Liao, Xingming and Chen, Chong and Wang, Zhuowei and Liu, Ying and Wang, Tao and Cheng, Lianglun},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Language model, Named entity recognition, Semantics, Data augmentation, Industrial robots, Graph construction, Faults diagnosis, Fine grained, Multi-Sources, Rapid deployments},
	annote = {Type: Article}
}

@article{ling2024NewIncrementalPipeline,
	file = {References/pdf/ling2024NewIncrementalPipeline.pdf},
	title = {A new incremental pipeline for concept formation driven by prior knowledge: {Application} on the {AI} {Act} domain},
	volume = {246},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213329685&doi=10.1016%2Fj.procs.2024.09.618&partnerID=40&md5=de7233c04a3f407dd8694add9c7c1636},
	doi = {10.1016/j.procs.2024.09.618},
	abstract = {In the Ontology Learning research domain, despite recent advancements, the performance of current non or semi-supervised approaches for concept formation remains sub-optimal, particularly from a single, small-sized corpus for a specialized domain. In order to answer the performance drawback, this paper introduces a novel pipeline, called CO-ISSC (Core Ontology-based Incremental Semi-Supervised Clustering), for concept formation towards ontology learning. This pipeline uses a PLM (Pre-trained Language Model) and combines in an incremental manner a semi-supervised dimension reduction technique and a clustering technique, guided by core concepts as prior knowledge to align results with the ontology domain. Its incremental nature enhances prior knowledge and boosts its performance. The CO-ISSC pipeline's performance is evaluated on the recent and significant AI Act text established by the European Union, which aims to ensure the safety, transparency, and non-discrimination of AI systems. To this end, we manually built a benchmark terminology for the AI Act domain given that no reference model exists yet. The results demonstrate promising performance of the CO-ISSC pipeline, outperforming baseline non-supervised or semi-supervised approaches such as DBSCAN, similarity measure based approaches, support vector machines and ANN. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Procedia Computer Science},
	author = {Ling, Hongtao and Harzallah, Mounira and Bernelin, Margo and Marinica, Claudia and Serrano-Alvarado, Patricia},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology, Ontology learning, Ontology-based, Dimension reduction, Performance, Concept formation, Incremental pipeline, Self-supervised learning, Semi-supervised learning, Adversarial machine learning, Support vector machines, Domain Knowledge, Contrastive Learning, Clusterings, AI act domain, Prior-knowledge, Semi-supervised},
	pages = {2148 -- 2157},
	annote = {Issue: C Type: Conference paper}
}

@article{lippolis2025AssessingCapabilityLarge,
	file = {References/pdf/lippolis2025AssessingCapabilityLarge.pdf},
	title = {Assessing the {Capability} of {Large} {Language} {Models} for {Domain}-{Specific} {Ontology} {Generation}},
	volume = {3977},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008494228&partnerID=40&md5=fe96df813eee91b10e9e7d0088ce1efc},
	abstract = {Large Language Models (LLMs) have shown significant potential for ontology engineering. However, it is still unclear to what extent they are applicable to the task of domain-specific ontology generation. In this study, we explore the application of LLMs for automated ontology generation and evaluate their performance across different domains. Specifically, we investigate the generalizability of two state-of-the-art LLMsDeepSeek and o1-preview, both equipped with reasoning capabilitiesby generating ontologies from a set of competency questions (CQs) and related user stories. Our experimental setup comprises six distinct domains carried out in existing ontology engineering projects and a total of 95 curated CQs designed to test the models reasoning for ontology engineering. Our findings show that with both LLMs, the performance of the experiments is remarkably consistent across all domains, indicating that these methods are capable of generalizing ontology generation tasks irrespective of the domain. These results highlight the potential of LLM-based approaches in achieving scalable and domain-agnostic ontology construction and lay the groundwork for further research into enhancing automated reasoning and knowledge representation techniques. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Lippolis, Anna Sofia and Saeedizade, Mohammad Javad and Keskisärkkä, Robin and Gangemi, Aldo and Blomqvist, Eva and Nuzzolese, Andrea Giovanni},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, Knowledge representation, Ontology generation, Performance, Domain Knowledge, Ontology's, State of the art, Domain-specific ontologies, Different domains, Two-state},
	annote = {Type: Conference paper}
}

@article{lippolis2025OntogeniaOntologyGeneration,
	file = {References/pdf/lippolis2025OntogeniaOntologyGeneration.pdf},
	title = {Ontogenia: {Ontology} {Generation} with {Metacognitive} {Prompting} in {Large} {Language} {Models}},
	volume = {15344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218451819&doi=10.1007%2F978-3-031-78952-6_38&partnerID=40&md5=45b240331711a18cc31af840ace6c730},
	doi = {10.1007/978-3-031-78952-6_38},
	abstract = {Recent advancements in Large Language Models (LLMs) have primarily focused on enhancing task-specific performances by experimenting with prompt design. Despite the proven effectiveness of Metacognitive Prompting (MP), its application in the field of ontology generation remains an uncharted territory. This study addresses this gap by exploring this prompting technique in supporting the ontology design process, particularly with GPT-4, where this strategy has demonstrated consistent superiority over conventional and more direct prompting methods in recent research. Our methodology, named Ontogenia, employs a gold-standard dataset of ontology competency questions translated into SPARQL-OWL queries. This approach allows us to explore various types and stages of knowledge refinement using MP, while adhering to the eXtreme Design methodology, a well-established protocol in ontology design. Finally, the quality and performance of the resulting ontologies are assessed using both standard ontology quality metrics and evaluation by an ontology expert. This research aims to enrich the discussion on methods of ontology generation driven by LLMs by presenting concrete results on the use of metacognitive prompting and ontology design patterns. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Lippolis, Anna Sofia and Ceriani, Miguel and Zuppiroli, Sara and Nuzzolese, Andrea Giovanni},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, Ontology design, Modeling languages, Competency question, Ontology generation, Performance, Ontology's, Metacognitive prompting, Metacognitives, Incorrect information},
	pages = {259 -- 265},
	annote = {Type: Conference paper}
}

@Online{liu2019RobertaRobustlyOptimized,
	author = {Yinhan Liu AND Myle Ott AND Naman Goyal AND Jingfei
                  Du AND Mandar Joshi AND Danqi Chen AND Omer Levy AND
                  Mike Lewis AND Luke Zettlemoyer AND Veselin
                  Stoyanov},
	title = {{RoBERTa: A Robustly Optimized BERT Pretraining
                  Approach}},
	year = 2019,
	eprint = {1907.11692v1},
	primaryclass = {cs.CL},
	archiveprefix = {arXiv}
}

@Article{liu2020ConceptPlacementUsing,
	file = {References/pdf/liu2020ConceptPlacementUsing.pdf},
	author = {Hao Liu and Yehoshua Perl and James Geller},
	title = {Concept placement using {BERT} trained by
                  transforming and summarizing biomedical ontology
                  structure},
	journal = {J. Biomed. Informatics},
	year = 2020,
	volume = 112,
	pages = 103607,
	doi = {10.1016/J.JBI.2020.103607},
	url = {https://doi.org/10.1016/j.jbi.2020.103607},
	timestamp = {Mon, 19 Aug 2024 09:03:45 +0200},
	biburl = {https://dblp.org/rec/journals/jbi/LiuPG20.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{liu2021SelfAlignmentPretraining,
	file = {References/pdf/liu2021SelfAlignmentPretraining.pdf},
	title = {Self-{Alignment} {Pretraining} for {Biomedical} {Entity} {Representations}},
	url = {https://aclanthology.org/2021.naacl-main.334/},
	doi = {10.18653/v1/2021.naacl-main.334},
	abstract = {Despite the widespread success of self-supervised learning via masked language models (MLM), accurately capturing fine-grained semantic relationships in the biomedical domain remains a challenge. This is of paramount importance for entity-level tasks such as entity linking where the ability to model entity relations (especially synonymy) is pivotal. To address this challenge, we propose SapBERT, a pretraining scheme that self-aligns the representation space of biomedical entities. We design a scalable metric learning framework that can leverage UMLS, a massive collection of biomedical ontologies with 4M+ concepts. In contrast with previous pipeline-based hybrid systems, SapBERT offers an elegant one-model-for-all solution to the problem of medical entity linking (MEL), achieving a new state-of-the-art (SOTA) on six MEL benchmarking datasets. In the scientific domain, we achieve SOTA even without task-specific supervision. With substantial improvement over various domain-specific pretrained MLMs such as BioBERT, SciBERTand and PubMedBERT, our pretraining scheme proves to be both effective and robust.},
	journal = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
	author = {Liu, Fangyu and Shareghi, Ehsan and Meng, Zaiqiao and Basaldella, Marco and Collier, Nigel},
	editor = {Toutanova, Kristina and Rumshisky, Anna and Zettlemoyer, Luke and Hakkani-Tur, Dilek and Beltagy, Iz and Bethard, Steven and Cotterell, Ryan and Chakraborty, Tanmoy and Zhou, Yichao},
	month = jun,
	year = {2021},
	note = {Place: Online
Publisher: Association for Computational Linguistics
Section: 0},
	keywords = {Language model, Semantics, Pre-training, Semantic relationships, Computational linguistics, Biomedical domain, Fine grained, State of the art, Entity-level, Hybrid systems, Model entities, Self-align, Self-alignment},
	pages = {4228--4238},
	annote = {Type: Conference paper}
}

@Article{liu2023JailbreakingChatgptVia,
	file = {References/pdf/liu2023JailbreakingChatgptVia.pdf},
	author = {Yi Liu and Gelei Deng and Zhengzi Xu and Yuekang Li
                  and Yaowen Zheng and Ying Zhang and Lida Zhao and
                  Tianwei Zhang and Yang Liu},
	title = {Jailbreaking ChatGPT via Prompt Engineering: An
                  Empirical Study},
	journal = {CoRR},
	year = 2023,
	volume = {abs/2305.13860},
	doi = {10.48550/ARXIV.2305.13860},
	eprint = {2305.13860},
	eprinttype = {arXiv},
	url = {https://doi.org/10.48550/arXiv.2305.13860},
	timestamp = {Mon, 03 Mar 2025 21:32:55 +0100},
	biburl = {https://dblp.org/rec/journals/corr/abs-2305-13860.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{liu2023VisualInstructionTuning,
	file = {References/pdf/liu2023VisualInstructionTuning.pdf},
	author = {Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
	pages = {34892--34916},
	publisher = {Curran Associates, Inc.},
	title = {Visual Instruction Tuning},
	url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/6dcf277ea32ce3288914faf369fe6de0-Paper-Conference.pdf},
	volume = {36},
	year = {2023}
}

@article{liu2024UsingGenerativeLarge,
	file = {References/pdf/liu2024UsingGenerativeLarge.pdf},
	title = {Using {Generative} {Large} {Language} {Models} for {Hierarchical} {Relationship} {Prediction} in {Medical} {Ontologies}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203690166&doi=10.1109%2FICHI61247.2024.00040&partnerID=40&md5=44d6691ccccf632afe6aa2f13128c9c9},
	doi = {10.1109/ICHI61247.2024.00040},
	abstract = {This study extends the exploration of ontology enrichment by evaluating the performance of various open-sourced Large Language Models (LLMs) on the task of predicting hierarchical relationships (IS-A) in medical ontologies including SNOMED CT Clinical Finding and Procedure hierarchies and the human Disease Ontology. With the previous finetuned BERT models for hierarchical relationship prediction as the baseline, we assessed eight open-source generative LLMs for the same task. We observed only three models, without finetuning, demonstrated comparable or superior performance compared to the baseline BERT -based models. The best performance model OpenChat achieved a macro average F1 score of 0.96 (0.95) on SNOMED CT Clinical Finding (Procedure) hierarchy, an increase over 7\% from the baseline 0.89 (0.85). On human Disease Ontology, OpenChat excels with an F1 score of 0.91, outperforming the second-best performance model Vicuna (0.84). Notably, some LLMs prove unsuitable for hierarchical relationship prediction tasks or appliable for concept placement of medical ontologies. We also explored various prompt templates and ensemble techniques to uncover potential confounding factors in applying LLMs for IS-A relation predictions for medical ontologies.},
	journal = {2024 IEEE 12th International Conference on Healthcare Informatics (ICHI)},
	author = {Liu, Hao and Zhou, Shuxin and Chen, Zhehuan and Perl, Yehoshua and Wang, Jiayin},
	month = jun,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Large Language Models, Large language model, Language model, Large language models, Medical ontology, Human disease, SNOMED CT, Informatics, Medical Ontology, Performance, SNOMED-CT, Accuracy, Predictive models, Medical services, Task analysis, Hieratical Relation Prediction, Prompts Design, Prediction models, Generative adversarial networks, Hieratical relation prediction, Performance Modeling, Prompt design},
	pages = {248--256},
	annote = {ISSN: 2575-2634}
}

@article{liu2025LargeLanguageModel,
	file = {References/pdf/liu2025LargeLanguageModel.pdf},
	title = {Large language model enabled knowledge discovery of building-level electrification using permit data},
	volume = {343},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006876397&doi=10.1016%2Fj.enbuild.2025.115890&partnerID=40&md5=55641cdb377f6fc74df931c0aa1a20c3},
	doi = {10.1016/j.enbuild.2025.115890},
	abstract = {Wide scale electrification is essential for decarbonization of the building sector, yet there is a significant knowledge gap regarding the specific locations, timelines, and types of electrification technologies that are being deployed. To address this gap, we developed an information framework powered by large language models (LLMs) to extract detailed electrification-related technology information from building permit text data. While U.S. building permit data is publicly available, it is often unstructured, incomplete, and highly variable. Our LLM-enabled system addresses these challenges by constructing a comprehensive building-level ontology that captures detailed attributes for six key electrification technologies: photovoltaics, electric vehicle chargers, energy storage systems, electric service panels, water heaters, and heat pumps. Our information extraction system exhibits strong performance, achieving 0.96 recall and 0.88 precision on our human-annotated test dataset. We experimentally deploy our framework on permit data in San Francisco County, California, demonstrating that it surpasses all existing public sources of electrification information in both spatiotemporal resolution and coverage. Our work provides new visibility into building electrification trends at scale, offering valuable insights for grid planners, policymakers, installers, and end-users to inform decision-making processes. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Energy and Buildings},
	author = {Liu, Tony and Zanocco, Chad M. and Wang, Zhecheng and Huang, Tianyuan and Flora, June A. and Rajagopal, Ram S.},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Language model, Building permits, Spatiotemporal mapping, Decarbonisation, Building Information Model, Building levels, Buildings sector, Distributed Energy Resources, Knowledge gaps, Specific location},
	annote = {Type: Article}
}

@article{liu2025OntotuneOntologyDriven,
	file = {References/pdf/liu2025OntotuneOntologyDriven.pdf},
	series = {{WWW} '25},
	title = {{OntoTune}: {Ontology}-{Driven} {Self}-training for {Aligning} {Large} {Language} {Models}},
	url = {https://doi.org/10.1145/3696410.3714816},
	doi = {10.1145/3696410.3714816},
	abstract = {Existing domain-specific Large Language Models (LLMs) are typically developed by fine-tuning general-purposed LLMs with large-scale domain-specific corpora. However, training on large-scale corpora often fails to effectively organize domain knowledge of LLMs, leading to fragmented understanding. Inspired by how humans connect concepts and organize knowledge through mind maps, we aim to emulate this approach by using ontology with hierarchical conceptual knowledge to reorganize LLM's domain knowledge. From this perspective, we propose an ontology-driven self-training framework called OntoTune, which aims to align LLMs with ontology through in-context learning, enabling the generation of responses guided by the ontology. We leverage in-context learning to identify whether the LLM has acquired the specific concept's ontology knowledge, and select the entries not yet mastered by LLM as the training set to further align the LLM with ontology. Compared to existing domain LLMs based on newly collected large-scale domain-specific corpora, our OntoTune, which relies on the existing, long-term developed ontology and LLM itself, significantly reduces data maintenance costs and offers improved generalization ability. We conduct our study in the medical domain to evaluate the effectiveness of OntoTune, utilizing a standardized medical ontology, SNOMED CT as our ontology source. Experimental results demonstrate that OntoTune achieves state-of-the-art performance in both in-ontology task hypernym discovery and out-of-ontology task medical domain QA. Moreover, compared to the latest direct ontology injection method TaxoLLaMA, our OntoTune better preserves original knowledge of LLM. The code and data are available at https://github.com/zjukg/OntoTune.},
	journal = {Proceedings of the ACM on Web Conference 2025},
	author = {Liu, Zhiqiang and Gan, Chengtao and Wang, Junjie and Zhang, Yichi and Bo, Zhongpu and Sun, Mengshu and Chen, Huajun and Zhang, Wen},
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {large language model, Large language model, Language model, Domain knowledge, Self-training, align with ontology, self-training, Ontology's, Large-scales, Align with ontology, Domain specific, Existing domains, Scale domains},
	pages = {119--133},
	annote = {event-place: Sydney NSW, Australia}
}

@article{liu2025ResearchConstructionApplication,
	file = {References/pdf/liu2025ResearchConstructionApplication.pdf},
	title = {Research on the construction and application of problem-method-oriented academic graph empowered by {LLM}},
	volume = {28},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012962905&doi=10.1007%2Fs10791-025-09675-2&partnerID=40&md5=a5e9b29e96ba8299450eb6d8d25e78df},
	doi = {10.1007/s10791-025-09675-2},
	abstract = {Nowadays, the volume of literature in each field is huge and is growing rapidly, which posts challenge to researchers’ literature review. In this circumstance, developing useful tool for achieving efficient literature management is of high value. Traditional literature management tools, such as tools for key word searching, paper recommendation, relation visualization, and keyword cloud drawing, are not suitable for conducting content-level literature review. To address the issues of traditional literature management tools, a novel problem and method-oriented fine-grained academic graph is proposed to facilitate the exploration of research questions, methodologies, study perspectives, and their connections hidden in massive literature. For building such graph, a new ontology dedicated for describing the features of research paper is developed, an innovative multi-relation join extraction model is proposed, and a creative approach for leveraging the Large Language Models (LLM) to augment the triplet extraction results generated by supervised-learning model is developed. Experiments on widely used benchmark datasets show that the proposed multi-relation extraction model is able to achieve at least 8.01\% and 8.65\% improvement on entity identification and relation classification respectively, compared with state-of-the-art models. The visualized demonstration of the proposed graph shows that our graph is capable of accurately capturing the problem network, method network and hot topics hidden in massive literature. The Q\&A system supported by the proposed graph demonstrates that our graph is really helpful for conducting literature review. © 2025 Elsevier B.V., All rights reserved.},
	number = {1},
	journal = {Discover Computing},
	author = {Liu, Qigang and Wang, Yinfan and Mu, Lifeng and Li, Jun},
	year = {2025},
	note = {Section: 0},
	annote = {Type: Article}
}

@Article{lloyd1982LeastSquaresQuantization,
	file = {References/pdf/lloyd1982LeastSquaresQuantization.pdf},
	author = {Lloyd, Stuart},
	title = {{Least squares quantization in PCM}},
	journal = {{IEEE Transactions on Information Theory}},
	year = 1982,
	volume = 28,
	number = 2,
	month = Mar,
	pages = {129-137},
	doi = {10.1109/TIT.1982.1056489},
	url = {https://hal.science/hal-04614938},
	PUBLISHER = {{Institute of Electrical and Electronics Engineers}},
	PDF = {https://hal.science/hal-04614938v1/file/Lloyd1982.pdf},
	HAL_ID = {hal-04614938},
	HAL_VERSION = {v1}
}

@article{llugiqi2025ExpertsLlmsEvaluating,
	file = {References/pdf/llugiqi2025ExpertsLlmsEvaluating.pdf},
	title = {From {Experts} to {LLMs}: {Evaluating} the {Quality} of {Automatically} {Generated} {Ontologies}},
	volume = {3977},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008498807&partnerID=40&md5=b2b9fe8261f5ee963e6e69a1cf2d3f92},
	abstract = {Ontologies play a crucial role in knowledge representation, yet their manual construction requires domain expertise and effort. While previous work has focused on using large language models (LLMs) for assessing ontology creation, fully automated ontology generation remains underexplored. As a consequence, most research relies on a limited set of well-known ontologies or knowledge graphs, which constrains the evaluation of various tasks such as link prediction and knowledge graph completion. This highlights the need for diverse ontology benchmarks with varying characteristics, such as number of concepts, hierarchy depth and so on, to effectively evaluate tasks such as link prediction and knowledge graph completion. In this work, we investigate the feasibility of generating ontologies using LLMs and evaluate whether they can produce ontologies of comparable quality to human-built ones. Given a seed set of concepts, a target number of concepts, relations, and maximum hierarchy depth, we employ three different LLMs to generate ontologies within the heart disease domain. Defining a seed set of concepts is particularly important for modeling the features of tabular datasets, enabling structured knowledge representation for downstream tasks. We systematically evaluate the generated ontologies by analyzing their structural integrity, semantic coherence, and suitability for downstream tasks. Our results show that while LLM-generated ontologies differ structurally from human-built ones, they remain comparable in semantic similarity and downstream ML performance, with LLaMA-generated ontologies proving to be the most effective. These findings highlight the potential of LLM-generated ontologies not only to support automated knowledge representation but also to enhance ontology benchmarks by introducing diverse structural characteristics, enabling more comprehensive evaluations of machine learning tasks. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Llugiqi, Majlinda and Ekaputra, Fajar J. and Sabou, Marta},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Semantics, Benchmarking, Ontology generation, Computational linguistics, Learning systems, Domain Knowledge, Ontology's, Knowledge-representation, Ontology evaluations, AS-links, Domain-specific ontologies, Down-stream, Large-language model},
	annote = {Type: Conference paper}
}

@article{lo2024EndEndOntology,
	file = {References/pdf/lo2024EndEndOntology.pdf},
	title = {End-to-{End} {Ontology} {Learning} with {Large} {Language} {Models}},
	volume = {37},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000479241&partnerID=40&md5=f517a883bd55f9054bd7e3cb20e0ebd1},
	abstract = {Ontologies are useful for automatic machine processing of domain knowledge as they represent it in a structured format. Yet, constructing ontologies requires substantial manual effort. To automate part of this process, large language models (LLMs) have been applied to solve various subtasks of ontology learning. However, this partial ontology learning does not capture the interactions between subtasks. We address this gap by introducing OLLM, a general and scalable method for building the taxonomic backbone of an ontology from scratch. Rather than focusing on subtasks, like individual relations between entities, we model entire subcomponents of the target ontology by finetuning an LLM with a custom regulariser that reduces overfitting on high-frequency concepts. We introduce a novel suite of metrics for evaluating the quality of the generated ontology by measuring its semantic and structural similarity to the ground truth. In contrast to standard syntax-based metrics, our metrics use deep learning techniques to define more robust distance measures between graphs. Both our quantitative and qualitative results on Wikipedia show that OLLM outperforms subtask composition methods, producing more semantically accurate ontologies while maintaining structural integrity. We further demonstrate that our model can be effectively adapted to new domains, like arXiv, needing only a small number of training examples. Our source code and datasets are available at https://github.com/andylolu2/ollm. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Advances in Neural Information Processing Systems},
	author = {Lo, Andy and Jiang, Albert Qiaochu and Li, Wenda and Jamnik, Mateja},
	year = {2024},
	note = {Section: 0},
	annote = {Type: Conference paper}
}

@article{lopes2022LearningDomainOntologies,
	file = {References/pdf/lopes2022LearningDomainOntologies.pdf},
	title = {Learning {Domain} {Ontologies} {Based} {On} {Top}-{Level} {Ontology} {Concepts} {Using} {Language} {Models} {And} {Informal} {Definitions}},
	volume = {3346},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150217899&partnerID=40&md5=6161d8c3f141c3af53e3a240d368bb42},
	abstract = {Ontology development is a challenging task that encompasses many time-consuming activities. One of these activities is the classification of the domain entities (concepts and instances) according to top-level concepts. This activity is usually performed manually by an ontology engineer. However, when the set of entities increases in size, associating each domain entity to the proper top-level ontological concept becomes challenging and requires a high level of expertise in both the target domain and ontology engineering. In this context, this work describes an approach for learning domain ontologies based on top-level ontology concepts using informal definitions as input. In our approach, we used informal definitions of the domain entities as text input of a language model that predicts their proper top-level concepts. Also, we present a methodology to extract datasets from existing domain ontologies to evaluate the proposed approach. Our experiments show that we have promising results in classifying domain entities into top-level ontology concepts. © 2023 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Lopes, Alcides Gonçalves and Carbonera, Joel Lúis and Abel, Mara},
	year = {2022},
	note = {Section: 0},
	keywords = {Ontology, Language model, Ontology learning, Domain ontologies, Ontology development, Ontology-based, Text classification, Deep neural networks, Computational linguistics, Text processing, Ontology's, Classification (of information), Ontology concepts, Target domain, Domain entities},
	pages = {180 -- 185},
	annote = {Type: Conference paper}
}

@article{lopes2023UsingTermsInformal,
	file = {References/pdf/lopes2023UsingTermsInformal.pdf},
	title = {Using terms and informal definitions to classify domain entities into top-level ontology concepts: {An} approach based on language models},
	volume = {265},
	issn = {0950-7051},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705123001351},
	doi = {https://doi.org/10.1016/j.knosys.2023.110385},
	abstract = {The classification of domain entities into top-level ontology concepts remains an activity performed manually by an ontology engineer. Although some works focus on automating this task by applying machine-learning approaches using textual sentences as input, they require the existence of the domain entities in external knowledge resources, such as pre-trained embedding models. In this context, this work proposes an approach that combines the term representing the domain entity and its informal definition into a single text sentence without requiring external knowledge resources. Thus, we use this sentence as the input of a deep neural network that contains a language model as a layer. Also, we present a methodology used to extract two novel datasets from the OntoWordNet ontology based on Dolce-Lite and Dolce-Lite-Plus top-level ontologies. Our experiments show that by using the transformer-based language models, we achieve promising results in classifying domain entities into 82 top-level ontology concepts, with 94\% regarding micro F1-score.},
	journal = {Knowledge-Based Systems},
	author = {Lopes, Alcides and Carbonera, Joel and Schmidt, Daniela and Garcia, Luan and Rodrigues, Fabricio and Abel, Mara},
	year = {2023},
	note = {Section: 0},
	keywords = {Ontology, Language model, Ontology learning, Top-level ontology, Embeddings, Deep neural networks, Computational linguistics, Knowledge resource, Learning systems, Ontology's, External knowledge, Ontology concepts, Domain entities, Machine learning approaches, Multilayer neural networks},
	pages = {110385},
	annote = {Type: Article}
}

@article{lopes2024CrossDomainClassification,
	file = {References/pdf/lopes2024CrossDomainClassification.pdf},
	title = {Cross-{Domain} {Classification} of {Domain} {Entities} into {Top}-{Level} {Ontology} {Concepts} {Using} {BERT}: {A} {Study} {Case} on the {BFO} {Domain} {Ontologies}},
	volume = {2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193935708&doi=10.5220%2F0012557600003690&partnerID=40&md5=e2743defc57c09f037e5c2bb310f611c},
	doi = {10.5220/0012557600003690},
	abstract = {Classifying domain entities into top-level ontology concepts using informal definitions remains an active research area with several open questions. One of these questions pertains to the quality of proposed pipelines employing language models for classifying informal definitions when training and testing samples are from different knowledge domains. This can introduce challenges due to varying vocabularies across domains or the potential for an entity to belong to different top-level concepts based on its domain. In this study, we present a study case where terms and informal definitions are extracted from 81 domain ontologies organized into 12 knowledge domains. We investigate the performance of a pipeline that utilizes the BERT language model for classifying domain entities into top-level concepts within a cross-domain classification scenario. Additionally, we explore various pipeline setups for input, preprocessing, and training steps. Our optimal classifier setup employs an unbalanced training methodology, no text preprocessing, and the concatenation of terms and informal definitions as input. Furthermore, we demonstrate that BERT yields promising results in classifying domain entities into top-level concepts within a cross-domain classification scenario. © 2024 Elsevier B.V., All rights reserved.},
	journal = {International Conference on Enterprise Information Systems, ICEIS - Proceedings},
	author = {Lopes, Alcides Gonçalves and Carbonera, Joel Lúis and Santos, Nicolau O. and Rodrigues, Fabrício Henrique Henrique and Garcia, Luan Fonseca and Abel, Mara},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology, Language model, Domain ontologies, Knowledge management, Computational linguistics, Cross-domain, Pipelines, Ontology's, Ontology concepts, Domain entities, Informal definition, Top-level ontology classification, Cross-domain classification, Study case},
	pages = {141 -- 148},
	annote = {Type: Conference paper}
}

@article{lopes2024HowClassifyDomain,
	file = {References/pdf/lopes2024HowClassifyDomain.pdf},
	title = {How to classify domain entities into top-level ontology concepts using large language models: {A} study across multiple labels, resources, and languages},
	volume = {3882},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214572340&partnerID=40&md5=2a7cc600567dd009cf3ccec08907c7c4},
	abstract = {Classifying domain entities into their respective top-level ontology concepts is a complex problem that typically demands manual analysis and deep expertise in the domain of interest and ontology engineering. Using an efficient approach to classify domain entities enhances data integration, interoperability, and the semantic clarity of ontologies, which are crucial for structured knowledge representation and modeling. Based on this, our main motivation is to help an ontology engineer with an automated approach to classify domain entities into top-level ontology concepts using informal definitions of these domain entities during the ontology development process. In this context, we hypothesize that the informal definitions encapsulate semantic information crucial for associating domain entities with specific top-level ontology concepts. Our approach leverages state-of-the-art language models to explore our hypothesis across multiple languages and informal definitions from different knowledge resources. In order to evaluate our proposal, we extracted multi-label datasets from the alignment of the OntoWordNet ontology and the BabelNet semantic network, covering the entire structure of the Dolce-Lite-Plus top-level ontology from most generic to most specific concepts. These datasets contain several different textual representation approaches of domain entities, including terms, example sentences, and informal definitions. Our experiments conducted 3 study cases, investigating the effectiveness of our proposal across different textual representation approaches, languages, and knowledge resources. We demonstrate that the best results are achieved using a classification pipeline with a K-Nearest Neighbor (KNN) method to classify the embedding representation of informal definitions from the Mistral large language model. The findings underscore the potential of informal definitions in reflecting top-level ontology concepts and point towards developing automated tools that could significantly aid ontology engineers during the ontology development process. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Lopes, Alcides Gonçalves and Carbonera, Joel Lúis and Rodrigues, Fabrício Henrique Henrique and Garcia, Luan Fonseca and Abel, Mara},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology, Language model, Ontology learning, Semantics, Knowledge representation, Ontology development, Modeling languages, Development process, Domain Knowledge, Ontology's, Classification (of information), Ontology concepts, Domain entities, Informal definition, Top-level ontology classification, Data encapsulation, Multiple languages},
	annote = {Type: Conference paper}
}

@article{lops2025LumenLeveragingLarge,
	file = {References/pdf/lops2025LumenLeveragingLarge.pdf},
	title = {{LUMEN}: {Leveraging} {Large} {Language} {Models} for {Dynamic} {Ontologies} in {Wind} {Energy} {Domain} {Analysis}},
	volume = {3990},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010754197&partnerID=40&md5=6b34e7aa673f27053a6d25ee8cd45275},
	abstract = {This study introduces LUMEN (Latent Understanding through Modeling Embeddings in Natural language), a structured approach leveraging Large Language Models (LLMs) and semantic embeddings to construct a hierarchical thesaurus for the wind energy domain. Using a domain-specific corpus generated via Sketch Engine, LUMEN applies a three-step methodology: corpus creation, semantic label identification through LLM-based analysis, and hierarchical term classification via embedding-based semantic similarity calculations. We outline our machine learning configuration, including the embedding techniques and similarity metrics employed. Results indicate that LUMEN can capture nuanced subdomains and semantic interrelations within wind energy, despite occasional misclassification issues. Future research directions include systematic benchmarking against established ontology-building tools and multilingual adaptation to broaden applicability. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Lops, Andrea and Sassi, Serena},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Terminology, Natural language processing, Language model, Artificial intelligence, Semantics, Knowledge management, Modeling languages, Embeddings, Thesauri, Information systems, Computational linguistics, Power, Latent semantic analysis, Language processing, Natural languages, Natural language processing systems, Domain analysis, Domain tree, Model embedding, Wind power, Wind power research},
	annote = {Type: Conference paper}
}

@Article{lubani2019OntologyPopulationApproaches,
	file = {References/pdf/lubani2019OntologyPopulationApproaches.pdf},
	author = {Mohamed Lubani and Shahrul Azman Mohd. Noah and
                  Rohana Mahmud},
	title = {Ontology population: Approaches and design aspects},
	journal = {J. Inf. Sci.},
	year = 2019,
	volume = 45,
	number = 4,
	doi = {10.1177/0165551518801819},
	url = {https://doi.org/10.1177/0165551518801819},
	timestamp = {Sun, 19 Jan 2025 13:44:20 +0100},
	biburl = {https://dblp.org/rec/journals/jis/LubaniNM19.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{ludwig2024SpeechToJobshop,
	file = {References/pdf/ludwig2024SpeechToJobshop.pdf},
	title = {{SPEECH}-{TO}-{JOBSHOP}: {AN} {ONTOLOGY}-{DRIVEN} {DIGITAL} {ASSISTANT} {FOR} {SIMULATION} {MODELING}},
	volume = {38},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195222610&partnerID=40&md5=4df1984998f2d5b0192a4f7b121cb30c},
	abstract = {This paper introduces a novel method utilizing speech-based digital assistants and large language models (LLMs) to streamline the creation of simulation models for Job Shop Scheduling Problems (JSSP). The system simplifies the process by allowing natural language interactions for ontology-based model generation. The study evaluates the performance of various LLMs in ontology-based simulation modeling by benchmarking their ability to extract and assign semantical entities and relations. We found that ChatGPT-4Turbo is able to correctly identify all model elements given in descriptions of the production scenarios we tested, while less resource-intensive and open source models like Mixtral-8x7b and Zephyr-beta perform well in a less complex scenario. The findings demonstrate the potential of integrating LLMs and natural language processing in simulation modeling, significantly enhancing efficiency and reducing the need for manual modeling. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Proceedings - European Council for Modelling and Simulation, ECMS},
	author = {Ludwig, Heiner and Betker, Vincent and Schmidt, Thorsten Lars and Kuhn, Mathias},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Modeling languages, Benchmarking, Computational linguistics, Job shop scheduling, Ontology's, Natural language processing systems, Digital assistants, Job shop scheduling problems, Job-shop, Job-Shop scheduling, Novel methods, Simulation model, Simulation-modelling},
	pages = {143 -- 149},
	annote = {Issue: 1 Type: Conference paper}
}

@article{lyu2023CausalKnowledgeGraph,
	file = {References/pdf/lyu2023CausalKnowledgeGraph.pdf},
	title = {Causal knowledge graph construction and evaluation for clinical decision support of diabetic nephropathy},
	volume = {139},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147538756&doi=10.1016%2Fj.jbi.2023.104298&partnerID=40&md5=c209c46ed49ec0410bc473201929091f},
	doi = {10.1016/j.jbi.2023.104298},
	abstract = {Background: Many important clinical decisions require causal knowledge (CK) to take action. Although many causal knowledge bases for medicine have been constructed, a comprehensive evaluation based on real-world data and methods for handling potential knowledge noise are still lacking. Objective: The objectives of our study are threefold: (1) propose a framework for the construction of a large-scale and high-quality causal knowledge graph (CKG); (2) design the methods for knowledge noise reduction to improve the quality of the CKG; (3) evaluate the knowledge completeness and accuracy of the CKG using real-world data. Material and methods: We extracted causal triples from three knowledge sources (SemMedDB, UpToDate and Churchill's Pocketbook of Differential Diagnosis) based on rule methods and language models, performed ontological encoding, and then designed semantic modeling between electronic health record (EHR) data and the CKG to complete knowledge instantiation. We proposed two graph pruning strategies (co-occurrence ratio and causality ratio) to reduce the potential noise introduced by SemMedDB. Finally, the evaluation was carried out by taking the diagnostic decision support (DDS) of diabetic nephropathy (DN) as a real-world case. The data originated from a Chinese hospital EHR system from October 2010 to October 2020. The knowledge completeness and accuracy of the CKG were evaluated based on three state-of-the-art embedding methods (R-GCN, MHGRN and MedPath), the annotated clinical text and the expert review, respectively. Results: This graph included 153,289 concepts and 1,719,968 causal triples. A total of 1427 inpatient data were used for evaluation. Better results were achieved by combining three knowledge sources than using only SemMedDB (three models: area under the receiver operating characteristic curve (AUC): p {\textbackslash}textless 0.01, F1: p {\textbackslash}textless 0.01), and the graph covered 93.9 \% of the causal relations between diseases and diagnostic evidence recorded in clinical text. Causal relations played a vital role in all relations related to disease progression for DDS of DN (three models: AUC: p {\textbackslash}textgreater 0.05, F1: p {\textbackslash}textgreater 0.05), and after pruning, the knowledge accuracy of the CKG was significantly improved (three models: AUC: p {\textbackslash}textless 0.01, F1: p {\textbackslash}textless 0.01; expert review: average accuracy: + 5.5 \%). Conclusions: The results demonstrated that our proposed CKG could completely and accurately capture the abstract CK under the concrete EHR data, and the pruning strategies could improve the knowledge accuracy of our CKG. The CKG has the potential to be applied to the DDS of diseases. © 2023 Elsevier B.V., All rights reserved.},
	journal = {Journal of Biomedical Informatics},
	author = {Lyu, Kewei and Tian, Yu and Shang, Yong and Zhou, Tianshu and Yang, Ziyue and Liu, Qianghua and Yao, Xi and Zhang, Ping and Chen, Jianghua and Li, Jingsong},
	year = {2023},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Semantics, machine learning, natural language processing, Decision support systems, Modeling languages, differential diagnosis, semantics, Quality control, Diagnosis, Electronic health record, Language, clinical decision support system, electronic health record, sentiment analysis, knowledge, decision support system, cardiovascular disease, Clinical, Causal knowledge, Diabetic nephropathy, human, language, Decision Support Systems, Diseases, Humans, Article, controlled study, diagnostic test accuracy study, Decision supports, Electronic health, Health records, Automated, automated pattern recognition, Pattern Recognition, receiver operating characteristic, disease exacerbation, Records management, Real-world, clinical evaluation, chronic kidney failure, chronic respiratory tract disease, diabetes mellitus, Diabetes Mellitus, Diabetic Nephropathies, diabetic nephropathy, Diagnostic decisions, glomerulopathy, insulin dependent diabetes mellitus, kidney disease, mathematical phenomena, metabolic acidosis, noise reduction, non insulin dependent diabetes mellitus, Three models, thyrotropin},
	annote = {Type: Article}
}

@article{macilenti2024PromptingIsNot,
	file = {References/pdf/macilenti2024PromptingIsNot.pdf},
	title = {Prompting is not all you need {Evaluating} {GPT}-4 performance on a real-world ontology alignment use case},
	volume = {246},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213321670&doi=10.1016%2Fj.procs.2024.09.557&partnerID=40&md5=4395b728eb94e98a4e4f110b2a408f1f},
	doi = {10.1016/j.procs.2024.09.557},
	abstract = {Ontology Alignment (OA) is a complex, demanding and error-prone task, requiring the intervention of domain and Semantic Web experts. Automating the alignment process thus becomes a must-do, especially when involving large datasets, to at least produce a first input for human experts. Automated ontology alignment could benefit from the outstanding language ability of Large Language Models (LLMs), which could implicitly provide the background knowledge that has been the Achilles' heel of traditional alignment systems. However, this requires a correct evaluation of the performance of LLMs and understanding the best way to incorporate them into more specific tools. In this paper, we show that a naive prompting approach on the popular GPT-4 model could face several problems when transferred to real-world use cases. To this end, we replicated the methods of Norouzi et al. (2023), applied to the OAEI 2022 conference track, on a reference alignment between a pair of datasets (reduced versions of two popular thesauri: European Commission's EuroVoc and TESEO, from the Italian Senate of the Republic), which has never been tested in OAEI evaluation campaigns. This reference alignment has several features common to real-world use cases: it is has a larger size than those considered in the study we replicated, it is not published online and is therefore not subject to data contamination and it involves relations between concepts that are more complex than simple equivalence. The replicated methods achieved a significantly lower performance on our reference alignment than on the OAEI 2022 conference track, suggesting that size, data contamination, and semantic complexity need to be considered when using LLMs for the alignment task. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Procedia Computer Science},
	author = {Macilenti, Giulio and Stellato, Armando and Fiorelli, Manuel},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Semantic technologies, Semantics, Ontology alignment, Performance, Latent semantic analysis, Large datasets, Semantic-Web, Human expert, Real-world, Error prone tasks},
	pages = {1289 -- 1298},
	annote = {Issue: C Type: Conference paper}
}

@article{magnini2024ActivelyLearningOntologies,
	file = {References/pdf/magnini2024ActivelyLearningOntologies.pdf},
	title = {Actively {Learning} {Ontologies} from {LLMs}: {First} {Results} ({Extended} {Abstract})},
	volume = {3739},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202829104&partnerID=40&md5=c17031ab39e0c1d51fce6e8892f975f6},
	abstract = {In active learning a learner attempts to acquire some kind of knowledge by posing questions to a teacher. Here we consider that the teacher is a language model and study the case in which the knowledge is expressed as an ontology. To evaluate the approach, we present first results testing logical consistency and the performance of GPT and other language models when answering whether concept inclusions from existing ℰℒ ontologies are ‘true’ or ‘false’. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Magnini, Matteo and Ozaki, Ana and Squarcialupi, Riccardo},
	year = {2024},
	note = {Section: 0},
	keywords = {Active learning, Language model, Reinforcement learning, Performance, Federated learning, Active Learning, Adversarial machine learning, Ontology's, Contrastive Learning, Extended abstracts, Teachers', Language study, Logical consistency},
	annote = {Type: Conference paper}
}

@article{mai2025DoLlmsReally,
	file = {References/pdf/mai2025DoLlmsReally.pdf},
	title = {Do {LLMs} {Really} {Adapt} to {Domains}? {An} {Ontology} {Learning} {Perspective}},
	volume = {15231},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211249904&doi=10.1007%2F978-3-031-77844-5_7&partnerID=40&md5=38704b1d84f3911bba65b157ac5f2a75},
	doi = {10.1007/978-3-031-77844-5_7},
	abstract = {Large Language Models (LLMs) have demonstrated unprecedented prowess across various natural language processing tasks in various application domains. Recent studies show that LLMs can be leveraged to perform lexical semantic tasks, such as Knowledge Base Completion (KBC) or Ontology Learning (OL). However, it has not effectively been verified whether their success is due to their ability to reason over unstructured or semi-structured data, or their effective learning of linguistic patterns and senses alone. This unresolved question is particularly crucial when dealing with domain-specific data, where the lexical senses and their meaning can completely differ from what a LLM has learned during its training stage. This paper investigates the following question: Do LLMs really adapt to domains and remain consistent in the extraction of structured knowledge, or do they only learn lexical senses instead of reasoning? To answer this question and, we devise a controlled experiment setup that uses WordNet to synthesize parallel corpora, with English and gibberish terms. We examine the differences in the outputs of LLMs for each corpus in two OL tasks: relation extraction and taxonomy discovery. Empirical results show that, while adapting to the gibberish corpora, off-the-shelf LLMs do not consistently reason over semantic relationships between concepts, and instead leverage senses and their frame. However, fine-tuning improves the performance of LLMs on lexical semantic tasks even when the domain-specific terms are arbitrary and unseen during pre-training, hinting at the applicability of pre-trained LLMs for OL. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Mai, Huu Tan and Chu, Cuongxuan and Paulheim, Heiko},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Ontology learning, Semantics, Federated learning, Latent semantic analysis, Domain adaptation, Language processing, Adversarial machine learning, Lexical semantics, Natural languages, Domain Knowledge, Natural language processing systems, Contrastive Learning, Domain specific, Applications domains, Semantic tasks, Incorrect information},
	pages = {126 -- 143},
	annote = {Type: Conference paper}
}

@article{maldonadosifuentes2024TowardsProtoArtificial,
	file = {References/pdf/maldonadosifuentes2024TowardsProtoArtificial.pdf},
	title = {Towards a {Proto} {Artificial} {General} {Intelligence}: {The} {Role} of {Large} {Language} {Model} {Ontologies} in its {Development}},
	volume = {28},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210772833&doi=10.13053%2FCyS-28-3-5200&partnerID=40&md5=11b4e51d55ef1d1b31e9000fc6d96fbe},
	doi = {10.13053/CyS-28-3-5200},
	abstract = {Proto Artificial General Intelligence (ProtoAGI) aims to create a versatile artificial intelligence system capable of autonomously performing diverse tasks. A foundational element of ProtoAGI is the Large Language Model (LLM) ontology, which plays a crucial role in organizing and retrieving information about different LLMs, enabling the selection of the most appropriate model for specific tasks. This ontology, the first of several designed to support ProtoAGI, addresses key challenges in managing and accessing information regarding LLM capabilities, performance, and task suitability. We present the methodology for constructing this ontology, covering data extraction, enrichment, and model recommendation using a generalized LLM API. The initial version of this ontology involved processing over a million tokens, underscoring the system’s complexity and the scale of information integrated. This ontology is designed for continuous updates, ensuring that ProtoAGI remains current with the latest advancements in LLMs. The ongoing development of this ontology marks a significant step in ProtoAGI’s evolution, following an initial proof-of-concept demonstrated during the 2024 eclipse, where the feasibility of integrating such a comprehensive LLM ontology into a general-purpose AI system was shown. By making this ontology accessible to the broader AI community, we aim to accelerate further advancements in AGI research and applications. © 2024 Elsevier B.V., All rights reserved.},
	number = {3},
	journal = {Computacion y Sistemas},
	author = {Maldonado-Sifuentes, Christian Efraín and Vargas-Santiago, Mariano and Solis-Gamboa, Samuel and Sidorov, G. and Lechuga-Gutierrez, Luis and González-Andrade, Francisco and del Carmen Heras Sánchez, María},
	year = {2024},
	note = {Section: 0},
	pages = {1401 -- 1415},
	annote = {Type: Article}
}

@article{maratsi2025ProposedMethodologySub,
	file = {References/pdf/maratsi2025ProposedMethodologySub.pdf},
	title = {A {Proposed} {Methodology} for {Sub}-{Ontology} {Development} in {Comprehensive} {Scientific} {Investigation} {Methods} and {Tooling}},
	volume = {2331},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013971365&doi=10.1007%2F978-3-031-81974-2_3&partnerID=40&md5=781fa0b9db7a6cb02c568dd99d22e7d9},
	doi = {10.1007/978-3-031-81974-2_3},
	abstract = {The role of ontologies in facilitating search capabilities within large collections of data is critical; the integration and analysis of diverse data sources becomes feasible as ontologies frame the data conceptually and provide a common understanding of terms and their relationships- the lack of ontological and conceptual support entailing the opposite effect. Along with documents and data lost in the vast-ness of available yet disparate data sources, numerous scientific papers and published research remain undiscovered due to poor linking to their respective scientific domain and investigation method(s) described in them. Within the scope of this study is to retrieve existing Wikidata method codes for 3 disciplines: psychology, neuroscience and cultural heritage, and analyse them, with the purpose of identifying gaps in the usage of hierarchical levels or codes, and examining whether they are currently capable of sufficiently describing the methodological domains in question, while also pertaining to a suitable level of specificity in or-der for the related data to be efficiently and effectively queried and retrieved. The findings revealed several issues regarding the discoverability and semantic search capabilities to retrieve scientific literature papers on research (or investigation) methods and tooling for the in-word disciplines. In this light, a proposed methodology to alleviate the current situation is drafted, introducing the utilisation of technological means, such as LLMs, to assist in identifying orphan categories of methods or tools and, by benchmarking against basic existing ontologies (e.g., FrameNet or other related Linked Open Vocabularies), to enrich the hierarchical structure of current representation practices in this regard. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Communications in Computer and Information Science},
	author = {Maratsi, Maria Ioanna and Gialoussi, Nina and Alexopoulos, Charalampos and Charalabidis, Yannis K.},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Interoperability, Ontology, LLM, Ontology mapping, Semantic Web, Semantic interoperability, Semantics, Semantic search, Wikidata, Open Data, Linked open data, Codes (symbols), Data handling, Linked open vocabulary, LOV, Scientific method, Scientific tool, Wikidata code},
	pages = {28 -- 43},
	annote = {Type: Conference paper}
}

@article{marchenko2024TaxorankconstructNovelRank,
	file = {References/pdf/marchenko2024TaxorankconstructNovelRank.pdf},
	title = {{TaxoRankConstruct}: {A} {Novel} {Rank}-based {Iterative} {Approach} to {Taxonomy} {Construction} with {Large} {Language} {Models}},
	volume = {3933},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000713232&partnerID=40&md5=e01af4385899f16ca8a870408073ad18},
	abstract = {Paper presents a novel method for the construction of taxonomical classifications (concept hierarchies) for concepts using large language models. Traditional methods of taxonomy construction often focus heavily on hypernym-hyponym relationships, emphasizing hierarchical connections between concepts. However, these approaches tend to overlook the qualitative attributes of objects that form the foundation of classification. In contrast, the approach proposed in this paper is based on the premise that "the properties of objects are primary, while the types of objects are secondary."This foundational idea drives the development of TaxoRankConstruct, a novel rank-based iterative approach that leverages Large Language Models (LLMs) to construct more nuanced taxonomies. This method aims to enhance the clarity and precision of taxonomical hierarchies by systematically organizing concepts based on specific, identifiable characteristics. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Marchenko, Oleksandr O. and Dvoichenkov, Danylo},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Natural language processing, Language model, Ontology learning, Taxonomies, Language processing, Human-AI collaboration, Natural languages, Contrastive Learning, Concept hierarchies, Hierarchical classification, Taxonomy construction},
	pages = {11 -- 27},
	annote = {Type: Conference paper}
}

@article{mateiu2023OntologyEngineeringWith,
	file = {References/pdf/mateiu2023OntologyEngineeringWith.pdf},
	title = {Ontology engineering with {Large} {Language} {Models}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193849216&doi=10.1109%2FSYNASC61333.2023.00038&partnerID=40&md5=82842416ae615f60e5776b5c7fd1ef98},
	doi = {10.1109/SYNASC61333.2023.00038},
	abstract = {We tackle the task of enriching ontologies by automatically translating natural language (NL) into Description Logic (DL). Since Large Language Models (LLMs) are the best tools for translations, we fine-tuned a GPT-3 model to convert NL into OWL Functional Syntax. For fine-tuning, we designed pairs of sentences in NL and the corresponding translations. This training pairs cover various aspects from ontology engineering: instances, class subsumption, domain and range of relations, object properties relationships, disjoint classes, complements, or cardinality restrictions. The resulted axioms are used to enrich an ontology, in a human supervised manner. The developed tool is publicly provided as a Protégé plugin.},
	journal = {2023 25th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)},
	author = {Mateiu, Patricia and Groza, Adrian},
	month = sep,
	year = {2023},
	note = {Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, large language models, OWL, Protege, Description logic, ontology engineering, Training, Computational linguistics, fine-tuning, Natural languages, Syntactics, Task analysis, Protege plugin, Scientific computing, Ontology's, Plug-ins, Fine tuning, Translation (languages), Data description},
	pages = {226--229},
	annote = {ISSN: 2470-881X}
}

@article{maudslay2022HomonymyInformationEnglish,
	file = {References/pdf/maudslay2022HomonymyInformationEnglish.pdf},
	title = {Homonymy {Information} for {English} {WordNet}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145881520&partnerID=40&md5=7d6804fd4c3843c66e32af494ae8f6f5},
	abstract = {A widely acknowledged shortcoming of WordNet is that it lacks a distinction between word meanings which are systematically related (polysemy), and those which are coincidental (homonymy). Several previous works have attempted to fill this gap, by inferring this information using computational methods. We revisit this task, and exploit recent advances in language modelling to synthesise homonymy annotation for Princeton WordNet. Previous approaches treat the problem using clustering methods; by contrast, our method works by linking WordNet to the Oxford English Dictionary, which contains the information we need. To perform this alignment, we pair definitions based on their proximity in an embedding space produced by a Transformer model. Despite the simplicity of this approach, our best model attains an F1 of .97 on an evaluation set that we annotate. The outcome of our work is a high-quality homonymy annotation layer for Princeton WordNet, which we release. © 2023 Elsevier B.V., All rights reserved.},
	author = {Maudslay, Rowan Hall and Teufel, Simone},
	year = {2022},
	note = {Section: 0},
	keywords = {Ontology, Language model, Modeling languages, Polysemy, Embeddings, Wordnet, Word meaning, Clustering methods, Transformer modeling, Best model, Homonymy, Oxford english dictionary},
	pages = {90 -- 98},
	annote = {Type: Conference paper}
}

@Article{mcdaniel2019EvaluatingDomainOntologies,
	file = {References/pdf/mcdaniel2019EvaluatingDomainOntologies.pdf},
	author = {Melinda McDaniel and Veda C. Storey},
	title = {Evaluating Domain Ontologies: Clarification,
                  Classification, and Challenges},
	journal = {{ACM} Comput. Surv.},
	year = 2019,
	volume = 52,
	number = 4,
	pages = {70:1--70:44},
	doi = {10.1145/3329124},
	url = {https://doi.org/10.1145/3329124},
	timestamp = {Sat, 08 Jan 2022 02:23:13 +0100},
	biburl = {https://dblp.org/rec/journals/csur/McDanielS19.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@InProceedings{mcqueen1967SomeMethodsClassification,
	file = {References/pdf/macqueen1967SomeMethodsClassification.pdf},
	title = {Some methods of classification and analysis of multivariate observations},
	author = {McQueen, James B},
	booktitle = {Proc. of 5th Berkeley Symposium on Math. Stat. and Prob.},
	pages = {281--297},
	year = {1967}
}

@Article{mei2025SurveyContextEngineering,
	file = {References/pdf/mei2025SurveyContextEngineering.pdf},
	author = {Lingrui Mei and Jiayu Yao and Yuyao Ge and Yiwei
                  Wang and Baolong Bi and Yujun Cai and Jiazhi Liu and
                  Mingyu Li and Zhong{-}Zhi Li and Duzhen Zhang and
                  Chenlin Zhou and Jiayi Mao and Tianze Xia and
                  Jiafeng Guo and Shenghua Liu},
	title = {A Survey of Context Engineering for Large Language
                  Models},
	journal = {CoRR},
	year = 2025,
	volume = {abs/2507.13334},
	doi = {10.48550/ARXIV.2507.13334},
	eprint = {2507.13334},
	eprinttype = {arXiv},
	url = {https://doi.org/10.48550/arXiv.2507.13334},
	timestamp = {Sun, 17 Aug 2025 16:23:23 +0200},
	biburl = {https://dblp.org/rec/journals/corr/abs-2507-13334.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{menad2024SimhomerSiameseModels,
	file = {References/pdf/menad2024SimhomerSiameseModels.pdf},
	title = {{SiMHOMer}: {Siamese} {Models} for {Health} {Ontologies} {Merging} and {Validation} {Through} {Large} {Language} {Models}},
	volume = {14848},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202640943&doi=10.1007%2F978-3-031-64629-4_9&partnerID=40&md5=de2865e3afc8b4c91c14e156b4378612},
	doi = {10.1007/978-3-031-64629-4_9},
	abstract = {Ontologies play a key role in representing and structuring domain knowledge. In the biomedical domain, the need for this type of representation is crucial for structuring, coding, and retrieving data. However, available ontologies do not encompass all the relevant concepts and relationships. In this paper, we propose the framework SiMHOMer (Siamese Modela for Health Ontologies Merging), to semantically merge and integrate the most relevant ontologies in the healthcare domain, including diseases, symptoms, drugs, and adverse events. We propose to rely on the siamese neural models we developed and trained on biomedical data, BioSTransformers, to identify new relevant relations between different concepts and to create new semantic relations, the objective being to build a new consistent merging ontology that specialists could use as a new resource for various health-related use cases. To validate the new relations, we have leveraged existing relations in the UMLS Metathesaurus and the Semantic Network. To evaluate our findings, a large language model is also used. Our first results show promising improvements for future research. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Menad, Safaa and Abdeddaïm, Saïd and Soualmia, Lina F.},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Language model, Semantics, Electronic health record, Biomedical ontologies, Ontology merging, Domain knowledge, UMLS, Ontology's, Neural modelling, Siamese neural model, Ontology validations},
	pages = {117 -- 129},
	annote = {Type: Conference paper}
}

@article{menad2025BiostransformersHealthOntologies,
	file = {References/pdf/menad2025BiostransformersHealthOntologies.pdf},
	title = {{BioSTransformers} for {Health} {Ontologies} {Merging}},
	volume = {2454},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005256728&doi=10.1007%2F978-3-031-87569-4_8&partnerID=40&md5=f9ad7e159e38ba7f06cc31bd6ae5256a},
	doi = {10.1007/978-3-031-87569-4_8},
	abstract = {Ontologies are fundamental for organizing and representing knowledge within a specific domain. In the biomedical domain, this type of representation is essential for structuring, coding, and retrieving data efficiently. However, existing biomedical ontologies often lack coverage of all relevant concepts and relationships in the same resource. In this paper, we describe our model for semantically merging and integrating diseases, symptoms, drugs, and adverse events into a single, unified resource. We propose leveraging BioSTransformers, our developed and trained siamese neural network models on biomedical data, to discover new relevant relationships between different biomedical concepts and create novel semantic relationships between these concepts. Our objective is to build a consistent, merged ontology that serves as a valuable resource for healthcare professionals across various health-related applications. To assess and validate the newly generated relationships, we plan to use external knowledge bases such as the UMLS Metathesaurus and the Semantic Network, alongside a large language model. Initial results are encouraging and pave the way for further research. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Communications in Computer and Information Science},
	author = {Menad, Safaa and Abdeddaïm, Saïd and Soualmia, Lina F.},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Language model, Biomedical ontologies, Ontology merging, Adverse events, Biomedical domain, Diseases, Ontology's, Disease symptoms, Neural modelling, Siamese neural model},
	pages = {169 -- 181},
	annote = {Type: Conference paper}
}

@article{menad2025PredictingSimilaritiesBetween,
	file = {References/pdf/menad2025PredictingSimilaritiesBetween.pdf},
	title = {Predicting {Similarities} {Between} {Biomedical} {Ontologies} : {The} {UMLs} {Use}-{Case}},
	doi = {10.1109/CBMS65348.2025.00134},
	abstract = {Biomedical ontologies are crucial for organizing domain-specific knowledge, yet traditional alignment methods relying on lexical matching often fail to capture complex semantic relationships. To address this limitation, we propose a novel approach leveraging siamese neural networks and transformerbased models to enhance ontology alignment within the biomedical domain. Our method applies self-supervised contrastive learning to biomedical literature, optimizing the prediction of semantic similarities between concepts in the UMLS Metathesaurus. The results demonstrate that this approach surpasses lexical-based techniques by identifying contextual relationships and uncovering new interconnections among UMLS terminologies. This highlights the potential of our models in improving ontology alignment and enriching biomedical knowledge integration.},
	journal = {2025 IEEE 38th International Symposium on Computer-Based Medical Systems (CBMS)},
	author = {Menad, Safaa and Abdeddaïm, Saïd and Soualmia, Lina F.},
	month = jun,
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Ontology, Terminology, Semantics, Biomedical Ontology, Neural networks, Transformers, Vocabulary, Semantic Similarity, Unified modeling language, Contrastive learning, Alignment, UMLS Metathesaurus, Biological system modeling, Vectors, Matching, Sentence Embeddings, Siamese Neural Network},
	pages = {648--653},
	annote = {ISSN: 2372-9198}
}

@article{mijalcheva2022LearningRobustFood,
	file = {References/pdf/mijalcheva2022LearningRobustFood.pdf},
	title = {Learning {Robust} {Food} {Ontology} {Alignment}},
	doi = {10.1109/BigData55660.2022.10020417},
	abstract = {In today’s knowledge society, large number of information systems use many different individual schemes to represent data. Ontologies are a promising approach for formal knowledge representation and their number is growing rapidly. The semantic linking of these ontologies is a necessary prerequisite for establishing interoperability between the large number of services that structure the data with these ontologies. Consequently, the alignment of ontologies becomes a central issue when building a worldwide Semantic Web. There is a need to develop automatic or at least semi-automatic techniques to reduce the burden of manually creating and maintaining alignments. Ontologies are seen as a solution to data heterogeneity on the Web. However, the available ontologies are themselves a source of heterogeneity. On the Web, there are multiple ontologies that refer to the same domain, and with that comes the challenge of a given graph-based system using multiple ontologies whose taxonomy is different, but the semantics are the same. This can be overcome by aligning the ontologies or by finding the correspondence between their components.In this paper, we propose a method for indexing ontologies as a support to a solution for ontology alignment based on a neural network. In this process, for each semantic resource we combine the graph based representations from the RDF2vec model, together with the text representation from the BERT model in order to capture the semantic and structural features. This methodology is evaluated using the FoodOn and OntoFood ontologies, based on the Food Onto Map alignment dataset, which contains 155 unique and validly aligned resources. Using these limited resources, we managed to obtain accuracy of 74\% and F1 score of 75\% on the test set, which is a promising result that can be further improved in future. Furthermore, the methodology presented in this paper is both robust and ontology-agnostic. It can be applied to any ontology, regardless of the domain.},
	journal = {2022 IEEE International Conference on Big Data (Big Data)},
	author = {Mijalcheva, Viktorija and Davcheva, Ana and Gramatikov, Sasho and Jovanovik, Milos and Trajanov, Dimitar and Stojanov, Riste},
	month = dec,
	year = {2022},
	note = {Section: 0},
	keywords = {Ontologies, Natural language processing, Semantic Web, Semantics, Big Data, Neural networks, Embeddings, Taxonomy, Ontology Alignment, Training, Data linking, Data normalization, Text representation},
	pages = {4097--4104}
}

@article{molina2025RobotSituationTask,
	file = {References/pdf/molina2025RobotSituationTask.pdf},
	title = {Robot {Situation} and {Task} {Awareness} {Using} {Large} {Language} {Models} and {Ontologies}},
	doi = {10.1109/DSN-W65791.2025.00045},
	abstract = {Robot situation and task awareness requires a deep understanding of the environment, the domain knowledge, and task planning. We present a novel framework that integrates ontologies, Large Language Models (LLMs), and the Planning Domain Definition Language (PDDL) to enhance the comprehension capabilities of robotic systems. The framework employs an LLM to extract structured knowledge from natural language descriptions provided by a human user, populating an OWL ontology that captures relevant objects, properties, and relations. This populated ontology is then used to parse a PDDL Domain file and generate a corresponding PDDL Problem file to solve particular planning problems. This research contributes to the intersection of knowledge representation, natural language processing, and automated planning, providing a solution for intuitive human-robot interaction through LLMs.},
	journal = {2025 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W)},
	author = {Molina, Victor and Ruiz-Celada, Oriol and Suarez, Raul and Rosell, Jan and Zaplana, Isiah},
	month = jun,
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Large Language Models, Natural language processing, Large language models, ontologies, OWL, Planning, Human-robot interaction, Robots, Conferences, robotic manipulation, task planning},
	pages = {96--103},
	annote = {ISSN: 2325-6664}
}

@article{moskvoretskii2024AreLargeLanguage,
	file = {References/pdf/moskvoretskii2024AreLargeLanguage.pdf},
	title = {Are {Large} {Language} {Models} {Good} at {Lexical} {Semantics}? {A} {Case} of {Taxonomy} {Learning}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195968824&partnerID=40&md5=62d830955a58a2e4366d6f4cd82571e1},
	abstract = {Recent studies on LLMs do not pay enousdfgh attention to linguistic and lexical semantic tasks, such as taxonomy learning. In this paper, we explore the capacities of Large Language Models featuring LLaMA-2 and Mistral for several Taxonomy-related tasks. We introduce a new methodology and algorithm for data collection via stochastic graph traversal leading to controllable data collection. Collected cases provide the ability to form nearly any type of graph operation. We test the collected dataset for learning taxonomy structure based on English WordNet and compare different input templates for fine-tuning LLMs. Moreover, we apply the fine-tuned models on such datasets on the downstream tasks achieving state-of-the-art results on the TexEval-2 dataset. © 2024 Elsevier B.V., All rights reserved.},
	author = {Moskvoretskii, Viktor and Panchenko, Alexander I. and Nikishina, Irina},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology, LLM, Language model, Semantics, Taxonomies, Wordnet, Computational linguistics, Data collection, Lexical semantics, Data acquisition, Learning systems, Semantic tasks, Taxonomy construction, Hypernym prediction, Linguistic semantics, Statistical tests, Stochastic systems, Taxonomy learning},
	pages = {1498 -- 1510},
	annote = {Type: Conference paper}
}

@article{mukanova2024LlmPoweredNatural,
	file = {References/pdf/mukanova2024LlmPoweredNatural.pdf},
	title = {{LLM}-{Powered} {Natural} {Language} {Text} {Processing} for {Ontology} {Enrichment}},
	volume = {14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198457806&doi=10.3390%2Fapp14135860&partnerID=40&md5=4e0679495529c9ad85ba2cee224641c0},
	doi = {10.3390/app14135860},
	abstract = {This paper describes a method and technology for processing natural language texts and extracting data from the text that correspond to the semantics of an ontological model. The proposed method is distinguished by the use of a Large Language Model algorithm for text analysis. The extracted data are stored in an intermediate format, after which individuals and properties that reflect the specified semantics are programmatically created in the ontology. The proposed technology is implemented using the example of an ontological model that describes the geographical configuration and administrative–territorial division of Kazakhstan. The proposed method and technology can be applied in any subject areas for which ontological models have been developed. The results of the study can significantly improve the efficiency of using knowledge bases based on semantic networks by converting texts in natural languages into semantically linked data. © 2024 Elsevier B.V., All rights reserved.},
	number = {13},
	journal = {Applied Sciences (Switzerland)},
	author = {Mukanova, Assel S. and Milosz, Marek and Dauletkaliyeva, Assem and Nazyrova, Aizhan and Yelibayeva, Gaziza and Kuzin, Dmitrii A. and Kussepova, Lazzat T.},
	year = {2024},
	note = {Section: 0},
	annote = {Type: Article}
}

@Article{mungall2012UberonIntegrativeMulti,
	file = {References/pdf/mungall2012UberonIntegrativeMulti.pdf},
	author = {Mungall, Christopher J and Torniai, Carlo and
                  Gkoutos, Georgios V and Lewis, Suzanna E and
                  Haendel, Melissa A},
	title = {Uberon, an integrative multi-species anatomy
                  ontology},
	journal = {Genome Biology},
	year = 2012,
	volume = 13,
	number = 1,
	month = jan,
	issn = {1474-760X},
	doi = {10.1186/gb-2012-13-1-r5},
	url = {http://dx.doi.org/10.1186/gb-2012-13-1-r5},
	publisher = {Springer Science and Business Media LLC}
}

@article{noori2025LlmsInAction,
	file = {References/pdf/noori2025LlmsInAction.pdf},
	title = {{LLMs} in {Action}: {Robust} {Metrics} for {Evaluating} {Automated} {Ontology} {Annotation} {Systems}},
	volume = {16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001031577&doi=10.3390%2Finfo16030225&partnerID=40&md5=0f97f7b802e682af93b9493065ed2e69},
	doi = {10.3390/info16030225},
	abstract = {Ontologies are critical for organizing and interpreting complex domain-specific knowledge, with applications in data integration, functional prediction, and knowledge discovery. As the manual curation of ontology annotations becomes increasingly infeasible due to the exponential growth of biomedical and genomic data, natural language processing (NLP)-based systems have emerged as scalable alternatives. Evaluating these systems requires robust semantic similarity metrics that account for hierarchical and partially correct relationships often present in ontology annotations. This study explores the integration of graph-based and language-based embeddings to enhance the performance of semantic similarity metrics. Combining embeddings generated via Node2Vec and large language models (LLMs) with traditional semantic similarity metrics, we demonstrate that hybrid approaches effectively capture both structural and semantic relationships within ontologies. Our results show that combined similarity metrics outperform individual metrics, achieving high accuracy in distinguishing child–parent pairs from random pairs. This work underscores the importance of robust semantic similarity metrics for evaluating and optimizing NLP-based ontology annotation systems. Future research should explore the real-time integration of these metrics and advanced neural architectures to further enhance scalability and accuracy, advancing ontology-driven analyses in biomedical research and beyond. © 2025 Elsevier B.V., All rights reserved.},
	number = {3},
	journal = {Information (Switzerland)},
	author = {Noori, Ali and Devkota, Pratik and Mohanty, Somya D. and Manda, Prashanti},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Language model, Semantics, Gene Ontology, Data integration, Gene ontology, Semantic similarity, Scalability, Graph embeddings, Data curation, Language processing, Natural languages, Ontology's, Natural language processing systems, Annotation systems, Ontology annotations, Similarity metrics},
	annote = {Type: Article}
}

@article{nori2024MedpromptO1Exploration,
	title = {From medprompt to o1: Exploration of run-time strategies for medical challenge problems and beyond},
	author = {Nori, Harsha and Usuyama, Naoto and King, Nicholas and McKinney, Scott Mayer and Fernandes, Xavier and Zhang, Sheng and Horvitz, Eric},
	journal = {arXiv preprint arXiv:2411.03590},
	year = {2024}
}

@article{norouzi2023ConversationalOntologyAlignment,
	file = {References/pdf/norouzi2023ConversationalOntologyAlignment.pdf},
	title = {Conversational {Ontology} {Alignment} with {ChatGPT}},
	volume = {3591},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180754943&partnerID=40&md5=8a06be5d71f54f617249262d138c8531},
	abstract = {This study evaluates the applicability and efficiency of ChatGPT for ontology alignment using a naive approach. ChatGPT’s output is compared to the results of the Ontology Alignment Evaluation Initiative 2022 campaign using conference track ontologies. This comparison is intended to provide insights into the capabilities of a conversational large language model when used in a naive way for ontology matching and to investigate the potential advantages and disadvantages of this approach. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Norouzi, Sanaz Saki and Mahdavinejad, Mohammad Saeid and Hitzler, Pascal Al},
	year = {2023},
	note = {Section: 0},
	keywords = {ChatGPT, Large language model, Ontology, Language model, Ontology matching, Ontology alignment, Prompt engineering, Schema matching, Computational linguistics, Ontology's, LLM behavior},
	pages = {61 -- 66},
	annote = {Type: Conference paper}
}

@Article{norouzi2024OntologyPopulationUsing,
	file = {References/pdf/norouzi2024OntologyPopulationUsing.pdf},
	author = {Sanaz Saki Norouzi and Adrita Barua and Antrea
                  Christou and Nikita Gautam and Andrew Eells and
                  Pascal Hitzler and Cogan Shimizu},
	title = {Ontology Population using LLMs},
	journal = {CoRR},
	year = 2024,
	volume = {abs/2411.01612},
	doi = {10.48550/ARXIV.2411.01612},
	eprint = {2411.01612},
	eprinttype = {arXiv},
	url = {https://doi.org/10.48550/arXiv.2411.01612},
	timestamp = {Wed, 11 Dec 2024 17:23:30 +0100},
	biburl = {https://dblp.org/rec/journals/corr/abs-2411-01612.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{norouzi2025ConexionConceptExtraction,
	file = {References/pdf/norouzi2025ConexionConceptExtraction.pdf},
	title = {{ConExion}: {Concept} {Extraction} with {Large} {Language} {Models}},
	volume = {3977},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008495646&partnerID=40&md5=26d9192d1623044601ad692225d1c091},
	abstract = {In this paper, an approach for concept extraction from documents using pre-trained large language models (LLMs) is presented. Compared with conventional methods that extract keyphrases summarizing the important information discussed in a document, our approach tackles a more challenging task of extracting all present concepts related to the specific domain, not just the important ones. Through comprehensive evaluations of two widely used benchmark datasets, we demonstrate that our method improves the F{\textbackslash}textlessinf{\textbackslash}textgreater1{\textbackslash}textless/inf{\textbackslash}textgreater score compared to state-of-the-art techniques. Additionally, we explore the potential of using prompts within these models for unsupervised concept extraction. The extracted concepts are intended to support domain coverage evaluation of ontologies and facilitate ontology learning, highlighting the effectiveness of LLMs in concept extraction tasks. Our source code and datasets are publicly available at https://github.com/ISE-FIZKarlsruhe/concept\_extraction. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Norouzi, Ebrahim and Hertling, Sven and Sack, Harald},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Concept extraction, Extraction, Benchmark datasets, Comprehensive evaluation, Conventional methods, Key-phrase, Key-phrases extractions, Present keyphrase extraction, State-of-the-art techniques},
	annote = {Type: Conference paper}
}

@misc{noy2001OntologyDevelopment101,
	file = {References/pdf/noy2001OntologyDevelopment101.pdf},
	title = {Ontology development 101: A guide to creating your first ontology},
	author = {Noy, Natalya F and McGuinness, Deborah L and others},
	year = {2001},
	publisher = {Stanford knowledge systems laboratory technical report KSL-01-05 and~…}
}

@article{oba2021AutomaticClassificationOntology,
	file = {References/pdf/oba2021AutomaticClassificationOntology.pdf},
	title = {Automatic {Classification} for {Ontology} {Generation} by {Pretrained} {Language} {Model}},
	volume = {12798},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112704288&doi=10.1007%2F978-3-030-79457-6_18&partnerID=40&md5=5cb2f6fa7ec2a1f6545b7a90c3c7f634},
	doi = {10.1007/978-3-030-79457-6_18},
	abstract = {In recent years, for systemizing enormous information on the Internet, ontology that organizes knowledge through a hierarchical structure of concepts has received a large amount of attention in spatiotemporal information science. However, constructing ontology manually requires a large amount of time and deep knowledge of the target field. Consequently, automating ontology generation from raw text corpus is required to meet the ontology demand. As an initial attempt of ontology generation with a neural network, a recurrent neural N = network (RNN)-based method is proposed. However, updating the architecture is possible because of the development in natural language processing (NLP). In contrast, the transfer learning of language models trained by a large unlabeled corpus such as bidirectional encoder representations from transformers (BERT) has yielded a breakthrough in NLP. Inspired by these achievements, to apply transfer learning of language models, we propose a novel workflow for ontology generation consisting of two-stage learning. This paper provides a quantitative comparison between the proposed method and the existing methods. Our result showed that our best method improved accuracy by over 12.5\%. © 2021 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Oba, Atsushi and Paik, Incheon and Kuwana, Ayato},
	year = {2021},
	note = {Section: 0},
	keywords = {Ontology, Language model, Ontology generation, Intelligent systems, Transfer learning, Computational linguistics, Recurrent neural networks, Learning systems, Hierarchical structures, Natural language processing systems, Automatic classification, Deep knowledge, NAtural language processing, Quantitative comparison, Spatiotemporal information},
	pages = {210 -- 221},
	annote = {Type: Conference paper}
}

@article{ocker2023ExploringLargeLanguage,
	file = {References/pdf/ocker2023ExploringLargeLanguage.pdf},
	title = {Exploring {Large} {Language} {Models} as a {Source} of {Common}-{Sense} {Knowledge} for {Robots}},
	volume = {3632},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184382211&partnerID=40&md5=9fb8e419f9ec5f7722d6c3c66bf1f13b},
	abstract = {Service robots need common-sense knowledge to help humans in everyday situations as it enables them to understand the context of their actions. However, approaches that use ontologies face a challenge because common-sense knowledge is often implicit, i.e., it is obvious to humans but not explicitly stated. This paper investigates if Large Language Models (LLMs) can fill this gap. Our experiments reveal limited effectiveness in the selective extraction of contextual action knowledge, suggesting that LLMs may not be sufficient on their own. However, the large-scale extraction of general, actionable knowledge shows potential, indicating that LLMs can be a suitable tool for efficiently creating ontologies for robots. This paper shows that the technique used for knowledge extraction can be applied to populate a minimalist ontology, showcasing the potential of LLMs in synergy with formal knowledge representation. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Ocker, Felix and Deigmoeller, Joerg and Eggert, Julian P.},
	year = {2023},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Knowledge representation, Knowledge extraction, Service robots, Computational linguistics, Extraction, Commonsense knowledge, Robots, Ontology's, Large-scales, Formal knowledge representations, Selective extraction},
	annote = {Type: Conference paper}
}

@article{omar2023MeasurementChatgptPerformance,
	file = {References/pdf/omar2023MeasurementChatgptPerformance.pdf},
	title = {Measurement of {ChatGPT} {Performance} in {Mapping} {Natural} {Language} {Speficaction} into an {Entity} {Relationship} {Diagram}},
	doi = {10.1109/ICSC58660.2023.10449869},
	abstract = {This paper explores the entity relationship diagram, a popular conceptual model used to depict entities, attributes, and relationships graphically. To help with this, we use ChatGPT, a sophisticated language model based on the GPT architecture, which can translate natural language text into an entity relationship diagram. The paper details the process of evaluating how well ChatGPT can perform compared to other state-of-the-art approaches for entity and relationship extraction. Our experimental findings demonstrate the strong ability of ChatGPT to translate natural language text into entity relationship diagrams, which has potential applications for knowledge graph building, data integration, and database schema design. Moreover, it can aid in automating the extraction and organization of information from unstructured text data, thereby simplifying the study of complex systems.},
	journal = {2023 IEEE 11th International Conference on Systems and Control (ICSC)},
	author = {Omar, Mussa A.},
	month = dec,
	year = {2023},
	note = {Section: 0},
	keywords = {ChatGPT, natural language processing, Machine learning, Software engineering, Chatbots, Natural languages, Adaptation models, Companies, Task analysis, entity relationship diagram},
	pages = {530--535},
	annote = {ISSN: 2379-0067}
}

@article{onoe2021ModelingFineGrained,
	file = {References/pdf/onoe2021ModelingFineGrained.pdf},
	title = {Modeling {Fine}-{Grained} {Entity} {Types} with {Box} {Embeddings}},
	url = {https://aclanthology.org/2021.acl-long.160/},
	doi = {10.18653/v1/2021.acl-long.160},
	abstract = {Neural entity typing models typically represent fine-grained entity types as vectors in a high-dimensional space, but such spaces are not well-suited to modeling these types' complex interdependencies. We study the ability of box embeddings, which embed concepts as d-dimensional hyperrectangles, to capture hierarchies of types even when these relationships are not defined explicitly in the ontology. Our model represents both types and entity mentions as boxes. Each mention and its context are fed into a BERT-based model to embed that mention in our box space; essentially, this model leverages typological clues present in the surface text to hypothesize a type representation for the mention. Box containment can then be used to derive both the posterior probability of a mention exhibiting a given type and the conditional probability relations between types themselves. We compare our approach with a vector-based typing model and observe state-of-the-art performance on several entity typing benchmarks. In addition to competitive typing performance, our box-based model shows better performance in prediction consistency (predicting a supertype and a subtype together) and confidence (i.e., calibration), demonstrating that the box-based model captures the latent type hierarchies better than the vector-based model does.},
	journal = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
	author = {Onoe, Yasumasa and Boratko, Michael and McCallum, Andrew and Durrett, Greg},
	editor = {Zong, Chengqing and Xia, Fei and Li, Wenjie and Navigli, Roberto},
	month = aug,
	year = {2021},
	note = {Place: Online
Publisher: Association for Computational Linguistics
Section: 0},
	pages = {2051--2064}
}

@article{onozuka2025AnalysisLlmsRdf,
	file = {References/pdf/onozuka2025AnalysisLlmsRdf.pdf},
	title = {Analysis of {LLMs} for {RDF} {Triple} {Generation}: {Semantic} and {Syntactic} {Evaluation} {Using} {WebNLG}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009459996&doi=10.1109%2FICSC64641.2025.00025&partnerID=40&md5=a0086a1e9ef98246a60e66d2507f9e5a},
	doi = {10.1109/ICSC64641.2025.00025},
	abstract = {Using the WebNLG dataset as ground truth, we evaluate the capability of large language models (LLMs) to generate resource description framework triples from natural language input. The proposed method employs two complementary evaluation metrics: cosine similarity for assessing semantic proximity and graph edit distance for comparing structural aspects of triple sets. The analysis demonstrates that these metrics provide distinct yet complementary perspectives on semantic evaluation, enabling a comprehensive assessment of the natural language understanding capabilities of LLMs. Through this approach, we demonstrate that modern LLMs exhibit sophisticated abilities in integrated syntax and semantics processing by utilizing distributed representations where both types of information coexist within high-dimensional vector spaces. This integration suggests that understanding of language structure of LLMs transcends simple pattern recognition to achieve meaningful semantic comprehension.},
	journal = {2025 19th International Conference on Semantic Computing (ICSC)},
	author = {Onozuka, Soichi and Ohnishi, Takaaki},
	month = feb,
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Large language model, Ontology, Natural language processing, Language model, Large language models, Semantics, RDF, Resource description framework, Similarity, LLMs, Computational linguistics, Resource Description Framework (RDF), Latent semantic analysis, Measurement, Evaluation metrics, Ground truth, Natural languages, Syntactics, Vectors, Pattern recognition, Ontology's, Natural language processing systems, Large datasets, Vector spaces, RDF triples, Resources description frameworks},
	pages = {136--143},
	annote = {ISSN: 2472-9671}
}

@misc{openai2024EmbeddingModels,
	author = {OpenAI},
	title = {{N}ew embedding models and {A}{P}{I} updates --- openai.com},
	howpublished = {\url{https://openai.com/index/new-embedding-models-and-api-updates/}},
	year = {25-01-2024},
	note = {[Accessed 06-05-2025]}
}

@misc{openai2024HelloGpt4o,
	title = {Hello {{GPT-4o}}},
	author = {{OpenAI}},
	date = {2024},
	year = 2024,
	url = {https://openai.com/index/hello-gpt-4o/},
	urldate = {2024-09-12},
	abstract = {We're announcing GPT-4 Omni, our new flagship model which can reason across audio, vision, and text in real time.},
	langid = {american},
	timestamp = {2024-09-12T19:38:33Z}
}

@misc{openai2024IntroducingOpenaiO1,
	title = {Introducing {{OpenAI O1}}},
	author = {{OpenAI}},
	year = 2024,
	url = {https://openai.com/o1/}
}

@article{otsuki2025EfficientMaintenanceLarge,
	file = {References/pdf/otsuki2025EfficientMaintenanceLarge.pdf},
	title = {Efficient {Maintenance} of {Large}-{Scale} {Medical} {Dictionaries} {Using} {Large} {Language} {Models}: {A} {Case} for {Biomarkers}},
	volume = {329},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013383391&doi=10.3233%2FSHTI250951&partnerID=40&md5=f2e9ca4306b90c3c282c72bd9b48ba1a},
	doi = {10.3233/SHTI250951},
	abstract = {Dictionaries are essential in natural language processing and provide significant value across tasks; however, their construction and maintenance are expensive. Leveraging manual revision histories to suggest automatic corrections for unedited terms offers a promising solution to enhance quality while reducing costs. This study proposes a method for automatically correcting metadata in a large-scale medical dictionary containing more than 500,000 terms. By utilizing large language models that excel in zero-shot settings, the system estimates the dictionary information without task-specific configurations. This method was demonstrated through experiments on variations in gene biomarker expression, a task that requires specialized medical knowledge. The results indicate that this approach can significantly reduce the dictionary maintenance burden. This record is sourced from MEDLINE/PubMed, a database of the U.S. National Library of Medicine},
	journal = {Studies in Health Technology and Informatics},
	author = {Otsuki, Yuka and Yada, Shuntaro and Nishiyama, Tomohiro and Sakurai, Toshiyuki and Okada, Masafumi and Kudo, Noriko and Kawabata, Kyoko and Fujimaki, Takako and Nagai, Hiroyuki and Wakamiya, Shoko},
	year = {2025},
	note = {Section: 0},
	keywords = {large language model, Large Language Models, natural language processing, Natural Language Processing, Biomarkers, human, Humans, biological marker, book, Dictionaries as Topic},
	pages = {804 -- 808},
	annote = {Type: Article}
}

@article{ourekouch2025RelcheckImprovingRelation,
	file = {References/pdf/ourekouch2025RelcheckImprovingRelation.pdf},
	title = {{RelCheck}: {Improving} {Relation} {Extraction} with {Ontology}-{Guided} and {LLM}-{Based} {Validation}},
	volume = {15718},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007980362&doi=10.1007%2F978-3-031-94575-5_24&partnerID=40&md5=e240bb1f207e7bb0f1d5f7e949973cc2},
	doi = {10.1007/978-3-031-94575-5_24},
	abstract = {Relation extraction (RE) is a key task in natural language processing (NLP) and a core component of information extraction. It focuses on identifying semantic relations between entities in text. Pretrained language models (PLMs), such as transformer-based models like BERT, XLNet and RoBERTa, have made notable progress in RE. Predictions of relations from these models are provided with varying confidence levels. While high-confidence predictions of relations are generally accurate, low-confidence predictions tend to be less precise and often lead to inaccuracies. The current research question is how to re-evaluate the low confidence predictions to ensure the overall confidence of a PLM. To solve this problem we propose a framework using automatically generated ontology schemas and LLMs. We first propose an algorithm that constructs ontology schemas from the RE datasets (TACRED and ReTACRED). Then we use LLMs to validate these low-confidence predictions through prompting to further improve the precision of final predictions. Experimental results on transformer-based models, GCN and LSTM-based models across two large-scale RE datasets (TACRED and ReTACRED) show significant improvements in precision and overall performance. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Ourekouch, Mounir and Koulali, Mohammed Amine and Erradi, Mohamed},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Relation extraction, Semantics, Knowledge graph construction, Ontology schema, Data mining, Forecasting, Computational linguistics, Extraction, Graph construction, Ontology's, Natural language processing systems, Large datasets, Prediction models, Confidence predictions, Model-based validation},
	pages = {441 -- 459},
	annote = {Type: Conference paper {\textbar} RAYYAN-LABELS: ontology-supported application}
}

@article{ouyang2024OntologyEnrichmentEffective,
	file = {References/pdf/ouyang2024OntologyEnrichmentEffective.pdf},
	series = {{KDD} '24},
	title = {Ontology {Enrichment} for {Effective} {Fine}-grained {Entity} {Typing}},
	url = {https://doi.org/10.1145/3637528.3671857},
	doi = {10.1145/3637528.3671857},
	abstract = {Fine-grained entity typing (FET) is the task of identifying specific entity types at a fine-grained level for entity mentions based on their contextual information. Conventional methods for FET require extensive human annotation, which is time-consuming and costly given the massive scale of data. Recent studies have been developing weakly supervised or zero-shot approaches. We study the setting of zero-shot FET where only an ontology is provided. However, most existing ontology structures lack rich supporting information and even contain ambiguous relations, making them ineffective in guiding FET. Recently developed language models, though promising in various few-shot and zero-shot NLP tasks, may face challenges in zero-shot FET due to their lack of interaction with task-specific ontology. In this study, we propose øurs, where we (1) enrich each node in the ontology structure with two categories of extra information:instance information for training sample augmentation andtopic information to relate types with contexts, and (2) develop a coarse-to-fine typing algorithm that exploits the enriched information by training an entailment model with contrasting topics and instance-based augmented training samples. Our experiments show that øurs achieves high-quality fine-grained entity typing without human annotation, outperforming existing zero-shot methods by a large margin and rivaling supervised methods. øurs also enjoys strong transferability to unseen and finer-grained types. We will open source this work upon acceptance.},
	journal = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
	author = {Ouyang, Siru and Huang, Jiaxin and Pillai, Pranav and Zhang, Yunyi and Zhang, Yu and Han, Jiawei},
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Ontology, Language model, Ontology enrichment, Modeling languages, language models, Fine-grained entity typing, Natural language inference, Supervised learning, Zero-shot learning, Language inference, fine-grained entity typing, natural language inference, zero-shot learning, Natural languages, Ontology's, Natural language processing systems, Inference engines, Fine grained, Human annotations, Training sample},
	pages = {2318--2327},
	annote = {event-place: Barcelona, Spain}
}

@Article{pan2023LargeLanguageModels,
	file = {References/pdf/pan2023LargeLanguageModels.pdf},
	author = {Jeff Z. Pan and Simon Razniewski and Jan{-}Christoph
                  Kalo and Sneha Singhania and Jiaoyan Chen and Stefan
                  Dietze and Hajira Jabeen and Janna Omeliyanenko and
                  Wen Zhang and Matteo Lissandrini and Russa Biswas
                  and Gerard de Melo and Angela Bonifati and Edlira
                  Vakaj and Mauro Dragoni and Damien Graux},
	title = {Large Language Models and Knowledge Graphs:
                  Opportunities and Challenges},
	journal = {CoRR},
	year = 2023,
	volume = {abs/2308.06374},
	doi = {10.48550/ARXIV.2308.06374},
	eprint = {2308.06374},
	eprinttype = {arXiv},
	url = {https://doi.org/10.48550/arXiv.2308.06374},
	timestamp = {Mon, 03 Jun 2024 15:23:13 +0200},
	biburl = {https://dblp.org/rec/journals/corr/abs-2308-06374.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{pan2025RagApproachGenerating,
	file = {References/pdf/pan2025RagApproachGenerating.pdf},
	title = {A {RAG} {Approach} for {Generating} {Competency} {Questions} in {Ontology} {Engineering}},
	volume = {2331},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013955848&doi=10.1007%2F978-3-031-81974-2_6&partnerID=40&md5=9076217b9a4a337e38d337f34bfddfc2},
	doi = {10.1007/978-3-031-81974-2_6},
	abstract = {Competency question (CQ) formulation is central to several ontology development and evaluation methodologies. Traditionally, the task of crafting these competency questions heavily relies on the effort of domain experts and knowledge engineers which is often time-consuming and labor-intensive. With the emergence of Large Language Models (LLMs), there arises the possibility to automate and enhance this process. Unlike other similar works which use existing ontologies or knowledge graphs as input to LLMs, we present a retrieval-augmented generation (RAG) approach that uses LLMs for the automatic generation of CQs given a set of scientific papers considered to be a domain knowledge base. We investigate its performance and specifically, we study the impact of different number of papers to the RAG and different temperature setting of the LLM. We conduct experiments using GPT-4 on two domain ontology engineering tasks and compare results against ground-truth CQs constructed by domain experts. Empirical assessments on the results, utilizing evaluation metrics (precision and consistency), reveal that compared to zero-shot prompting, adding relevant domain knowledge to the RAG improves the performance of LLMs on generating CQs for concrete ontology engineering tasks. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Communications in Computer and Information Science},
	author = {Pan, Xueli and Ossenbruggen, Jacco Van and de Boer, Victor and Huang, Zhisheng},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology engineering, Knowledge graph, Large language model, Ontology, Language model, Ontology development, Competency question, Domain knowledge, Performance, Domain Knowledge, Ontology evaluations, Domain experts, Engineering tasks},
	pages = {70 -- 81},
	annote = {Type: Conference paper}
}

@article{peng2023OntologyMatchingUsing,
	file = {References/pdf/peng2023OntologyMatchingUsing.pdf},
	title = {Ontology {Matching} using {Textual} {Class} {Descriptions}},
	volume = {3591},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180776271&partnerID=40&md5=5115bca4fda57f89bac2412fb02a8506},
	abstract = {In this paper, we propose TEXTO, a TEXT-based Ontology matching system. This matcher leverages the rich semantic information of classes available in most ontologies by a combination of a pre-trained word embedding model and a pre-trained language model. Its performance is evaluated on the datasets of the OAEI Common Knowledge Graphs Track, augmented with the description of each class, and a new dataset based on the refreshed alignment of Schema.org and Wikidata. Our results demonstrate that TEXTO outperforms all state-of-art matchers in terms of precision, recall and F1 score. In particular, we show that almost perfect class alignment can be achieved using textual content only, excluding any structural information like the graph of classes or the instances of each class. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Peng, Yiwen and Alam, Mehwish Afshar and Bonald, Thomas},
	year = {2023},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Semantics, Ontology matching, Embeddings, Performance, Computational linguistics, Ontology's, Matching system, Textual information, Semantics Information, Common knowledge},
	pages = {67 -- 72},
	annote = {Type: Conference paper}
}

@article{peng2024RefiningWikidataTaxonomy,
	file = {References/pdf/peng2024RefiningWikidataTaxonomy.pdf},
	series = {{CIKM} '24},
	title = {Refining {Wikidata} {Taxonomy} using {Large} {Language} {Models}},
	url = {https://doi.org/10.1145/3627673.3679156},
	doi = {10.1145/3627673.3679156},
	abstract = {Due to its collaborative nature, Wikidata is known to have a complex taxonomy, with recurrent issues like the ambiguity between instances and classes, the inaccuracy of some taxonomic paths, the presence of cycles, and the high level of redundancy across classes. Manual efforts to clean up this taxonomy are time-consuming and prone to errors or subjective decisions. We present WiKC, a new version of Wikidata taxonomy cleaned automatically using a combination of Large Language Models (LLMs) and graph mining techniques. Operations on the taxonomy, such as cutting links or merging classes, are performed with the help of zero-shot prompting on an open-source LLM. The quality of the refined taxonomy is evaluated from both intrinsic and extrinsic perspectives, on a task of entity typing for the latter, showing the practical interest of WiKC.},
	journal = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
	author = {Peng, Yiwen and Bonald, Thomas and Alam, Mehwish},
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {large language model, knowledge graphs, graph mining},
	pages = {5395--5399},
	annote = {event-place: Boise, ID, USA}
}

@article{perini2025BrickllmPythonLibrary,
	file = {References/pdf/perini2025BrickllmPythonLibrary.pdf},
	title = {{BrickLLM}: {A} {Python} library for generating {Brick}-compliant {RDF} graphs using {LLMs}},
	volume = {30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000797991&doi=10.1016%2Fj.softx.2025.102121&partnerID=40&md5=7f6b3f13a501848795a1ca05f2d8be99},
	doi = {10.1016/j.softx.2025.102121},
	abstract = {One of the key challenges of Energy Management and Information Systems in buildings is related to the lack of interoperability, due to the absence of standardization of the underlying data models. In recent years, there has been a growing interest in using ontology-based metadata models to address this issue, as they offer a structured approach to organize and share information across diverse systems (e.g. Brick ontology). However, the creation of ontology-based metadata models is often a labor-intensive task that requires specific domain expertise, hindering the practical use of such data models. For this reason, in this work the BrickLLM Python library is introduced, which addresses this issue by generating Brick-compliant Resource Description Framework graphs through Large Language Models, automating the process of converting natural language building descriptions into machine-readable metadata. The library supports both cloud-based APIs (e.g., OpenAI, Anthropic, Fireworks AI), local models (e.g. LLaMa3.2, etc.) and evenfine-tuned ones. This paper explores the architecture, key functionalities, and practical applications of BrickLLM, showcasing its potential impact on the future of building systems monitoring and automation. © 2025 Elsevier B.V., All rights reserved.},
	journal = {SoftwareX},
	author = {Perini, Marco and Antonucci, Daniele and Giudice, Rocco and Piscitelli, Marco Savino and Capozzoli, Alfonso},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Information management, RDF, Brick, Portability, Metadata, Energy, Ontology-based, RDF graph, Network security, In-buildings, Metadata model, Problem oriented languages, Structured approach},
	annote = {Type: Article}
}

@InProceedings{petersen2023LexicalSemanticsWith,
	file = {References/pdf/petersen2023LexicalSemanticsWith.pdf},
	author = {Petersen, Erika and Potts, Christopher},
	title = {Lexical Semantics with Large Language Models: A Case
                  Study of English “break”},
	year = 2023,
	booktitle = {Findings of the Association for Computational
                  Linguistics: EACL 2023},
	publisher = {Association for Computational Linguistics},
	pages = {490–511},
	doi = {10.18653/v1/2023.findings-eacl.36},
	url = {http://dx.doi.org/10.18653/v1/2023.findings-eacl.36}
}

@article{pham2025EnhancingOntologiesWith,
	file = {References/pdf/pham2025EnhancingOntologiesWith.pdf},
	title = {Enhancing {Ontologies} with {Large} {Language} {Models}: {A} {Semi}-{Automated} {Approach}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005143430&doi=10.24251%2Fhicss.2025.189&partnerID=40&md5=464e13815927a5a34910caab9c2bff4a},
	doi = {10.24251/hicss.2025.189},
	abstract = {The process of creating and maintaining domain ontologies is a time- and resource-intensive activity, given the dynamic nature of domain knowledge and the regular introduction of new terms. This study aims to determine the effectiveness of large language models (LLMs) in augmenting the domain ontology authoring process. We fine-tuned state-of-the-art pre-trained LLMs and evaluated their performance on two tasks: synonym identification and parent-child relationship identification. The models achieved 98\% accuracy in the first task and 75.4\% accuracy in the second, demonstrating significant capabilities in automating synonym identification and relationship classification. In addition to providing a methodological basis for further extending and improving these results, we demonstrate that LLMs can be effectively used in ontology development and maintenance. This can save time and effort in the process. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
	author = {Pham, Anh T.V. and Huettemann, Sebastian and Mueller, Roland M.},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Natural language processing, Language model, Domain ontologies, Ontology enrichment, Ontology extension, Language processing, Natural languages, Ontology's, Natural language processing systems, Transformer modeling, Automatic identification},
	pages = {1565 -- 1574},
	annote = {Type: Conference paper}
}

@article{piazza2024LargeLanguageModels,
	file = {References/pdf/piazza2024LargeLanguageModels.pdf},
	title = {Large {Language} {Models} for {Automatic} {Standardization} of {Cyber} {Deception} {Plans} based on the {Adversary} {Engagement} {Ontology}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214561637&doi=10.1109%2FMILCOM61039.2024.10773797&partnerID=40&md5=6c47ba88a0ce6b2a790968dfdddcf22a},
	doi = {10.1109/MILCOM61039.2024.10773797},
	abstract = {Adversary Engagement Ontology (AEO) is a candidate ontology for the Unified Cyber Ontology (UCO), a community effort aimed at ontological standardization of cyber domain concepts and objects under a unifying framework. It forms a part of the Cyber Domain Ontology (CDO). In the past, community efforts and development have always been labor-intensive with regards to changes in ontology, example generation for adopters, and documentation generation. Large Language Models (LLMs), such as Claude-3.5-Sonnet and GPT4, have been proven capable of automating many tasks and aiding in human expert decision-making. Additionally, LLMs have been used in code interpretation, generation, and evaluation with efficiency and accuracy comparable to that of humans. This emergent capability of LLMs has led to the advantage of using LLMs to streamline the process of ontology development. Motivated by the aforementioned-approaches, we aim to demonstrate how these foundational LLMs can assist in ontology example generation and development, as well as be utilized to automate structured, albeit tedious tasks.},
	journal = {MILCOM 2024 - 2024 IEEE Military Communications Conference (MILCOM)},
	author = {Piazza, Nancirose and Upadhayay, Bibek and Scarpa, Ronald and Behzadan, Vahid},
	month = oct,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Ontology, Natural language processing, Language model, Large language models, Domain ontologies, Ontology development, Standardization, Decision making, Accuracy, Documentation, Codes, Military communication, Adversary Engagement, Ontology's, Decisions makings, Human expert, Adversary engagement, Domain concepts, Labour-intensive, Plan-based},
	pages = {1--5},
	annote = {ISSN: 2155-7586}
}

@article{pisu2024ClassifyingScientificTopic,
	file = {References/pdf/pisu2024ClassifyingScientificTopic.pdf},
	title = {Classifying {Scientific} {Topic} {Relationships} with {SciBERT}},
	volume = {3759},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204687914&partnerID=40&md5=a41e6340c629d84f102448f83d2f523d},
	abstract = {Current AI systems, including smart search engines and recommendation systems tools for streamlining literature reviews, and interactive question-answering platforms, are becoming indispensable for researchers to navigate and understand the vast landscape of scientific knowledge.Taxonomies and ontologies of research topics are key to this process, but manually creating them is costly and often leads to outdated results.This poster paper shows the use of SciBERT model to automatically generate research topic ontologies.Our model excels at identifying semantic relationships between research topics, outperforming traditional methods.This approach promises to streamline the creation of accurate and up-to-date ontologies, enhancing the effectiveness of AI tools for researchers. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Pisu, Alessia and Pompianu, Livio and Salatino, Angelo Antonio and Osborne, Francesco and Riboni, Daniele and Motta, Enrico and Reforgiato Recupero, Diego},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Language model, Semantics, Search engines, Question answering, Ontology generation, Recommender systems, Knowledge graph generation, AI systems, SciBERT, Ontology's, 'current, Graph generation, Research topics},
	annote = {Type: Conference paper}
}

@article{pisu2024LeveragingLanguageModels,
	file = {References/pdf/pisu2024LeveragingLanguageModels.pdf},
	title = {Leveraging {Language} {Models} for {Generating} {Ontologies} of {Research} {Topics}},
	volume = {3747},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203384989&partnerID=40&md5=be1194ae4f01daf079586c6797976a77},
	abstract = {The current generation of artificial intelligence technologies, such as smart search engines, recommendation systems, tools for systematic reviews, and question-answering applications, plays a crucial role in helping researchers manage and interpret scientific literature. Taxonomies and ontologies of research topics are a fundamental part of this environment as they allow intelligent systems and scientists to navigate the ever-growing number of research papers. However, creating these classifications manually is an expensive and time-consuming process, often resulting in outdated and coarse-grained representations. Consequently, researchers have been focusing on developing automated or semi-automated methods to create taxonomies of research topics. This paper studies the application of transformer-based language models for generating research topic ontologies. Specifically, we have developed a model leveraging SciBERT to identify four semantic relationships between research topics (supertopic, subtopic, same-as, and other) and conducted a comparative analysis against alternative solutions. The preliminary findings indicate that the transformer-based model significantly surpasses the performance of models reliant on traditional features. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Pisu, Alessia and Pompianu, Livio and Salatino, Angelo Antonio and Osborne, Francesco and Riboni, Daniele and Motta, Enrico and Reforgiato Recupero, Diego},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Semantics, Question answering, Taxonomies, Ontology generation, Recommender systems, Knowledge graph generation, SciBERT, Ontology's, Artificial intelligence technologies, Graph generation, Research topics, Current generation},
	pages = {11},
	annote = {Type: Conference paper}
}

@article{plu2025ComprehensiveBenchmarkEvaluating,
	file = {References/pdf/plu2025ComprehensiveBenchmarkEvaluating.pdf},
	title = {A {Comprehensive} {Benchmark} for {Evaluating} {LLM}-{Generated} {Ontologies}},
	volume = {3953},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003711461&partnerID=40&md5=8fd2db4b7f249a0ddbc9b672049723f2},
	abstract = {This paper presents a methodology for evaluating ontologies that are automatically generated by Large Language Models (LLMs). Our approach combines quantitative metrics that compare generated ontologies with respect to a human-made reference and qualitative user assessments across diverse domains. We apply this methodology to evaluate the ontologies produced by various LLMs, including Claude 3.5 Sonnet, GPT-4o, and GPT-4o-mini. The results demonstrate the benchmark’s effectiveness in identifying strengths and weaknesses of LLM-generated ontologies, providing valuable insights for improving automated ontology generation techniques. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Plu, Julien and Escobar, Oscar Moreno and Trouillez, Edouard and Gapin, Axelle and Troncy, Raphaël},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Ontology development, Evaluation, Ontology generation, Benchmark, Ontology's, Automatically generated, Diverse domains, Quantitative metric},
	annote = {Type: Conference paper}
}

@Article{povedavillalon2022LotIndustrialOriented,
	file = {References/pdf/povedavillalon2022LotIndustrialOriented.pdf},
	author = {Mar{\'{\i}}a Poveda{-}Villal{\'{o}}n and Alba
                  Fern{\'{a}}ndez{-}Izquierdo and Mariano
                  Fern{\'{a}}ndez{-}L{\'{o}}pez and Ra{\'{u}}l
                  Garc{\'{\i}}a{-}Castro},
	title = {{LOT:} An industrial oriented ontology engineering
                  framework},
	journal = {Eng. Appl. Artif. Intell.},
	year = 2022,
	volume = 111,
	pages = 104755,
	doi = {10.1016/J.ENGAPPAI.2022.104755},
	url = {https://doi.org/10.1016/j.engappai.2022.104755},
	timestamp = {Wed, 18 May 2022 10:21:45 +0200},
	biburl = {https://dblp.org/rec/journals/eaai/Poveda-Villalon22.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{procko2023AutomaticGenerationBfo,
	file = {References/pdf/procko2023AutomaticGenerationBfo.pdf},
	title = {Automatic {Generation} of {BFO}-{Compliant} {Aristotelian} {Definitions} in {OWL} {Ontologies} with {GPT}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184805224&doi=10.1109%2FTransAI60598.2023.00042&partnerID=40&md5=7f05736a0f125cf5bfd0cf0230dd81c3},
	doi = {10.1109/TransAI60598.2023.00042},
	abstract = {Ontologies are representational artifacts that purport to accurately describe some aspect of reality, including the entities and the relations that hold between them. In computer science, ontologies are software artifacts containing the schematic structure for machine-readable knowledge, typically formed as a graph of subject-predicate-object triples, constrained through Description Logics. These resources and their relations are self-defining, i.e., some resource may be defined by considering all its stated relations. Resources are often attended with natural language annotations, that humans may read and interpret, such as labels and definitions. Many long-standing ontologies have useless lexical definitions that define resources cyclically, e.g., a FOAF: Person is simply defined as “A person”. In Aristotelian terms, the definition of a thing should be reducible, by using terms simpler than itself, such that every definition can be unpacked up to the most general thing, which can only be defined by stating examples and use cases. This paper presents an innovative technique that leverages the Generative Pre-trained Transformer (GPT) large language model, GPT -4, for automatically generating Aristotelian definition annotations for OWL classes that engenders compliance with the Basic Formal Ontology standard.},
	journal = {2023 Fifth International Conference on Transdisciplinary AI (TransAI)},
	author = {Procko, Tyler Thomas and Ochoa, Omar and Elvira, Timothy},
	month = sep,
	year = {2023},
	note = {Section: 0},
	keywords = {Ontology, GPT, Linked data, ontology, OWL, Annotations, Description logic, Transformers, Software, Epistemology, Generative pre-trained transformer, Linked Data, BFO, Regulatory compliance, epistemology, Automatic Generation, Natural languages, Maintenance engineering, Ontology's, Birds, Linked datum, OWL ontologies, Data description, Schematic structures, Software artefacts},
	pages = {141--146},
	annote = {Type: Conference paper}
}

@article{procko2023Gpt4Stochastic,
	file = {References/pdf/procko2023Gpt4Stochastic.pdf},
	title = {{GPT}-4: {A} {Stochastic} {Parrot} or {Ontological} {Craftsman}? {Discovering} {Implicit} {Knowledge} {Structures} in {Large} {Language} {Models}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184808375&doi=10.1109%2FTransAI60598.2023.00043&partnerID=40&md5=1508a82f1a0c8b3376895ff708ffdb11},
	doi = {10.1109/TransAI60598.2023.00043},
	abstract = {Ontologies are representational artifacts that purport to accurately portray the aspect of reality under the purview of the ontologists laboring upon them. Ontologies exist in a spectrum of formality, from lexical thesauri to knowledge graphs, to collections of statements of first-order logic. The recent proliferation of Large Language Models (LLMs) has brought to bear interactive “knowledge bases” with general awareness of most things. As ontologists create ontologies from their understanding of reality; and as LLMs, presumably, possess some “understanding” of reality, embedded in their vector matrices corresponding to lexical terms from massive quantities of learned texts, a question is posed: what form of ontology can an LLM create when prompted about some novel facet of reality, without explicitly asking it for an ontology? I.e., will an LLM categorize things into bins, or a subsumption hierarchy, or perhaps something else? LLMs, as they are understood, respond when prompted with the most likely response, because they are predictors of next tokens, i.e., they are stochastic parrots. In any case, it is posited that, if prompted without any explicit request for an ontology, an LLM can produce an ontology of novel form, effectively granting insight into the “understanding” an LLM has of the world, as all humans possess an understanding of the world that ontologies are based upon. This paper explores the use of the flagship LLM, GPT-4, in forming an ontology of a novel domain.},
	journal = {2023 Fifth International Conference on Transdisciplinary AI (TransAI)},
	author = {Procko, Tyler Thomas and Elvira, Timothy and Ochoa, Omar},
	month = sep,
	year = {2023},
	note = {Section: 0},
	keywords = {Knowledge graphs, Large language model, Ontology, Language model, GPT, large language models, ontology, OWL, taxonomy, Taxonomy, Formal logic, Organizations, Computational linguistics, Visualization, Supervised learning, First order logic, Natural languages, Stochastic processes, Ontology's, Birds, Implicit knowledge, Stochastic systems, Knowledge structures, Spectra's, Stochastic models, Stochastics},
	pages = {147--154},
	annote = {Type: Conference paper}
}

@article{pruski2025EnhancingEscoWith,
	file = {References/pdf/pruski2025EnhancingEscoWith.pdf},
	title = {Enhancing {ESCO} with {Generative} {AI}: {A} {Dynamic} {Approach} to {Supporting} 21st {Century} {Education}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008223380&doi=10.1109%2FEDUCON62633.2025.11016516&partnerID=40&md5=b97ab1cd1b30a3fd2cf619db06f6e211},
	doi = {10.1109/EDUCON62633.2025.11016516},
	abstract = {In the rapidly evolving landscape of engineering education, upskilling and lifelong learning have become critical to maintaining competitiveness and fostering innovation. The use of ontologies, such as the European Skills, Competences, Qualifications, and Occupations (ESCO), plays a crucial role in organizing and managing the skills required for modern engineering roles. However, the slow pace of ontology updates and the lack of contextual adaptability present significant challenges, leading to outdated and irrelevant information for educators, learners, and industry professionals. This paper explores the potential of integrating Large Language Models (LLMs) with knowledge engineering to accelerate the process of updating ontologies like ESCO. By dynamically analyzing data and incor-porating contextual information, LLMs offer promising avenues for enhancing the evolution and precision of these ontologies. We discuss the potential impact of this approach in engineering education, particularly in aligning ups killing and reskilling efforts with the demands of emerging technologies such as AI -driven automation and digital engineering. This paper aims to highlight how LLMs can support the creation of more responsive, context-aware learning frameworks, ultimately sustaining educational ex-cellence and fostering critical thinking in engineering education.},
	journal = {2025 IEEE Global Engineering Education Conference (EDUCON)},
	author = {Pruski, Cédric and Gallais, Marie and Da Silveira, Marcos},
	month = apr,
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Large language model, Ontology, LLM, Language model, Large language models, Knowledge engineering, Ontology evolution, Robustness, Technological innovation, Contextualization, Engineering education, Soft sensors, lifelong learning, Multilingual, Industries, Qualifications, Upskilling, Ontology's, Dynamic approaches, Industry professionals, Life long learning, Modern engineering},
	pages = {1--5},
	annote = {ISSN: 2165-9567}
}

@article{qiang2024AgentOmLeveraging,
	file = {References/pdf/qiang2024AgentOmLeveraging.pdf},
	title = {Agent-{OM}: {Leveraging} {LLM} {Agents} for {Ontology} {Matching}},
	volume = {18},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3712221.3712222},
	doi = {10.14778/3712221.3712222},
	abstract = {Ontology matching (OM) enables semantic interoperability between different ontologies and resolves their conceptual heterogeneity by aligning related entities. OM systems currently have two prevailing design paradigms: conventional knowledge-based expert systems and newer machine learning-based predictive systems. While large language models (LLMs) and LLM agents have revolutionised data engineering and have been applied creatively in many domains, their potential for OM remains underexplored. This study introduces a novel agent-powered LLM-based design paradigm for OM systems. With consideration of several specific challenges in leveraging LLM agents for OM, we propose a generic framework, namely Agent-OM (Agent for Ontology Matching), consisting of two Siamese agents for retrieval and matching, with a set of OM tools. Our framework is implemented in a proof-of-concept system. Evaluations of three Ontology Alignment Evaluation Initiative (OAEI) tracks over state-of-the-art OM systems show that our system can achieve results very close to the long-standing best performance on simple OM tasks and can significantly improve the performance on complex and few-shot OM tasks.},
	number = {3},
	journal = {Proc. VLDB Endow.},
	author = {Qiang, Zhangcheng and Wang, Weiqing and Taylor, Kerry},
	month = nov,
	year = {2024},
	note = {Section: 0},
	keywords = {Interoperability, Ontology, Language model, Semantic interoperability, Semantics, Ontology matching, Search engines, Expert systems, Performance, Adversarial machine learning, Learning systems, Ontology's, Matching system, Model agents, Design paradigm, Knowledge-based expert systems, Related entities},
	pages = {516--529},
	annote = {Publisher: VLDB Endowment}
}

@article{qiang2025OaeiLlmBenchmark,
	file = {References/pdf/qiang2025OaeiLlmBenchmark.pdf},
	title = {{OAEI}-{LLM}: {A} {Benchmark} {Dataset} for {Understanding} {Large} {Language} {Model} {Hallucinations} in {Ontology} {Matching}},
	volume = {3953},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003710219&partnerID=40&md5=2bc85a3f291179ba30149f9d98dc04dc},
	abstract = {Hallucinations of large language models (LLMs) commonly occur in domain-specific downstream tasks, with no exception in ontology matching (OM). The prevalence of using LLMs for OM raises the need for benchmarks to better understand LLM hallucinations. The OAEI-LLM dataset is an extended version of the Ontology Alignment Evaluation Initiative (OAEI) datasets that evaluate LLM-specific hallucinations in OM tasks. We outline the methodology used in dataset construction and schema extension, and provide examples of potential use cases. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Qiang, Zhangcheng and Taylor, Kerry L. and Wang, Weiqing and Jiang, Jing},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Language model, Ontology matching, Ontology alignment, Modeling languages, Large datasets, Domain specific, Down-stream, Benchmark datasets, Extended versions, Large language model hallucination},
	annote = {Type: Conference paper}
}

@article{racharak2024AutomatedMedicalRdf,
	file = {References/pdf/racharak2024AutomatedMedicalRdf.pdf},
	title = {An {Automated} {Medical} {Rdf} {Knowledge} {Graph} {Construction} {From} {Text} {Using} in-{Context} {Learning}},
	doi = {10.1109/KSE63888.2024.11063495},
	abstract = {The parameterized knowledge within large language models (LLMs), like ChatGPT, offers a significant opportunity for modelling domain knowledge base from text. However, LLMs' context sensitivity can hinder obtaining precise and taskaligned outcomes, thus requiring a suitable design for leveraging prompt engineering. This study explores the efficacy of different prompting methods for RDF knowledge graph construction from medical documents as our preliminary investigation, aiming to develop an efficient pipeline for a large-scale automatic knowledge graph construction according to semantic web standards and technologies. The results show that leveraging in-context learning within LLMs is capable of extracting an array of precise RDF triples from text. We perform a qualitative analysis of the extracted triples with different prompt templates, giving insights that could guide potential development in the research field.},
	journal = {2024 16th International Conference on Knowledge and System Engineering (KSE)},
	author = {Racharak, Teeradaj and Wang, Tongyu and Jearanaiwongkul, Watanee},
	month = nov,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Knowledge graphs, Large language models, Resource description framework, Knowledge engineering, Prompt engineering, Prompting, Standards, OpenAI, Few-shot, Sensitivity, Resource Description Framework, Pipelines, Systems engineering and theory, Generative Knowledge Graph Extraction},
	pages = {465--471},
	annote = {ISSN: 2694-4804}
}

@InProceedings{rajpoot2023GptFinreIn,
	file = {References/pdf/rajpoot2023GptFinreIn.pdf},
	title = "{GPT}-{F}in{RE}: In-context Learning for Financial Relation Extraction using Large Language Models",
	author = "Rajpoot, Pawan  and
      Parikh, Ankur",
	editor = "Chen, Chung-Chi  and
      Huang, Hen-Hsen  and
      Takamura, Hiroya  and
      Chen, Hsin-Hsi  and
      Sakaji, Hiroki  and
      Izumi, Kiyoshi",
	booktitle = "Proceedings of the Sixth Workshop on Financial Technology and Natural Language Processing",
	month = nov,
	year = "2023",
	address = "Bali, Indonesia",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2023.finnlp-2.5/",
	doi = "10.18653/v1/2023.finnlp-2.5",
	pages = "42--45",
	abstract = "Relation extraction (RE) is a crucial task in natural language processing (NLP) that aims to identify and classify relationships between entities mentioned in text. In the financial domain, relation extraction plays a vital role in extracting valuable information from financial documents, such as news articles, earnings reports, and company filings. This paper describes our solution to relation extraction on one such dataset REFinD. The dataset was released along with shared task as a part of the Fourth Workshop on Knowledge Discovery from Unstructured Data in Financial Services, co-located with SIGIR 2023. In this paper, we employed OpenAI models under the framework of in-context learning (ICL). We utilized two retrieval strategies to find top K relevant in-context learning demonstrations / examples from training data for a given test example. The first retrieval mechanism, we employed, is a learning-free dense retriever and the other system is a learning-based retriever. We were able to achieve 3rd rank overall. Our best F1-score is 0.718."
}

@Book{raschka2024BuildLargeLanguage,
	file = {References/pdf/raschka2024BuildLargeLanguage.pdf},
	title = {Build a large language model (from scratch)},
	author = {Raschka, Sebastian},
	year = {2024},
	publisher = {Simon and Schuster}
}

@article{reales2024CoreConceptIdentification,
	file = {References/pdf/reales2024CoreConceptIdentification.pdf},
	title = {Core {Concept} {Identification} in {Educational} {Resources} via {Knowledge} {Graphs} and {Large} {Language} {Models}},
	volume = {5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208722616&doi=10.1007%2Fs42979-024-03341-y&partnerID=40&md5=758642118b6621a5065b31a83abbb2cd},
	doi = {10.1007/s42979-024-03341-y},
	abstract = {The growing demand for online education raises the question of which learning resources should be included in online programs to ensure students achieve their desired learning outcomes. By automatically identifying the core concepts in educational materials, teachers can select coherent and relevant resources for their courses. This work explores the use of Large Language Models (LLMs) to identify core concepts in educational resources. We propose three different pipelines for building knowledge graphs from lecture transcripts using LLMs and ontologies such as DBpedia. These knowledge graphs are then utilized to determine the central concepts (nodes) within the educational resources. Results show that LLM-constructed knowledge graphs when guided by ontologies, achieve state-of-the-art performance in core concept identification. © 2025 Elsevier B.V., All rights reserved.},
	number = {8},
	journal = {SN Computer Science},
	author = {Reales, Daniel and Manrique, Rubén Francisco and Grévisse, Christian},
	year = {2024},
	note = {Section: 0},
	annote = {Type: Article}
}

@article{rebboud2025BenchmarkingLlmBased,
	file = {References/pdf/rebboud2025BenchmarkingLlmBased.pdf},
	title = {Benchmarking {LLM}-based {Ontology} {Conceptualization}: {A} {Proposal}},
	volume = {3953},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003719390&partnerID=40&md5=3a9798338e35ed4a969743b0278931bb},
	abstract = {This study presents a benchmark proposal designed to enhance knowledge engineering tasks through the use of large language models (LLMs). As LLMs become increasingly pivotal in knowledge extraction and modeling, it is crucial to evaluate and improve their performance. Building on prior work aiming at reverse generating competency questions (CQs) from existing ontologies, we introduce a benchmark focused on specific knowledge modeling tasks including ontology documentation, ontology generation, and query generation. In addition, we propose a baseline evaluation framework that applies various techniques, such as semantic comparison, ontology evaluation criteria, and structural comparison, using both existing ground truth datasets and newly proposed ontologies with corresponding CQs and documentation. This rigorous evaluation aims to provide a deeper understanding of LLM capabilities and contribute to their optimization in knowledge engineering applications. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Rebboud, Youssra and Lisena, Pasquale and Tailhardat, Lionel and Troncy, Raphaël},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge acquisition, Knowledge graph, Large language model, Language model, Knowledge extraction, Conceptual design, Knowledge model, Performance, Ontology's, Knowledge-representation, Model-based OPC, Knowledge organization system (KOS), Engineering tasks, Benchmark proposal, Image representation},
	annote = {Type: Conference paper}
}

@article{rebboud2025CanLlmsGenerate,
	file = {References/pdf/rebboud2025CanLlmsGenerate.pdf},
	title = {Can {LLMs} {Generate} {Competency} {Questions}?},
	volume = {15344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218474145&doi=10.1007%2F978-3-031-78952-6_7&partnerID=40&md5=4f9c4d533bce3706de5a09e47bb22cb3},
	doi = {10.1007/978-3-031-78952-6_7},
	abstract = {Large Language Models have shown high performances in a large number of tasks, being recently applied also to support Knowledge Graphs construction. An important step for data modeling consists in the definition of a set of competency questions, which are often used as a guide for the development of an ontology and as a mean to evaluate the resulting schema. In this work, we investigate the suitability of LLMs for the automatic generation of competency questions given an existing ontology. We compare different large language models under various settings in order to give a comprehensive overview of what LLMs can do to support the knowledge engineer. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Rebboud, Youssra and Tailhardat, Lionel and Lisena, Pasquale and Troncy, Raphaël},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, LLM, Language model, Modeling languages, Data modeling, Performance, Automatic Generation, Graph construction, Ontology's, Support knowledge},
	pages = {71 -- 80},
	annote = {Type: Conference paper}
}

@article{regino2024GeneratingECommerce,
	file = {References/pdf/regino2024GeneratingECommerce.pdf},
	title = {Generating {E}-commerce {Related} {Knowledge} {Graph} from {Text}: {Open} {Challenges} and {Early} {Results} using {LLMs}},
	volume = {3747},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203334838&partnerID=40&md5=ac53dff8d619e6e1d33d20a00efdd161},
	abstract = {E-commerce systems need to use and manage vast amounts of unstructured textual data. This poses significant challenges for knowledge representation, information retrieval, and recommendation tasks. This study investigates the generation of E-commerce-related Knowledge Graphs (KGs) from text. In particular, we explore using Large Language Models (LLMs). Our approach integrates ontology with text-based examples from existing KGs via prompts to create structured RDF triples. We outline a four-step method encompassing text classification, extracting relevant characteristics, generating RDF triples, and assessing the generated triples. Each step leverages LLM instructions to process unstructured text. We discuss the insights, challenges, and potential future directions, highlighting the significance of integrating ontology elements with unstructured text for generating semantically enriched KGs. Through case experimentations, we demonstrate the effectiveness and applicability of our solution in the E-commerce domain. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Regino, Andre Gomes and César Dos Reis, Júlio},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Structured Query Language, Ontology's, Unstructured texts, RDF triples, E-commerce systems, Knowledge graph enhancement, Marketplaces, Text-to-triple},
	pages = {18},
	annote = {Type: Conference paper}
}

@article{reif2024ChatbotBasedOntology,
	file = {References/pdf/reif2024ChatbotBasedOntology.pdf},
	title = {Chatbot-{Based} {Ontology} {Interaction} {Using} {Large} {Language} {Models} and {Domain}-{Specific} {Standards}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207845394&doi=10.1109%2FETFA61755.2024.10711065&partnerID=40&md5=6e55dc21dbf2c13a30448996fcb6cb63},
	doi = {10.1109/ETFA61755.2024.10711065},
	abstract = {The following contribution introduces a concept that employs Large Language Models (LLMs) and a chatbot interface to enhance SPARQL query generation for ontologies, thereby facilitating intuitive access to formalized knowledge. Utilizing natural language inputs, the system converts user inquiries into accurate SPARQL queries that strictly query the factual content of the ontology, effectively preventing misinformation or fabrication by the LLM. To enhance the quality and precision of outcomes, additional textual information from established domain-specific standards is integrated into the ontology for precise descriptions of its concepts and relationships. An experimental study assesses the accuracy of generated SPARQL queries, revealing significant benefits of using LLMs for querying ontologies and highlighting areas for future research.},
	journal = {2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA)},
	author = {Reif, Jonathan and Jeleniewski, Tom and Gill, Milapji Singh and Gehlhoff, Felix and Fay, Alexander},
	month = sep,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Large Language Models, Large language model, Ontology, Language model, Large language models, Semantic Web, Semantics, Industry 4.0, Standards, Cyber-physical systems, Accuracy, Chatbots, Cyber-Physical Systems, Fake news, Fabrication, Natural languages, Manufacturing automation, Structured Query Language, Ontology's, Query languages, Cybe-physical systems, Semantic-Web, Domain specific, Query generation},
	pages = {1--4},
	annote = {ISSN: 1946-0759 {\textbar} RAYYAN-LABELS: SPARQL}
}

@article{rezayi2025ExploringNewFrontiers,
	file = {References/pdf/rezayi2025ExploringNewFrontiers.pdf},
	title = {Exploring {New} {Frontiers} in {Agricultural} {NLP}: {Investigating} the {Potential} of {Large} {Language} {Models} for {Food} {Applications}},
	volume = {11},
	issn = {2332-7790},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201463745&doi=10.1109%2FTBDATA.2024.3442542&partnerID=40&md5=5b2de44b44642ac5f1b62bf16a120c7f},
	doi = {10.1109/TBDATA.2024.3442542},
	abstract = {This paper explores new frontiers in agricultural natural language processing (NLP) by investigating the effectiveness of food-related text corpora for pretraining transformer-based language models. Specifically, we focus on semantic matching, establishing mappings between food descriptions and nutrition data through fine-tuning AgriBERT with the FoodOn ontology. Our work introduces an expanded comparison with state-of-the-art language models such as GPT-4, Mistral-large, Claude 3 Sonnet, and Gemini 1.0 Ultra. This exploratory investigation, rather than a direct comparison, aims to understand how AgriBERT, a domain-specific, fine-tuned, open-source model, complements the broad knowledge and generative abilities of these advanced LLMs in addressing the unique challenges of the agricultural sector. We also experiment with other applications, such as cuisine prediction from ingredients, expanding our research to include various NLP tasks beyond semantic matching. Overall, this paper underscores the potential of integrating domain-specific models like AgriBERT with advanced LLMs to enhance the performance and applicability of agricultural NLP applications.},
	number = {3},
	journal = {IEEE Transactions on Big Data},
	author = {Rezayi, Saed and Liu, Zhengliang and Wu, Zihao and Dhakal, Chandra and Ge, Bao and Dai, Haixing and Mai, Gengchen and Liu, Ninghao and Zhen, Chen and Liu, Tianming and Li, Sheng},
	month = jun,
	year = {2025},
	note = {Section: 0},
	keywords = {ChatGPT, Natural language processing, Language model, Semantics, natural language processing, Modeling languages, language models, Context modeling, Data models, Training, Semantic matching, semantic matching, Language processing, Natural languages, Biological system modeling, food applications, Task analysis, Context models, Food applications},
	pages = {1235--1246},
	annote = {Type: Article}
}

@article{riquelmegarcía2025AnnotationBiologicalSamples,
	file = {References/pdf/riquelmegarcía2025AnnotationBiologicalSamples.pdf},
	title = {Annotation of biological samples data to standard ontologies with support from large language models},
	volume = {27},
	issn = {2001-0370},
	url = {https://www.sciencedirect.com/science/article/pii/S2001037025001837},
	doi = {https://doi.org/10.1016/j.csbj.2025.05.020},
	abstract = {The semantic integration of biological data is hindered by the vast heterogeneity of data sources and their limited semantic formalization. A crucial step in this process is mapping data elements to ontological concepts, which typically involves substantial manual effort. Large Language Models (LLMs) have demonstrated potential in automating complex language-related tasks and may offer a solution to streamline biological data annotation. This study investigates the utility of LLMs—specifically various base and fine-tuned GPT models—for the automatic assignment of ontological identifiers to biological sample labels. We evaluated model performance in annotating labels to four widely used ontologies: the Cell Line Ontology (CLO), Cell Ontology (CL), Uber-anatomy Ontology (UBERON), and BRENDA Tissue Ontology (BTO). Our dataset was compiled from publicly available, high-quality databases containing biologically relevant sequence information, which suffers from inconsistent annotation practices, complicating integrative analyses. Model outputs were compared against annotations generated by text2term, a state-of-the-art annotation tool. The fine-tuned GPT model outperformed both the base models and text2term in annotating cell lines and cell types, particularly for the CL and UBERON ontologies, achieving a precision of 47–64\% and a recall of 88–97\%. In contrast, base models exhibited significantly lower performance. These results suggest that fine-tuned LLMs can accelerate and improve the accuracy of biological data annotation. Nonetheless, our evaluation highlights persistent challenges, including variable precision across ontology categories and the continued need for expert curation to ensure annotation validity.},
	journal = {Computational and Structural Biotechnology Journal},
	author = {Riquelme-García, Andrea and Mulero-Hernández, Juan and Fernández-Breis, Jesualdo Tomás},
	year = {2025},
	note = {Section: 0},
	keywords = {large language model, Large language model, Ontology, Language model, Large language models, Bioinformatics, Biological samples, Data interoperability, Generative AI, ontology, data interoperability, Data annotation, Formal concept analysis, generative artificial intelligence, human, ontology development, medical ontology, Article, female, Ontology's, false positive result, human cell, medical research, data base, anatomical concepts, anatomy ontology, Base models, Biological data, biological product, Cell lines, false negative result, HeLa cell line, Tissue culture, uterine epithelium},
	pages = {2155--2167},
	annote = {Type: Article}
}

@article{rodrigues2023UseChatgptClassifying,
	file = {References/pdf/rodrigues2023UseChatgptClassifying.pdf},
	title = {On the {Use} of {ChatGPT} for {Classifying} {Domain} {Terms} {According} to {Upper} {Ontologies}},
	volume = {14319},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177226095&doi=10.1007%2F978-3-031-47112-4_24&partnerID=40&md5=dca995c6f4355d84ee7c1ba5820fa9bd},
	doi = {10.1007/978-3-031-47112-4_24},
	abstract = {In this paper, we report an experiment to investigate the performance of ChatGPT in the task of classifying domain terms according to the categories of upper-level ontologies. The experiment consisted of (1) starting a conversation in ChatGPT with a contextual prompt listing the categories of an upper-level ontology along with their definitions, (2) submitting a follow-up prompt with a list of terms from a domain along with informal definitions, (3) asking ChatGPT to classify the terms according to the categories of the chosen upper-level ontology and explain its decision, and (4) comparing the answers of ChatGPT with the classification proposed by experts in the chosen ontology. Given the results, we evaluated the success rate of ChatGPT in performing the task and analyzed the cases of misclassification to understand the possible reasons underlying them. Based on that, we made some considerations about the extent to which we can employ ChatGPT as an assistant tool for the task of classifying domain terms into upper-level ontologies. For our experiment, we selected a set of 19 terms from the manufacturing domain that were gathered by the Industrial Ontologies Foundry (IOF) and for which there are informal textual definitions reflecting a community view of them. Also, as a baseline for comparison, we resorted to publicly available classifications of such terms according to DOLCE and BFO upper-level ontologies, which resulted from a thorough ontological analysis of those terms and informal definitions by experts in each of the ontologies. © 2023 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Rodrigues, Fabrício Henrique Henrique and Lopes, Alcides Gonçalves and Dos Santos, Nicolau O. and Garcia, Luan Fonseca and Carbonera, Joel Lúis and Abel, Mara},
	year = {2023},
	note = {Section: 0},
	keywords = {ChatGPT, Large language model, Ontology, LLM, Language model, Manufacturing, BFO, DOLCE, Ontology's, Term classification, Foundries, Industrial ontology foundry},
	pages = {249 -- 258},
	annote = {Type: Conference paper}
}

@Article{ruas2022NilinkerAttentionBased,
	file = {References/pdf/ruas2022NilinkerAttentionBased.pdf},
	author = {Pedro Ruas and Francisco M. Couto},
	title = {{NILINKER:} Attention-based approach to {NIL} Entity
                  Linking},
	journal = {J. Biomed. Informatics},
	year = 2022,
	volume = 132,
	pages = 104137,
	doi = {10.1016/J.JBI.2022.104137},
	url = {https://doi.org/10.1016/j.jbi.2022.104137},
	timestamp = {Mon, 24 Oct 2022 20:51:19 +0200},
	biburl = {https://dblp.org/rec/journals/jbi/RuasC22.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{sadruddin2025Llms4schemadiscoveryHumanIn,
	file = {References/pdf/sadruddin2025Llms4schemadiscoveryHumanIn.pdf},
	title = {{LLMs4SchemaDiscovery}: {A} {Human}-in-the-{Loop} {Workflow} for {Scientific} {Schema} {Mining} with {Large} {Language} {Models}},
	volume = {15719},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007760723&doi=10.1007%2F978-3-031-94578-6_14&partnerID=40&md5=09f8a3feeee6d10d3656ede32cca3b1e},
	doi = {10.1007/978-3-031-94578-6_14},
	abstract = {Extracting structured information from unstructured text is crucial for modeling real-world processes, but traditional schema mining relies on semi-structured data, limiting scalability. This paper introduces schema-miner, a novel tool that combines large language models with human feedback to automate and refine schema extraction. Through an iterative workflow, it organizes properties from text, incorporates expert input, and integrates domain-specific ontologies for semantic depth. Applied to materials science—specifically atomic layer deposition—schema-miner demonstrates that expert-guided LLMs generate semantically rich schemas suitable for diverse real-world applications. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Sadruddin, Sameer and D’Souza, Jennifer and Poupaki, Eleni and Watkins, Alex and Giglou, Hamed Babaei and Rula, Anisa and Karasulu, Bora and Auer, Sören and Mackus, Adrie and Kessels, Erwin},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Language model, Semantics, Human-in-the-loop, Work-flows, Unstructured texts, Human-in-the-loop workflow, Multilayers, Schema discovery, Schema mining, Scientific schema, Structured information},
	pages = {244 -- 261},
	annote = {Type: Conference paper}
}

@article{saeedizade2024NavigatingOntologyDevelopment,
	file = {References/pdf/saeedizade2024NavigatingOntologyDevelopment.pdf},
	title = {Navigating {Ontology} {Development} with {Large} {Language} {Models}},
	volume = {14664},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194261410&doi=10.1007%2F978-3-031-60626-7_8&partnerID=40&md5=baaad02d5b7b04faf346edad72360685},
	doi = {10.1007/978-3-031-60626-7_8},
	abstract = {Ontology engineering is a complex and time-consuming task, even with the help of current modelling environments. Often the result is error-prone unless developed by experienced ontology engineers. However, with the emergence of new tools, such as generative AI, inexperienced modellers might receive assistance. This study investigates the capability of Large Language Models (LLMs) to generate OWL ontologies directly from ontological requirements. Specifically, our research question centres on the potential of LLMs in assisting human modellers, by generating OWL modelling suggestions and alternatives. We experiment with several state-of-the-art models. Our methodology incorporates diverse prompting techniques like Chain of Thoughts (CoT), Graph of Thoughts (GoT), and Decomposed Prompting, along with the Zero-shot method. Results show that currently, GPT-4 is the only model capable of providing suggestions of sufficient quality, and we also note the benefits and drawbacks of the prompting techniques. Overall, we conclude that it seems feasible to use advanced LLMs to generate OWL suggestions, which are at least comparable to the quality of human novice modellers. Our research is a pioneering contribution in this area, being the first to systematically study the ability of LLMs to assist ontology engineers. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Saeedizade, Mohammad Javad and Blomqvist, Eva},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, Ontology development, Computational linguistics, Zero-shot learning, Ontology's, Birds, Error prones, Current modeling, Modeling environments, OWL ontologies, Time-consuming tasks},
	pages = {143 -- 161},
	annote = {Type: Conference paper}
}

@article{saetia2024FinancialProductOntology,
	file = {References/pdf/saetia2024FinancialProductOntology.pdf},
	title = {Financial {Product} {Ontology} {Population} with {Large} {Language} {Models}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204898551&doi=10.18653%2Fv1%2F2024.textgraphs-1.4&partnerID=40&md5=bfa3b333c19f905f0559a241ed50be00},
	doi = {10.18653/v1/2024.textgraphs-1.4},
	abstract = {Ontology population, which aims to extract structured data to enrich domain-specific ontologies from unstructured text, typically faces challenges in terms of data scarcity and linguistic complexity, particularly in specialized fields such as retail banking. In this study, we investigate the application of large language models (LLMs) to populate domain-specific ontologies of retail banking products from Thai corporate documents. We compare traditional span-based approaches to LLMs-based generative methods, with different prompting techniques. Our findings reveal that while span-based methods struggle with data scarcity and the complex linguistic structure, LLMs-based generative approaches substantially outperform, achieving a 61.05\% F1 score, with the most improvement coming from providing examples in the prompts. This improvement highlights the potential of LLMs for ontology population tasks, offering a scalable and efficient solution for structured information extraction, especially in low-resource language settings. © 2024 Elsevier B.V., All rights reserved.},
	author = {Saetia, Chanatip and Phruetthiset, Jiratha and Chalothorn, Tawunrat and Lertsutthiwong, Monchai and Taerungruang, Supawat and Buabthong, Pakpoom},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology, Ontology Population, Language model, Computational linguistics, Structured data, Data scarcity, Model-based OPC, Unstructured texts, Domain-specific ontologies, Financial products, Product Ontologies, Retail banking},
	pages = {53 -- 60},
	annote = {Type: Conference paper}
}

@article{sahbi2024AutomaticOntologyPopulation,
	file = {References/pdf/sahbi2024AutomaticOntologyPopulation.pdf},
	title = {Automatic {Ontology} {Population} from {Textual} {Advertisements}: {LLM} vs. {Semantic} {Approach}},
	volume = {246},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211219376&doi=10.1016%2Fj.procs.2024.09.364&partnerID=40&md5=a07ef1696c731a6c2952f13728042482},
	doi = {10.1016/j.procs.2024.09.364},
	abstract = {Automatic ontology population involves identifying, extracting and integrating information from various sources to instantiate the classes and properties of an ontology, thereby building a domain Knowledge Graph (KG). In this paper, we compare two text-based ontology population techniques: KOnPoTe, a semantic approach based on textual and domain knowledge analysis, and a generative AI approach utilizing Claude, a Large Language Model (LLM). We present experiments conducted on two French sales advertisement domains: real estate and boats, and discuss the strengths and limitations of both approaches. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Procedia Computer Science},
	author = {Sahbi, Aya and Alec, Céline and Beust, Pierre},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graph, Large language model, Ontology, Ontology Population, Language model, Semantics, Modeling languages, Semantic approach, Domain knowledge, Domain Knowledge, Automatic ontology, Property, Extracting information, Generative adversarial networks, Marketing, Integrating information, Textual advertisement},
	pages = {3083 -- 3092},
	annote = {Issue: C Type: Conference paper}
}

@article{sahbi2025SemanticVs,
	file = {References/pdf/sahbi2025SemanticVs.pdf},
	title = {Semantic vs. {LLM}-based approach: {A} case study of {KOnPoTe} vs. {Claude} for ontology population from {French} advertisements},
	volume = {156},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211195979&doi=10.1016%2Fj.datak.2024.102392&partnerID=40&md5=7adba98e00024b722539b1e6c7c8ebdc},
	doi = {10.1016/j.datak.2024.102392},
	abstract = {Automatic ontology population is the process of identifying, extracting, and integrating relevant information from diverse sources to instantiate the classes and properties specified in an ontology, thereby creating a Knowledge Graph (KG) for a particular domain. In this study, we evaluate two approaches for ontology population from text: KOnPoTe, a semantic technique that employs textual and domain knowledge analysis, and a generative AI method leveraging Claude, a Large Language Model (LLM). We conduct comparative experiments on three French advertisement domains: real estate, boats, and restaurants to assess the performance of these techniques. Our analysis highlights the respective strengths and limitations of the semantic approach and the LLM-based one in the context of the ontology population process. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Data and Knowledge Engineering},
	author = {Sahbi, Aya and Alec, Céline and Beust, Pierre},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Ontology Population, Language model, Semantics, Domain Knowledge, Ontology's, Model based approach, Automatic ontology, Property, Case-studies, Textual description},
	annote = {Type: Article}
}

@Article{sahoo2024SystematicSurveyPrompt,
	file = {References/pdf/sahoo2024SystematicSurveyPrompt.pdf},
	author = {Pranab Sahoo and Ayush Kumar Singh and Sriparna Saha
                  and Vinija Jain and Samrat Mondal and Aman Chadha},
	title = {A Systematic Survey of Prompt Engineering in Large
                  Language Models: Techniques and Applications},
	journal = {CoRR},
	year = 2024,
	volume = {abs/2402.07927},
	doi = {10.48550/ARXIV.2402.07927},
	eprint = {2402.07927},
	eprinttype = {arXiv},
	url = {https://doi.org/10.48550/arXiv.2402.07927},
	timestamp = {Mon, 19 Feb 2024 15:25:43 +0100},
	biburl = {https://dblp.org/rec/journals/corr/abs-2402-07927.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{sainz2021Ask2transformersZeroShot,
	file = {References/pdf/sainz2021Ask2transformersZeroShot.pdf},
	title = {{Ask2Transformers}: {Zero}-shot domain labelling with pre-trained language models},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119149541&partnerID=40&md5=02af5dddcf0ffae9926edf8de4a38bdb},
	abstract = {In this paper we present a system that exploits different pre-trained Language Models for assigning domain labels to WordNet synsets without any kind of supervision. Furthermore, the system is not restricted to use a particular set of domain labels. We exploit the knowledge encoded within different off-the-shelf pre-trained Language Models and task formulations to infer the domain label of a particular WordNet definition. The proposed zero-shot system achieves a new state-of-the-art on the English dataset used in the evaluation. © 2021 Elsevier B.V., All rights reserved.},
	author = {Sainz, Oscar and Rigau, German},
	year = {2021},
	note = {Section: 0},
	keywords = {Ontology, Language model, Wordnet, Computational linguistics, Labelings, State of the art, Synsets},
	pages = {44 -- 52},
	annote = {Type: Conference paper}
}

@article{sampels2024OntomatchResultsOaei,
	file = {References/pdf/sampels2024OntomatchResultsOaei.pdf},
	title = {{OntoMatch} {Results} for {OAEI} 2024},
	volume = {3897},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216387360&partnerID=40&md5=f3574fe259d893ec448d7aeae809d538},
	abstract = {This paper presents the results of OntoMatch in the OAEI 2024 competition. OntoMatch is an ontology matching system that combines graph search algorithms with zero-shot prompting of Large Language Models (LLMs) to produce class correspondences. The system follows an iterative approach involving neighbourhood candidate selection, context extraction using graph search techniques, verbalising of context and zero-shot LLM prompting with templates. Each iteration concludes with a cardinality filter to refine the alignments. OntoMatch was evaluated on the OAEI conference benchmark dataset. The results demonstrate the impact of incorporating graph-based contextual information alongside carefully crafted prompt templates, achieving competitive scores and highlighting the effectiveness of LLM-driven approaches for ontology alignment. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Sampels, Julian},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Ontology matching, Modeling languages, Zero-shot learning, Graph search, Matching system, Graph-search algorithms, Iterative approach, Neighbourhood, Prompt generation},
	pages = {124 -- 131},
	annote = {Type: Conference paper}
}

@Online{sanh2019DistilbertDistilledVersion,
	author = {Victor Sanh AND Lysandre Debut AND Julien Chaumond
                  AND Thomas Wolf},
	title = {{DistilBERT, a distilled version of BERT: smaller,
                  faster, cheaper and lighter}},
	year = 2019,
	eprint = {1910.01108v4},
	primaryclass = {cs.CL},
	archiveprefix = {arXiv}
}

@article{schaeffer2024PertinenceLlmsOntology,
	file = {References/pdf/schaeffer2024PertinenceLlmsOntology.pdf},
	title = {On the {Pertinence} of {LLMs} for {Ontology} {Learning}},
	volume = {3874},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214247692&partnerID=40&md5=a817900503c26a5320cf55725e593f4d},
	abstract = {Ontology learning from text is traditionally approached as sub-tasks tackled with linguistic, statistical or logic-based methods. Large language models and their generation capabilities have recently caught much interest. We investigate the pertinence of such generative models for ontology learning. We evaluate the created ontologies on two different use cases by aligning with a reference ontology and compare components for each sub-task using the OLAF ontology learning framework. In addition to demonstrating the relevance of large language models for ontology learning, we discuss component combinations, LLM size, and environmental impact in creating efficient pipelines while limiting resource consumption. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Schaeffer, Marion and Sesboüé, Matthias and Charbonnier, Léa and Delestre, Nicolas and Kotowicz, Jean Philippe and Zanni-Merk, Cécilia},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, LLM, Language model, Ontology learning, Knowledge graph construction, Federated learning, Generative model, Adversarial machine learning, Graph construction, Ontology's, Contrastive Learning, Subtask, Learning from texts},
	pages = {1 -- 18},
	annote = {Type: Conference paper}
}

@article{schneider2023NlfoaNaturalLanguage,
	file = {References/pdf/schneider2023NlfoaNaturalLanguage.pdf},
	series = {K-{CAP} '23},
	title = {{NLFOA}: {Natural} {Language} {Focused} {Ontology} {Alignment}},
	url = {https://doi.org/10.1145/3587259.3627560},
	doi = {10.1145/3587259.3627560},
	abstract = {For Ontology Alignment (OA), the task is to align semantically equivalent concepts and relations from different ontologies. This task plays a crucial role in many downstream tasks and applications in academia and industry. Since manually aligning ontologies is inefficient and costly, numerous approaches exist to do this automatically. However, most approaches are tailored to specific domains, are rule-based systems or based on feature engineering, and require external knowledge. The most recent advances in the field of OA rely on the widely proven effectiveness of pre-trained language models to represent the human-generated language that describes the entities in an ontology. However, these approaches additionally require sophisticated algorithms or Graph Neural Networks to exploit an ontology’s graphical structure to achieve state-of-the-art performance. In this work, we present NLFOA, or Natural Language Focused Ontology Alignment, which purely focuses on the natural language contained in ontologies to process the ontology’s semantics as well as graphical structure. An evaluation of our approach on common OA datasets shows superior results when finetuning with only a small number of training samples. Additionally, it demonstrates strong results in a zero-shot setting which could be employed in an active learning setup to reduce human labor when manually aligning ontologies significantly.},
	journal = {Proceedings of the 12th Knowledge Capture Conference 2023},
	author = {Schneider, Florian and Dash, Sarthak and Bagchi, Sugato and Mihindukulasooriya, Nandana and Gliozzo, Alfio Massimiliano},
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Knowledge graph, Ontology, Language model, Semantics, Ontology alignment, Graph neural networks, Zero-shot learning, Ontology Alignment Sentence Transformers Zero-Shot, Natural languages, Ontology's, External knowledge, Down-stream, Feature engineerings, Graphical structures, Ontology alignment sentence transformer zero-shot, Rules based systems},
	pages = {114--121},
	annote = {event-place: Pensacola, FL, USA}
}

@Article{schulhoff2024PromptReportSystematic,
	file = {References/pdf/schulhoff2024PromptReportSystematic.pdf},
	title = {The prompt report: a systematic survey of prompt engineering techniques},
	author = {Schulhoff, Sander and Ilie, Michael and Balepur, Nishant and Kahadze, Konstantine and Liu, Amanda and Si, Chenglei and Li, Yinheng and Gupta, Aayush and Han, HyoJung and Schulhoff, Sevien and others},
	journal = {arXiv preprint arXiv:2406.06608},
	year = {2024}
}

@InProceedings{sennrich2016NeuralMachineTranslation,
	file = {References/pdf/sennrich2016NeuralMachineTranslation.pdf},
	author = {Sennrich, Rico and Haddow, Barry and Birch,
                  Alexandra},
	title = {Neural Machine Translation of Rare Words with
                  Subword Units},
	year = 2016,
	booktitle = {Proceedings of the 54th Annual Meeting of the
                  Association for Computational Linguistics (Volume 1:
                  Long Papers)},
	publisher = {Association for Computational Linguistics},
	doi = {10.18653/v1/p16-1162},
	url = {http://dx.doi.org/10.18653/v1/p16-1162}
}

@article{shan2025LargeLanguageModels,
	file = {References/pdf/shan2025LargeLanguageModels.pdf},
	title = {Large language {Models}-empowered automatic knowledge graph development based on multi-modal data for building health resilience},
	volume = {68},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010563058&doi=10.1016%2Fj.aei.2025.103655&partnerID=40&md5=329bb060f38e387aae8af0f77b054252},
	doi = {10.1016/j.aei.2025.103655},
	abstract = {Improving the health resilience of building (BHR) helps keep stable health status of both the building and its occupants under disasters. As BHR is an emerging concept, there is no structured knowledge graph to understand the whole process of BHR under disasters. Therefore, this study aims to build a structured BHR knowledge graph based on multi-modal data, providing sufficient structured knowledge for BHR enhancement. An automated knowledge graph construction approach is proposed to empower the ontology design and triple extraction by large language models (LLMs), and validation processes based on In-context Learning (ICL) prompts. A case study is conducted to construct the knowledge graph of BHR under rainstorms in Hong Kong. The performance of the proposed LLMs-empowered knowledge extraction is also validated based on natural language processing metrics and LLMs-based Evaluation (LLMs-Eval). BHR knowledge graph indicates the potential relations between disasters, factors, response actions, and the health status of the building and occupants, and provides insight to guide the BHR enhancement. The superiority of the proposed LLMs-empowered automated knowledge graph construction approach is proven, implying LLMs have great potential in knowledge graph construction, not only for BHR but also for other concepts that require structured knowledge for further explorations and analyses. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Advanced Engineering Informatics},
	author = {Shan, Tianlong and Zhang, Fan and Chan, Albert P.C. and Zhu, Shiyao and Li, Kaijian},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Building health resilience, Multi-modal data, Rainstorm, Graph theory, Extraction, Graph construction, Graphic methods, Construction approaches, Health status, Modal analysis, Natural language processing systems, Structured knowledge},
	annote = {Type: Article}
}

@Article{shao2024DeepseekmathPushingLimits,
	file = {References/pdf/shao2024DeepseekmathPushingLimits.pdf},
	author = {Zhihong Shao and Peiyi Wang and Qihao Zhu and Runxin
                  Xu and Junxiao Song and Mingchuan Zhang and Y. K. Li
                  and Y. Wu and Daya Guo},
	title = {DeepSeekMath: Pushing the Limits of Mathematical
                  Reasoning in Open Language Models},
	journal = {CoRR},
	year = 2024,
	volume = {abs/2402.03300},
	doi = {10.48550/ARXIV.2402.03300},
	eprint = {2402.03300},
	eprinttype = {arXiv},
	url = {https://doi.org/10.48550/arXiv.2402.03300},
	timestamp = {Mon, 12 Feb 2024 13:36:38 +0100},
	biburl = {https://dblp.org/rec/journals/corr/abs-2402-03300.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@misc{shaya2012AstronomyOntology,
	title = {Astronomy {{Ontology}}},
	author = {Shaya, Edward},
	date = {2012},
	year = 2012,
	url = {https://www.astro.umd.edu/~eshaya/astro-onto/ontologies/astronomy.html},
	urldate = {2024-11-20},
	timestamp = {2024-11-20T14:00:28Z}
}

@article{shi2025EvidenceTriangulatorUsing,
	file = {References/pdf/shi2025EvidenceTriangulatorUsing.pdf},
	title = {Evidence triangulator: using large language models to extract and synthesize causal evidence across study designs},
	volume = {16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012984973&doi=10.1038%2Fs41467-025-62783-x&partnerID=40&md5=6c7c0d7e6de22060d6fb918902827e12},
	doi = {10.1038/s41467-025-62783-x},
	abstract = {Health strategies increasingly emphasize both behavioural and biomedical interventions, yet the complex and often contradictory guidance on diet, behavior, and health outcomes complicates evidence-based decision-making. Evidence triangulation across diverse study designs is essential for balancing biases and establishing causality, but scalable, automated methods for achieving this are lacking. In this study, we assess the performance of large language models in extracting both ontological and methodological information from scientific literature to automate evidence triangulation. A two-step extraction approach—focusing on exposure-outcome concepts first, followed by relation extraction—outperforms a one-step method, particularly in identifying the direction of effect (F1 = 0.86) and statistical significance (F1 = 0.96). Using salt intake and blood pressure as a case study, we calculate the Convergency of Evidence and Level of Convergency, finding a strong excitatory effect of salt on blood pressure (942 studies), and weak excitatory effect on cardiovascular diseases and deaths (124 studies). This approach complements traditional meta-analyses by integrating evidence across study designs, and enabling rapid, dynamic assessment of scientific controversies. © 2025 Elsevier B.V., All rights reserved.},
	number = {1},
	journal = {Nature Communications},
	author = {Shi, Xuanyu and Zhao, Wenjing and Chen, Ting and Yang, Chao and Du, Jian},
	year = {2025},
	note = {Section: 0},
	keywords = {large language model, Large Language Models, data extraction, ontology, information retrieval, Causality, knowledge graph, adverse event, methodology, etiology, cardiovascular disease, accuracy, human, gold standard, nomenclature, language, causality, Humans, Article, predictive model, accuracy assessment, analytical error, blood, blood pressure, Blood Pressure, Cardiovascular Diseases, cardiovascular mortality, case study, Cochrane Library, detection method, Dietary, dietary intake, drug effect, evidence synthesis, internal validity, ischemic heart disease, Medical Subject Headings, Medline, Mendelian randomization analysis, observational study, outcome assessment, probability, randomized controlled trial (topic), Research Design, salt intake, scientific literature, sodium chloride, Sodium Chloride, study design, triangulation},
	annote = {Type: Article}
}

@article{shimizu2025AcceleratingKnowledgeGraph,
	file = {References/pdf/shimizu2025AcceleratingKnowledgeGraph.pdf},
	title = {Accelerating knowledge graph and ontology engineering with large language models},
	volume = {85},
	issn = {1570-8268},
	url = {https://www.sciencedirect.com/science/article/pii/S1570826825000022},
	doi = {https://doi.org/10.1016/j.websem.2025.100862},
	abstract = {Large Language Models bear the promise of significant acceleration of key Knowledge Graph and Ontology Engineering tasks, including ontology modeling, extension, modification, population, alignment, as well as entity disambiguation. We lay out LLM-based Knowledge Graph and Ontology Engineering as a new and coming area of research, and argue that modular approaches to ontologies will be of central importance.},
	journal = {Journal of Web Semantics},
	author = {Shimizu, Cogan and Hitzler, Pascal},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Ontology engineering, Knowledge graph, Large language model, Ontology modeling, Ontology Population, Ontology model, Language model, Large language models, Ontology population, Entity disambiguation, Knowledge graph engineering, Modular ontologies, Ontology alignment},
	pages = {100862},
	annote = {Type: Article}
}

@article{shlyk2024RealRetrievalAugmented,
	file = {References/pdf/shlyk2024RealRetrievalAugmented.pdf},
	title = {{REAL}: {A} {Retrieval}-{Augmented} {Entity} {Linking} {Approach} for {Biomedical} {Concept} {Recognition}},
	url = {https://aclanthology.org/2024.bionlp-1.29/},
	doi = {10.18653/v1/2024.bionlp-1.29},
	abstract = {Large Language Models (LLMs) offer an appealing alternative to training dedicated models for many Natural Language Processing (NLP) tasks. However, outdated knowledge and hallucination issues can be major obstacles in their application in knowledge-intensive biomedical scenarios. In this study, we consider the task of biomedical concept recognition (CR) from unstructured scientific literature and explore the use of Retrieval Augmented Generation (RAG) to improve accuracy and reliability of the LLM-based biomedical CR. Our approach, named REAL (Retrieval Augmented Entity Linking), combines the generative capabilities of LLMs with curated knowledge bases to automatically annotate natural language texts with concepts from bio-ontologies. By applying REAL to benchmark corpora on phenotype concept recognition, we show its effectiveness in improving LLM-based CR performance. This research highlights the potential of combining LLMs with external knowledge sources to advance biomedical text processing.},
	journal = {Proceedings of the 23rd Workshop on Biomedical Natural Language Processing},
	author = {Shlyk, Darya and Groza, Tudor and Mesiti, Marco and Montanelli, Stefano and Cavalleri, Emanuele},
	editor = {Demner-Fushman, Dina and Ananiadou, Sophia and Miwa, Makoto and Roberts, Kirk and Tsujii, Junichi},
	month = aug,
	year = {2024},
	note = {Place: Bangkok, Thailand
Publisher: Association for Computational Linguistics
Section: 0},
	keywords = {Language model, Concept recognition, Benchmarking, Performance, Computational linguistics, Language processing, Natural languages, Natural language processing systems, Model-based OPC, External knowledge, Natural languages texts, Scientific literature, Bio-ontologies},
	pages = {380--389},
	annote = {Type: Conference paper}
}

@article{silva2024AiAssistedDomain,
	file = {References/pdf/silva2024AiAssistedDomain.pdf},
	series = {{MODELS} {Companion} '24},
	title = {{AI} {Assisted} {Domain} {Modeling} {Explainability} and {Traceability}},
	url = {https://doi.org/10.1145/3652620.3688197},
	doi = {10.1145/3652620.3688197},
	abstract = {Domain Models are abstract representations of selected elements in a domain that is created in a collaborative process between domain and modeler experts. The participants share domain knowledge to conceptualize and reason about the elements that will create the domain models. Through this exchange, a comprehensive and accurate representation of the domain is achieved, ensuring that the model captures the relevant aspects and relationships in the domain. Research in Artificial Intelligence (AI) has explored various methods to assist in the creation of domain models from text using Natural Language Processing (NLP) and Machine Learning (ML). Recent advancements with Large Language Models (LLMs) have shown that it is possible to create domain models using prompting techniques; however, the generated domain models contain errors and remain constrained by the performance of the LLM used.Despite the impressive capabilities of LLMs to create domain models, it is evident that it does not address the needs of domain and modelers experts that participate in the creation of domain models. Every AI technique has its advantages and limitations that must be integrated with human feedback in a collaboration process. Therefore, we propose an approach that incorporates human-AI collaboration supported by AI assistants that follows a dialogue approach to understand the users needs and purpose to suggest relevant models. Our proposal combines symbolic and subsymbolic AI techniques with explainability and traceability of the decisions that assist to create domain models that are relevant for the users.},
	journal = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
	author = {Silva Mercado, Jonathan},
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {large language models, uncertainty, explainability, domain modeling, traceability},
	pages = {130--135},
	annote = {event-place: Linz, Austria}
}

@article{silva2024ComplexMultiOntology,
	file = {References/pdf/silva2024ComplexMultiOntology.pdf},
	title = {Complex {Multi}-{Ontology} {Alignment} {Through} {Geometric} {Operations} on {Language} {Embeddings}},
	volume = {392},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213368903&doi=10.3233%2FFAIA240632&partnerID=40&md5=2a4ee19f34446fb87dbc163e17bc4910},
	doi = {10.3233/FAIA240632},
	abstract = {With knowledge graphs increasing in popularity, aligning and integrating them is paramount to ensure their usefulness and reusability. A key step in this process is ontology matching, whereby the semantic models of KGs are aligned into a single cohesive semantic backbone. While finding simple pairwise equivalences between entities in two ontologies is well addressed by state-of-the-art algorithms, finding more complex mappings that can include multiple entities from different ontologies is far from solved, despite their importance in ensuring a deep and meaningful integration of KGs. We propose a novel complex ontology matching approach that explores geometric operations over the shared semantic space afforded by large language models, enabling the discovery of complex mappings that are missed by purely lexical approaches. We evaluate our approach on several biomedical ontologies using partial reference alignments and manual expert validation. Our approach improves on the performance of a purely lexical approach while also increasing the coverage of complex multi-ontology alignments by 20 to 80\%, which translates to a 97\% coverage of the source ontologies. Moreover, the manual evaluation of the mappings produced by LLM shows that it achieves a high level of precision. This work demonstrates that the use of LLMs can improve on the performance of traditional lexical strategies. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Frontiers in Artificial Intelligence and Applications},
	author = {Silva, Marta Contreiras and Faria, Daniel and Pesquita, Cátia},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Semantics, Ontology matching, Ontology alignment, Semantic modelling, Embeddings, Mapping, Performance, Graph embeddings, Reusability, Latent semantic analysis, Ontology's, Complex mapping, Geometric operations, Multi-ontologies},
	pages = {1333 -- 1340},
	annote = {Type: Conference paper}
}

@Article{soares2025ExploringLargeLanguage,
	file = {References/pdf/soares2025ExploringLargeLanguage.pdf},
	author = {Filipi Miranda Soares and Antonio Mauro Saraiva and
                  Lu{\'{\i}}s Ferreira Pires and Luiz Olavo Bonino da
                  Silva Santos and Dilvan de Abreu Moreira and
                  Fernando Elias Corr{\^{e}}a and Kelly Rosa Braghetto
                  and Debora Pignatari Drucker and Alexandre
                  Cl{\'{a}}udio Botazzo Delbem},
	title = {Exploring a Large Language Model for Transforming
                  Taxonomic Data into {OWL:} Lessons Learned and
                  Implications for Ontology Development},
	journal = {Data Intell.},
	year = 2025,
	volume = 7,
	number = 2,
	pages = {265-302},
	doi = {10.3724/2096-7004.DI.2025.0020},
	url = {https://doi.org/10.3724/2096-7004.di.2025.0020},
	timestamp = {Tue, 05 Aug 2025 22:46:56 +0200},
	biburl = {https://dblp.org/rec/journals/dint/SoaresSPSMCBDD25.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{soares2025ExploringLargeLanguageb,
	file = {References/pdf/soares2025ExploringLargeLanguage.crdownload; References/pdf/soares2025ExploringLargeLanguage.pdf},
	title = {Exploring a {Large} {Language} {Model} for {Transforming} {Taxonomic} {Data} into {OWL}: {Lessons} {Learned} and {Implications} for {Ontology} {Development}},
	volume = {7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008033640&doi=10.3724%2F2096-7004.di.2025.0020&partnerID=40&md5=6058e3e1f68e29e82ea9f1764e6f68fb},
	doi = {10.3724/2096-7004.di.2025.0020},
	abstract = {Managing scientific names in ontologies that represent species taxonomies is challenging due to the ever-evolving nature of these taxonomies. Manually maintaining these names becomes increasingly difficult when dealing with thousands of scientific names. To address this issue, this paper investigates the use of ChatGPT-4 to automate the development of the Organism module in the Agricultural Product Types Ontology (APTO) for species classification. Our methodology involved leveraging ChatGPT-4 to extract data from the GBIF Backbone API and generate OWL files for further integration in APTO. Two alternative approaches were explored: (1) issuing a series of prompts for ChatGPT-4 to execute tasks via the BrowserOP plugin and (2) directing ChatGPT-4 to design a Python algorithm to perform analogous tasks. Both approaches rely on a prompting method where we provide instructions, context, input data, and an output indicator. The first approach showed scalability limitations, while the second approach used the Python algorithm to overcome these challenges, but it struggled with typographical errors in data handling. This study highlights the potential of Large language models like ChatGPT-4 to streamline the management of species names in ontologies. Despite certain limitations, these tools offer promising advancements in automating taxonomy-related tasks and improving the efficiency of ontology development. © 2025 Elsevier B.V., All rights reserved.},
	number = {2},
	journal = {Data Intelligence},
	author = {Soares, Filipi Miranda and Saraiva, Antônio Mauro and Ferreira Pires, L. Ferreira and da Silva Santos, Luiz Olavo Bonino and Moreira, Dilvan De Abreu and Correa, Fernando Elias and Braghetto, Kelly Rosa and Drucker, Debora P. and Delbem, Alexandre Claudio Botazzo},
	year = {2025},
	note = {Section: 0},
	keywords = {ChatGPT, Knowledge graphs, Knowledge graph, Ontology, Language model, Ontology development, Metadata, Taxonomies, Python, Agriculture, Ontology's, Birds, Data assimilation, Data handling, High level languages, Plug-ins, Product types, Species classification, Typographical errors},
	pages = {265 -- 302},
	annote = {Type: Article}
}

@article{sorokoletova2024TowardsScalableAi,
	file = {References/pdf/sorokoletova2024TowardsScalableAi.pdf},
	title = {Towards a scalable {AI}-driven framework for data-independent {Cyber} {Threat} {Intelligence} {Information} {Extraction}},
	doi = {10.1109/FLLM63129.2024.10852465},
	abstract = {Cyber Threat Intelligence (CTI) is critical for mitigating threats to organizations, governments, and institutions, yet the necessary data are often dispersed across diverse formats. AI-driven solutions for CTI Information Extraction (IE) typically depend on high-quality, annotated data, which are not always available. This paper introduces 0-CTI, a scalable AI-based framework designed for efficient CTI Information Extraction. Leveraging advanced Natural Language Processing (NLP) techniques, particularly Transformer-based architectures, the proposed system processes complete text sequences of CTI reports to extract a cyber ontology of named entities and their relationships.Our contribution is the development of 0-CTI, the first modular framework for CTI Information Extraction that supports both supervised and zero-shot learning. Unlike existing state-of-the-art models that rely heavily on annotated datasets, our system enables fully dataless operation through zero-shot methods for both Entity and Relation Extraction, making it adaptable to various data availability scenarios. Additionally, our supervised Entity Extractor surpasses current state-of-the-art performance in cyber Entity Extraction, highlighting the dual strength of the framework in both low-resource and data-rich environments.By aligning the system’s outputs with the Structured Threat Information Expression (STIX) format, a standard for information exchange in the cybersecurity domain, 0-CTI standardizes extracted knowledge, enhancing communication and collaboration in cybersecurity operations.},
	journal = {2024 2nd International Conference on Foundation and Large Language Models (FLLM)},
	author = {Sorokoletova, Olga and Antonioni, Emanuele and Colò, Giordano},
	month = nov,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Natural language processing, Large language models, Information retrieval, Natural Language Processing, Transformers, Data mining, Cyber threat intelligence, Named Entity Recognition, Cyber Threat Intelligence, Relation Extraction, Computer security, Standards organizations, Zero shot learning, Structured Threat Information Expression},
	pages = {398--406}
}

@article{soularidis2024LlmAssistedGeneration,
	file = {References/pdf/soularidis2024LlmAssistedGeneration.pdf},
	title = {{LLM}-{Assisted} {Generation} of {SWRL} {Rules} from {Natural} {Language}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008498105&doi=10.1109%2FAIxDKE63520.2024.00008&partnerID=40&md5=5e63e58a9654eba4991ac8cb40693cc7},
	doi = {10.1109/AIxDKE63520.2024.00008},
	abstract = {Recently, Large Language Models (LLMs) have attracted great attention due to their remarkable performance in human-like text generation and reasoning skills (although their memory and hallucination problems still remain key issues to tackle more efficiently). LLMs have been applied to various application domains, including Knowledge Graph (KG) generation, question and answering over KGs and text-to-SPARQL translation. In this work, we investigate the capabilities of LLMs in text-to-SWRL translation, i.e., translation of Natural Language (NL) rules into Semantic Web Rule Language (SWRL) rules, put in the context of an industrial Ontology Engineering (OE) environment called GLUON, presenting our first experimental results. The aim of this work is to identify the level of automation that is adequate for the LLM to generate well-formed SWRL rules, towards the development of an LLM-based framework, as a plugin to the GLUON OE environment. In this direction we leverage and combine the reasoning capabilities of GPT-4o model, the Retrieval-Augmented Generation (RAG) technology, and prompt engineering. We employ quantitative and qualitative metrics to evaluate the generated SWRL rules, focusing on the correct syntax and the level of human intervention. © 2025 Elsevier B.V., All rights reserved.},
	author = {Soularidis, Andreas and Kotis, Konstantinos I. and Lamolle, Myriam and Mejdoul, Zakaria and Lortal, Gaëlle and Vouros, George A.},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, Knowledge management, Retrieval-augmented generation, Semantic web rule language, Performance, Computational linguistics, Natural languages, Natural language processing systems, Translation (languages), Rules languages, Semantic Web rules, Engineering environment},
	pages = {7 -- 12},
	annote = {Type: Conference paper}
}

@article{sousa2024TowardsGeneratingComplex,
	file = {References/pdf/sousa2024TowardsGeneratingComplex.pdf},
	title = {Towards {Generating} {Complex} {Alignments} with {Large} {Language} {Models} via {Prompt} {Engineering}},
	volume = {3897},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216423330&partnerID=40&md5=0a2afeab7c303ab8425938365e9b4ee6},
	abstract = {Still few ontology matching approaches focus on generating alignments by a Large Language Model (LLM), especially in the complex matching task. This paper proposes an approach that leverages the capabilities of LLMs to perform complex ontology matching. The method integrates subsets of both source and target ontologies into the prompt and, as a response, the LLM generates alignments in the structured EDOAL format, rather than natural language descriptions. This reduction technique, based on the automatic generation of SPARQL queries, tackles the challenge of large prompt sizes, reduces the search space, and enables efficient processing on consumer-grade hardware. This approach is evaluated on the Conference and Geolink datasets from the OAEI complex track, demonstrating improved scalability and the ability to produce well-formed EDOAL. Key contributions include the development of a SPARQL-based prompt engineering strategy and the application of few-shot learning techniques to complex alignment generation. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Sousa, Guilherme and Lima, Rinaldo Jose De and Trojahn, Cassia},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Ontology matching, SPARQL, Modeling languages, Complex matching, Natural languages, Ontology's, Natural language processing systems, Matchings, Language description, Reduction techniques},
	pages = {43 -- 56},
	annote = {Type: Conference paper}
}

@article{stork2024EnablingSocialDemography,
	file = {References/pdf/stork2024EnablingSocialDemography.pdf},
	title = {Enabling {Social} {Demography} {Research} {Using} {Semantic} {Technologies}},
	volume = {14665},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195271433&doi=10.1007%2F978-3-031-60635-9_12&partnerID=40&md5=b632337dffe85b9fc216b98f19dc9198},
	doi = {10.1007/978-3-031-60635-9_12},
	abstract = {A shift in scientific publishing from paper-based to knowledge-based practices promotes reproducibility, machine actionability and knowledge discovery. This is important for disciplines like social demography, where study indicators are often social constructs such as race or education, hypothesis tests are challenging to compare due to their limited temporal and spatial coverage, and research output is presented in natural language, which can be ambiguous and imprecise. In this work, we present the MIRA resource, to aid researchers in their research workflow, and publish FAIR findings. MIRA consists of: (1) an ontology for social demography research, (2) a method for automated ontology population by prompting Large Language Models, and (3) a knowledge graph populated in terms of the ontology by annotating a set of research papers on health inequality. The resource allows researchers to formally represent their social demography research hypotheses, discovering research biases and novel research questions. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Stork, Lise and Zijdeman, Richard Lindert and Tiddi, Ilaria and Ten Teije, Annette},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Information extraction, Knowledge graph, Ontology, Semantic technologies, Semantic Web, Semantics, Demography, Ontology's, Scientific knowledge, Scientific knowledge graph, Knowledge based, Health inequality, Hypothesis representation, Population statistics, Social demography},
	pages = {199 -- 216},
	annote = {Type: Conference paper}
}

@article{strader2024IndoorOutdoor3d,
	file = {References/pdf/strader2024IndoorOutdoor3d.pdf},
	title = {Indoor and {Outdoor} {3D} {Scene} {Graph} {Generation} {Via} {Language}-{Enabled} {Spatial} {Ontologies}},
	volume = {9},
	issn = {2377-3766},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189615964&doi=10.1109%2FLRA.2024.3384084&partnerID=40&md5=86b59d43a6f2399478a764bbb05e2117},
	doi = {10.1109/LRA.2024.3384084},
	abstract = {This letter proposes an approach to build 3D scene graphs in arbitrary indoor and outdoor environments. Such extension is challenging; the hierarchy of concepts that describe an outdoor environment is more complex than for indoors, and manually defining such hierarchy is time-consuming and does not scale. Furthermore, the lack of training data prevents the straightforward application of learning-based tools used in indoor settings. To address these challenges, we propose two novel extensions. First, we develop methods to build a spatial ontology defining concepts and relations relevant for indoor and outdoor robot operation. In particular, we use a Large Language Model (LLM) to build such an ontology, thus largely reducing the amount of manual effort required. Second, we leverage the spatial ontology for 3D scene graph construction using Logic Tensor Networks (LTN) to add logical rules, or axioms (e.g., “a beach contains sand”), which provide additional supervisory signals at training time thus reducing the need for labelled data, providing better predictions, and even allowing predicting concepts unseen at training time. We test our approach in a variety of datasets, including indoor, rural, and coastal environments, and show that it leads to a significant increase in the quality of the 3D scene graph generation with sparsely annotated data.},
	number = {6},
	journal = {IEEE Robotics and Automation Letters},
	author = {Strader, Jared and Hughes, Nathan and Chen, William and Speranzon, Alberto and Carlone, Luca},
	month = jun,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Ontology, Artificial intelligence, Semantics, Modeling languages, Scene understanding, Indoor environment, Training data, Solid modeling, Three-dimensional displays, Semantic scene understanding, 3D scene graphs, AI-based methods, Image analysis, semantic scene understanding, spatial ontologies, Spatial resolution, Ontology's, Three dimensional computer graphics, Personnel training, Spatial ontologies, 3d scene graph, 3D scenes, AI-based method, Scene-graphs, Solid modelling, Three dimensional displays, Three-dimensional display},
	pages = {4886--4893},
	annote = {Type: Article}
}

@article{strakova2023ExtendingEventType,
	file = {References/pdf/strakova2023ExtendingEventType.pdf},
	title = {Extending an {Event}-type {Ontology}: {Adding} {Verbs} and {Classes} {Using} {Fine}-tuned {LLMs} {Suggestions}},
	url = {https://aclanthology.org/2023.law-1.9/},
	doi = {10.18653/v1/2023.law-1.9},
	abstract = {In this project, we have investigated the use of advanced machine learning methods, specifically fine-tuned large language models, for pre-annotating data for a lexical extension task, namely adding descriptive words (verbs) to an existing (but incomplete, as of yet) ontology of event types. Several research questions have been focused on, from the investigation of a possible heuristics to provide at least hints to annotators which verbs to include and which are outside the current version of the ontology, to the possible use of the automatic scores to help the annotators to be more efficient in finding a threshold for identifying verbs that cannot be assigned to any existing class and therefore they are to be used as seeds for a new class. We have also carefully examined the correlation of the automatic scores with the human annotation. While the correlation turned out to be strong, its influence on the annotation proper is modest due to its near linearity, even though the mere fact of such pre-annotation leads to relatively short annotation times.},
	journal = {Proceedings of the 17th Linguistic Annotation Workshop (LAW-XVII)},
	author = {Straková, Jana and Fučíková, Eva and Hajič, Jan and Urešová, Zdeňka},
	editor = {Prange, Jakob and Friedrich, Annemarie},
	month = jul,
	year = {2023},
	note = {Place: Toronto, Canada
Publisher: Association for Computational Linguistics
Section: 0},
	keywords = {Ontology, Language model, Learning systems, Ontology's, 'current, Research questions, Event Types, Human annotations, Machine learning methods},
	pages = {85--95},
	annote = {Type: Conference paper}
}

@Article{suchanek2008YagoLargeOntology,
	file = {References/pdf/suchanek2008YagoLargeOntology.pdf},
	author = {Suchanek, Fabian M. and Kasneci, Gjergji and Weikum,
                  Gerhard},
	title = {YAGO: A Large Ontology from Wikipedia and WordNet},
	journal = {Journal of Web Semantics},
	year = 2008,
	volume = 6,
	number = 3,
	month = sep,
	pages = {203–217},
	issn = {1570-8268},
	doi = {10.1016/j.websem.2008.06.001},
	url = {http://dx.doi.org/10.1016/j.websem.2008.06.001},
	publisher = {Elsevier BV}
}

@article{sun2024AreLargeLanguage,
	file = {References/pdf/sun2024AreLargeLanguage.pdf},
	title = {Are {Large} {Language} {Models} a {Good} {Replacement} of {Taxonomies}?},
	volume = {17},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3681954.3681973},
	doi = {10.14778/3681954.3681973},
	abstract = {Large language models (LLMs) demonstrate an impressive ability to internalize knowledge and answer natural language questions. Although previous studies validate that LLMs perform well on general knowledge while presenting poor performance on long-tail nuanced knowledge, the community is still doubtful about whether the traditional knowledge graphs should be replaced by LLMs. In this paper, we ask if the schema of knowledge graph (i.e., taxonomy) is made obsolete by LLMs. Intuitively, LLMs should perform well on common taxonomies and at taxonomy levels that are common to people. Unfortunately, there lacks a comprehensive benchmark that evaluates the LLMs over a wide range of taxonomies from common to specialized domains and at levels from root to leaf so that we can draw a confident conclusion. To narrow the research gap, we constructed a novel taxonomy hierarchical structure discovery benchmark named TaxoGlimpse to evaluate the performance of LLMs over taxonomies. TaxoGlimpse covers ten representative taxonomies from common to specialized domains with in-depth experiments of different levels of entities in this taxonomy from root to leaf. Our comprehensive experiments of eighteen LLMs under three prompting settings validate that LLMs perform miserably poorly in handling specialized taxonomies and leaf-level entities. Specifically, the QA accuracy of the best LLM drops by up to 30\% as we go from common to specialized domains and from root to leaf levels of taxonomies.},
	number = {11},
	journal = {Proc. VLDB Endow.},
	author = {Sun, Yushi and Xin, Hao and Sun, Kai and Xu, Yifan Ethan and Yang, Xiao and Dong, Xin Luna and Tang, Nan and Chen, Lei},
	month = jul,
	year = {2024},
	note = {Section: 0},
	pages = {2919--2932},
	annote = {Publisher: VLDB Endowment}
}

@article{sun2025Docs2kgHumanLlm,
	file = {References/pdf/sun2025Docs2kgHumanLlm.pdf},
	series = {{WWW} '25},
	title = {{Docs2KG}: {A} {Human}-{LLM} {Collaborative} {Approach} to {Unified} {Knowledge} {Graph} {Construction} from {Heterogeneous} {Documents}},
	url = {https://doi.org/10.1145/3701716.3715309},
	doi = {10.1145/3701716.3715309},
	abstract = {Enterprises generate vast amounts of unstructured documents, posing challenges for knowledge extraction and representation. Large language models (LLMs) offer strong potential for processing such data but struggle with factual accuracy and provenance. Knowledge graphs (KGs) provide a structured framework to address these limitations [6], yet constructing high-quality KGs from heterogeneous data remains a challenge. To address this issue, we present Docs2KG, a modular framework to build high-quality KGs from diverse unstructured documents. We first employs state-of-the-art document processing techniques to extract textual content, tabular data, and figures. The extracted information is then unified into a multifaceted KG with three aspects: (1) a Layout KG capturing document structural hierarchies, (2) a Metadata KG preserving document properties, and (3) a Semantic KG representing domain-specific entities and relationships. Docs2KG supports multiple construction paradigms for Semantic KG: ontology-based approaches, hybrid NLP pipelines with LLM verification, LLM-guided ontology generation, and specialized models for named entity recognition, event extraction, and causal relationship identification to enhance semantic coverage and accuracy. A key feature of Docs2KG is its human-in-the-loop verification interface, enabling iterative quality assessment and refinement of the resulting KGs. Docs2KG is openly available at https://docs2kg.ai4wa.com, with the aim of advancing knowledge graph construction research and accelerating enterprise applications through high-quality knowledge graph construction.},
	journal = {Companion Proceedings of the ACM on Web Conference 2025},
	author = {Sun, Qiang and Luo, Yuanyi and Zhang, Wenxiao and Li, Sirui and Li, Jichunyang and Niu, Kai and Kong, Xiangrui and Liu, Wei},
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Semantics, knowledge graph, Data mining, Heterogeneous data, Graph theory, Extraction, Unstructured data, unstructured data, heterogeneous data, Graph construction, Iterative methods, Data handling, Information retrieval systems, Collaborative approach, Data accuracy, High quality, Quality knowledge, Semantics knowledge, Unstructured documents},
	pages = {801--804},
	annote = {event-place: Sydney NSW, Australia}
}

@article{svatek2024WelcomeNewbornEntity,
	file = {References/pdf/svatek2024WelcomeNewbornEntity.pdf},
	title = {Welcome, newborn entity! on handling newly generated entities in ontology transformation},
	volume = {3967},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006920019&partnerID=40&md5=a57ad8bb2d6f629d92714d9b77231eb1},
	abstract = {Modeling can be seen both as an engineering and a design task. Even when clear requirements are available for an ontology modeling endevour, many times the requirements can be solved in several different ways. Even further, when requirements change and evolve, a certain modeling style, or pattern, may no longer be the best choice. However, refactoring an ontology due to such changes in requirements, or due to the desire to align better with other external ontologies or data sets, is a complex and tedious process, also requiring extensive expertise. Attempting to automate part of the ontology transformation process, by identifying typical transformation patterns, and creating tool support for their semi-automated application, is therefore an important research topic. One specific sub-task of such automation is the naming of new entities (e.g. classes or properties) that are generated through the pattern application. In this paper we discuss the need for such automated naming support, and show the feasibility of introducing Large Language Models (LLMs) for taking the automation one step further. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Svátek, Vojtech and Ŝváb-Zamazal, Ondr̂ej Ř.Ej and Haniková, Kateřina and Chudán, David and Saeedizade, Mohammad Javad and Blomqvist, Eva},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology model, Language model, OWL, Requirements engineering, Ontology's, Design tasks, Best choice, Entity naming, Ontology transformation, Requirements change},
	annote = {Type: Conference paper}
}

@article{taboada2025OntologyMatchingWith,
	file = {References/pdf/taboada2025OntologyMatchingWith.pdf},
	title = {Ontology matching with {Large} {Language} {Models} and prioritized depth-first search},
	volume = {123},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004876116&doi=10.1016%2Fj.inffus.2025.103254&partnerID=40&md5=60448dc85d882e6b0594bd7acd43f80a},
	doi = {10.1016/j.inffus.2025.103254},
	abstract = {Ontology matching (OM) plays a key role in enabling data interoperability and knowledge sharing. Recently, methods based on Large Language Model (LLMs) have shown great promise in OM, particularly through the use of a retrieve-then-prompt pipeline. In this approach, relevant target entities are first retrieved and then used to prompt the LLM to predict the final matches. Despite their potential, these systems still present limited performance and high computational overhead. To address these issues, we introduce MILA, a novel approach that embeds a retrieve-identify-prompt pipeline within a prioritized depth-first search (PDFS) strategy. This approach efficiently identifies a large number of semantic correspondences with high accuracy, limiting LLM requests to only the most borderline cases. We evaluated MILA using three challenges from the 2024 edition of the Ontology Alignment Evaluation Initiative. Our method achieved the highest F-Measure in five of seven unsupervised tasks, outperforming state-of-the-art OM systems by up to 17\%. It also performed better than or comparable to the leading supervised OM systems. MILA further exhibited task-agnostic performance, remaining stable across all tasks and settings, while significantly reducing runtime. These findings highlight that high-performance LLM-based OM can be achieved through a combination of programmed (PDFS), learned (embedding vectors), and prompting-based heuristics, without the need of domain-specific heuristics or fine-tuning. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Information Fusion},
	author = {Taboada, Maria Jesús Salvador and Martínez, Diego and Arideh, Mohammed and Mosquera, Rosa},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Interoperability, Language model, Data interoperability, Greedy search, Ontology matching, Retrieval augmented generation, Zero-shot setting, Performance, Depth first, Matching system},
	annote = {Type: Article}
}

@article{tang2023DomainKnowledgeDistillation,
	file = {References/pdf/tang2023DomainKnowledgeDistillation.pdf},
	title = {Domain {Knowledge} {Distillation} from {Large} {Language} {Model}: {An} {Empirical} {Study} in the {Autonomous} {Driving} {Domain}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186526218&doi=10.1109%2FITSC57777.2023.10422308&partnerID=40&md5=eb8968513a3c5a2be5a84e95c070417e},
	doi = {10.1109/ITSC57777.2023.10422308},
	abstract = {Engineering knowledge-based (or expert) systems require extensive manual effort and domain knowledge. As Large Language Models (LLMs) are trained using an enormous amount of cross-domain knowledge, it becomes possible to automate such engineering processes. This paper presents an empirical automation and semi-automation framework for domain knowledge distillation using prompt engineering and the LLM ChatGPT. We assess the framework empirically in the autonomous driving domain and present our key observations. In our implementation, we construct the domain knowledge ontology by “chatting” with ChatGPT. The key finding is that while fully automated domain ontology construction is possible, human supervision and early intervention typically improve efficiency and output quality as they lessen the effects of response randomness and the butterfly effect. We, therefore, also develop a web-based distillation assistant enabling supervision and flexible intervention at runtime. We hope our findings and tools could inspire future research toward revolutionizing the engineering of knowledge-based systems across application domains.},
	journal = {2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC)},
	author = {Tang, Yun and Da Costa, Antonio A. Bruto and Zhang, Xizhe and Patrick, Irvine and Khastgir, Siddartha and Jennings, Paul},
	month = sep,
	year = {2023},
	note = {Section: 0},
	keywords = {large language model, Ontologies, Large language model, Ontology, Language model, Domain ontologies, Knowledge engineering, Autonomous vehicles, Intelligent transportation systems, Domain knowledge, Autonomous driving, Empirical studies, Computational linguistics, Cross-domain, Engineering knowledge, Chatbots, autonomous driving, Manuals, Runtime, domain ontology distillation, Domain Knowledge, Distillation, Domain ontology distillation, Knowledge experts},
	pages = {3893--3900},
	annote = {ISSN: 2153-0017}
}

@article{taye2023OntologyLearningFramework,
	file = {References/pdf/taye2023OntologyLearningFramework.pdf},
	title = {An {Ontology} {Learning} {Framework} for unstructured {Arabic} {Text}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184808063&doi=10.1109%2FISAS60782.2023.10391548&partnerID=40&md5=383c7dfc97308ff44961706ab31047f2},
	doi = {10.1109/ISAS60782.2023.10391548},
	abstract = {Ontologies are widely regarded as valuable sources of semantics and interoperability in all artificially intelligent systems. Due to the rapid growth of unstructured data on the web, studying how to automatically get ontology from unstructured text is important. Therefore, ontology learning (OL) is an important process in the business world. It involves finding and extracting concepts from the text so that these concepts can be used for things such as information retrieval. Unfortunately, learning ontology is not easy for some reasons, and there has not been much research on how to automatically learn a domain-specific ontology from data.Ontology Studying Arabic text is not as developed as learning Latin text. There is almost no automated support for using Arabic literary knowledge in semantically enabled systems. Machine learning (ML) has proven beneficial in numerous fields, including text mining. By employing neural language models such as AraBERT, it is possible to obtain word embeddings as distributed word representations from textual input using machine learning. However, the application of machine learning to aid the development of Arabic ontology is largely unexplored. This research examines the performance of AraBERT for ontology learning tasks in Arabic. Early performance results as an application of Arabic ontology learning are promising. In this research, we provide a method for populating an existing ontology with instance information extracted from the input natural language text. This prototype has achieved an information extraction accuracy of 91\%.},
	journal = {2023 7th International Symposium on Innovative Approaches in Smart Technologies (ISAS)},
	author = {Taye, Mohammad Mustafa and Abulail, Rawan and Al-Oudat, Mohammad},
	month = nov,
	year = {2023},
	note = {Section: 0},
	keywords = {Ontologies, Interoperability, Ontology, Natural language processing, Ontology learning, Semantic Web, Semantics, Text mining, Semantic representation, Machine learning, Information retrieval, Arabic ontology, Data mining, Intelligent systems, Arabic Ontology, Language processing, Natural languages, Prototypes, Learning systems, Ontology Learning (OL), Natural language Processing (NLP), semantic representation, Ontology's, Natural language processing systems, Learning algorithms, Semantic-Web},
	pages = {1--12},
	annote = {Type: Conference paper}
}

@article{teclaw2025BuildingInformationModel,
	file = {References/pdf/teclaw2025BuildingInformationModel.pdf},
	title = {Building information model and schema cross-validation using semantics – conceptual framework},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010599305&doi=10.1177%2F14780771251352954&partnerID=40&md5=e22edf984918c7575e8f14ed451fd433},
	doi = {10.1177/14780771251352954},
	abstract = {Ensuring consistency between Mechanical, Electrical, and Plumbing (MEP) schema drawings and Building Information Models (BIM) is essential for design accuracy and minimizing data discrepancies in construction projects. While BIM provides detailed 3D visualizations of building components, schematic drawings remain crucial for capturing the logical and functional relationships within early-stage designs. However, discrepancies between these two representations often arise, necessitating extensive manual verification. This study introduces a conceptual framework for automated cross-validation between MEP schema drawings and BIM models by leveraging semantic representations. The framework utilizes AI-driven technologies, particularly Large Language Models (LLMs), to extract structured knowledge from both schematics and BIM data, translating this information into machine-readable formats based on the Brick ontology. By integrating semantic web technologies and multimodal processing, the proposed framework effectively identifies inconsistencies in airflow distribution, system connectivity, and performance parameters. This approach significantly enhances the efficiency and accuracy of design validation, minimizes data discrepancies, and fosters interoperability among heterogeneous data sources. Initial findings demonstrate the scalability and effectiveness of semantic-based validation, suggesting substantial benefits for MEP-BIM integration. Future research will extend the framework to additional MEP domains, including electrical and plumbing systems, and further refine AI-based recognition methods. © 2025 Elsevier B.V., All rights reserved.},
	journal = {International Journal of Architectural Computing},
	author = {Teclaw, Wojciech and Łuczkowski, Marcin and Labonnote, Nathalie and Hjelseth, Eilif},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Interoperability, Ontology, Language model, Semantic Web, Semantics, Information theory, Validation, Building Information Modelling, Construction projects, Conceptual frameworks, Architectural design, Building Information Model, Data accuracy, and plumbing, Cross validation, electrical, Information schema, Mechanical, Three dimensional computer graphics},
	annote = {Type: Article}
}

@article{toro2024DynamicRetrievalAugmented,
	file = {References/pdf/toro2024DynamicRetrievalAugmented.pdf},
	title = {Dynamic {Retrieval} {Augmented} {Generation} of {Ontologies} using {Artificial} {Intelligence} ({DRAGON}-{AI})},
	volume = {15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206568005&doi=10.1186%2Fs13326-024-00320-3&partnerID=40&md5=a23bb98318ff68a24095821e8384557b},
	doi = {10.1186/s13326-024-00320-3},
	abstract = {Background: Ontologies are fundamental components of informatics infrastructure in domains such as biomedical, environmental, and food sciences, representing consensus knowledge in an accurate and computable form. However, their construction and maintenance demand substantial resources and necessitate substantial collaboration between domain experts, curators, and ontology experts. We present Dynamic Retrieval Augmented Generation of Ontologies using AI (DRAGON-AI), an ontology generation method employing Large Language Models (LLMs) and Retrieval Augmented Generation (RAG). DRAGON-AI can generate textual and logical ontology components, drawing from existing knowledge in multiple ontologies and unstructured text sources. Results: We assessed performance of DRAGON-AI on de novo term construction across ten diverse ontologies, making use of extensive manual evaluation of results. Our method has high precision for relationship generation, but has slightly lower precision than from logic-based reasoning. Our method is also able to generate definitions deemed acceptable by expert evaluators, but these scored worse than human-authored definitions. Notably, evaluators with the highest level of confidence in a domain were better able to discern flaws in AI-generated definitions. We also demonstrated the ability of DRAGON-AI to incorporate natural language instructions in the form of GitHub issues. Conclusions: These findings suggest DRAGON-AI's potential to substantially aid the manual ontology construction process. However, our results also underscore the importance of having expert curators and ontology editors drive the ontology generation process. © 2024 Elsevier B.V., All rights reserved.},
	number = {1},
	journal = {Journal of Biomedical Semantics},
	author = {Toro, Sabrina and Anagnostopoulos, Anna V. and Bello, Susan M. and Blumberg, Kai Lewis and Cameron, Rhiannon and Carmody, Leigh C. and Diehl, Alexander D. and Dooley, Damion M. and Duncan, William D. and Fey, Petra},
	year = {2024},
	note = {Section: 0},
	keywords = {artificial intelligence, natural language processing, information retrieval, Natural Language Processing, Artificial Intelligence, Biological Ontologies, procedures, biological ontology, Information Storage and Retrieval},
	annote = {Type: Article}
}

@article{totoian2024HybridomOntologyMatching,
	file = {References/pdf/totoian2024HybridomOntologyMatching.pdf},
	title = {{HybridOM}: {Ontology} {Matching} using {Hybrid} {Search}},
	volume = {3897},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216388200&partnerID=40&md5=6c536aafb8b92a07ed02734fedb6f96c},
	abstract = {Ontology matching targets identical concepts from different ontologies with the final purpose of interoperability and ontologies merging. The matching task is not restricted to ontologies, it is also relevant for knowledge graphs. Ontology matching solutions based on transformer-based embeddings, textual similarity, logical mapping, or Large Language Models (LLMs) are still facing problems, mainly due to the lack of uniform information about the concepts and lack of homogeneous semantic granularity along different ontologies. In this work, we present a framework that combines vector-based similarity and string-based similarity through hybrid searches. LLMs are used to generate descriptions for ontology concepts, hence the concepts' representation is enriched and the alignment process can benefit from both the knowledge captured by the initial ontologies and the extended LLM-generated textual descriptions. The proposed system, HybridOM, is an unsupervised approach independent of the ontologies' domain. HybridOM is evaluated within Bio-ML 2024 track for the task of concept matching. It achieves the highest values for F1-score and Recall for most of the ontology pairs while maintaining a balance between precision and recall. The proposed method has been adapted for industrial usage in a human capital management product called msg.ProfileMap. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Totoian, Marius Horatiu and Marginean, Anca Nicoleta and Blohm, Philipp and Hussain, Mir Nawab},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Semantics, Ontology matching, Ontology merging, Ontology's, Hybrid search, Human resource management, Vector database, Verbalization},
	pages = {138 -- 145},
	annote = {Type: Conference paper}
}

@Online{touvron2023Llama2Open,
	author = {Hugo Touvron AND Louis Martin AND Kevin Stone AND
                  Peter Albert AND Amjad Almahairi AND Yasmine Babaei
                  AND Nikolay Bashlykov AND Soumya Batra AND Prajjwal
                  Bhargava AND Shruti Bhosale AND Dan Bikel AND Lukas
                  Blecher AND Cristian Canton Ferrer AND Moya Chen AND
                  Guillem Cucurull AND David Esiobu AND Jude Fernandes
                  AND Jeremy Fu AND Wenyin Fu AND Brian Fuller AND
                  Cynthia Gao AND Vedanuj Goswami AND Naman Goyal AND
                  Anthony Hartshorn AND Saghar Hosseini AND Rui Hou
                  AND Hakan Inan AND Marcin Kardas AND Viktor Kerkez
                  AND Madian Khabsa AND Isabel Kloumann AND Artem
                  Korenev AND Punit Singh Koura AND Marie-Anne Lachaux
                  AND Thibaut Lavril AND Jenya Lee AND Diana Liskovich
                  AND Yinghai Lu AND Yuning Mao AND Xavier Martinet
                  AND Todor Mihaylov AND Pushkar Mishra AND Igor
                  Molybog AND Yixin Nie AND Andrew Poulton AND Jeremy
                  Reizenstein AND Rashi Rungta AND Kalyan Saladi AND
                  Alan Schelten AND Ruan Silva AND Eric Michael Smith
                  AND Ranjan Subramanian AND Xiaoqing Ellen Tan AND
                  Binh Tang AND Ross Taylor AND Adina Williams AND
                  Jian Xiang Kuan AND Puxin Xu AND Zheng Yan AND
                  Iliyan Zarov AND Yuchen Zhang AND Angela Fan AND
                  Melanie Kambadur AND Sharan Narang AND Aurelien
                  Rodriguez AND Robert Stojnic AND Sergey Edunov AND
                  Thomas Scialom},
	title = {{Llama 2: Open Foundation and Fine-Tuned Chat
                  Models}},
	year = 2023,
	eprint = {2307.09288v2},
	primaryclass = {cs.CL},
	archiveprefix = {arXiv}
}

@article{trappey2025PatentLitigationMining,
	file = {References/pdf/trappey2025PatentLitigationMining.pdf},
	title = {Patent litigation mining using a large language model—{Taking} unmanned aerial vehicle development as the case domain},
	volume = {80},
	issn = {0172-2190},
	url = {https://www.sciencedirect.com/science/article/pii/S0172219024000723},
	doi = {https://doi.org/10.1016/j.wpi.2024.102332},
	abstract = {As unmanned aerial vehicle (UAV), also called “drone”, swiftly advances with innovative functions and applications, the surge in patent applications has profoundly reshaped the intellectual property (IP) landscape in the UAV industry, leading to a growing number of litigations. This study is structured in two phases, aiming to develop an intelligent approach to analyzing the trend and evolution of patent litigations. The first phase involves macro- and micro-patent analyses of the related technology domain. Macro patent analysis elucidates the fundamental patent information in the drone industry, while micro patent analysis leverages the technology function matrix (TFM) to identify R\&D hotspots and potentials. The second phase involves litigation (judgement) mining based on large language model (LLM). Beginning with the construction of a knowledge ontology, the domain infringement landscape can be detected through TFMs. A comparative analysis of the two-phase TFMs (i.e., both TFMs of patent and infringement allocations) is then conducted to pinpoint the key legal actions and the relevant technology. To drill deeper in infringement mining, dynamic topic modeling (DTM) is applied to analyze trends and dynamics in drone controller technology over time. This study aims to strengthen IP protection by developing an intelligent litigation mining approach that adopts large language model (LLM) and uses UAV/drone litigation studies as examples to show how the approach being applied in the industry.},
	journal = {World Patent Information},
	author = {Trappey, Amy J. C. and Chou, Shao-Chien and Li, Gi-Kuen J.},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Drone, Dynamic topic modeling, Patent analysis, Patent litigation mining, Technology function matrix, Unmanned aerial vehicle (UAV)},
	pages = {102332},
	annote = {Type: Article}
}

@article{tsaneva2024LlmDrivenOntology,
	file = {References/pdf/tsaneva2024LlmDrivenOntology.pdf},
	title = {{LLM}-driven {Ontology} {Evaluation}: {Verifying} {Ontology} {Restrictions} with {ChatGPT}},
	volume = {3747},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203385177&partnerID=40&md5=7ab507fcd01da145dd09b126148403a6},
	abstract = {Recent advancements in artificial intelligence, particularly in large language models (LLMs), have sparked interest in their application to knowledge engineering (KE) tasks. While existing research has primarily explored the utilisation of LLMs for constructing and completing semantic resources such as ontologies and knowledge graphs, the evaluation of these resources-addressing quality issues- has not yet been thoroughly investigated. To address this gap, we propose an LLM-driven approach for the verification of ontology restrictions. We replicate our previously conducted human-in-the-loop experiment using ChatGPT-4 instead of human contributors to assess whether comparable ontology verification results can be obtained. We find that (1) ChatGPT-4 achieves intermediate-to-expert scores on an ontology modelling qualification test; (2) the model performs ontology restriction verification with accuracy of 92.22\%; (3) combining model answers on the same ontology axiom represented in different formalisms improves the accuracy to 96.67\%; and (4) higher accuracy is observed in identifying defects related to the incompleteness of ontology axioms compared to errors due to restrictions misuse. Our results highlight the potential of LLMs in supporting knowledge engineering tasks and outline future research directions in the area. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Tsaneva, Stefani and Vasic, Stefan and Sabou, Marta},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graph, Large language model, Ontology, Language model, Semantics, Modeling languages, Semantic resources, Defect detection, Model-driven, Ontology's, Ontology graphs, Ontology evaluations, Engineering tasks, Engineering research, Errors, Ontology axioms},
	pages = {15},
	annote = {Type: Conference paper}
}

@article{tsaneva2025BenchmarkingOntologyValidation,
	file = {References/pdf/tsaneva2025BenchmarkingOntologyValidation.pdf},
	title = {Benchmarking {Ontology} {Validation} {Capabilities} of {LLMs}},
	volume = {3953},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003709629&partnerID=40&md5=a794337d7764e3e883482385a1b47794},
	abstract = {With the advent of Generative AI, numerous approaches exploring large language models (LLMs) have been proposed for addressing a number of Knowledge Engineering (KE) tasks. Yet, the status of this research field is rather preliminary and there is, for now, no systematic and comprehensive understanding on how LLMs perform on selected knowledge engineering tasks (e.g., what is their expertise level in understanding ontology modeling concepts). Such insights would be crucial for researchers working in this field to support with selecting the most suitable LLMs during experiment design. This situation is exacerbated by the rapid expansion in the number of available LLMs. We therefore see the need for methodologies and tools that allow (comparatively) assessing LLM capabilities. To address this need, we propose the creation of an assessment test benchmark for evaluating the LLM knowledge engineering skills. We present ongoing work and preliminary results on assessing the expertise of LLMs in terms of a concrete KE task, namely ontology validation. Our experiments highlight the superiority of proprietary models on this task, particularly GPT-4o and Claude-Sonnet-3.5, over open source models. Lastly, we identify the need of a community-driven comparative LLM assessment platform that facilitates resource sharing and experience exchange, while protecting the integrity and privacy of the envisioned benchmark. We share (i) the current version of the qualification tests and (ii) its implementation for assessing LLM capabilities for ontology validation. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Tsaneva, Stefani and Herwanto, Guntur Budi and Sabou, Marta},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology model, Language model, Engineering tasks, Engineering research, Assessment test, Expertise evaluation, Modeling concepts, Ontology validations, Research fields, Validation capability},
	annote = {Type: Conference paper}
}

@article{tupayachi2024TowardsNextGeneration,
	file = {References/pdf/tupayachi2024TowardsNextGeneration.pdf},
	title = {Towards {Next}-{Generation} {Urban} {Decision} {Support} {Systems} through {AI}-{Powered} {Construction} of {Scientific} {Ontology} {Using} {Large} {Language} {Models}—{A} {Case} in {Optimizing} {Intermodal} {Freight} {Transportation}},
	volume = {7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207278547&doi=10.3390%2Fsmartcities7050094&partnerID=40&md5=8aac4eff5a2cd83bba2ce13f8f44fd59},
	doi = {10.3390/smartcities7050094},
	abstract = {Highlights: What are the main findings? We have developed an integrated and automated methodology that leverages a pre-trained Large Language Model (LLM) to generate scenario-based ontologies and knowledge graphs from research articles and technical manuals. Our methodology utilizes the ChatGPT API as the primary reasoning engine, supplemented by Natural Language Processing modules and carefully engineered prompts. This combination enables an automated tool capable of generating ontologies independently. The ontologies generated through our AI-powered method are interoperable and can significantly facilitate the design of data models and software architecture, particularly in the development of urban decision support systems. What is the implication of the main finding? We compared ontologies generated by our LLM with those created by human experts through CQ-based qualitative evaluation, assessing the reliability and feasibility of our approach. The methodology has been successfully applied to intermodal freight data and simulations. This has allowed us to generate a scenario-based ontology and knowledge graph that enhances data discovery, integration, and management, thereby supporting network optimization and multiple criteria decision analysis. Our methodology is both generalizable and adaptive, enabling the automation of ontology generation to support the development of urban and environmental decision support systems across various disciplines. The incorporation of Artificial Intelligence (AI) models into various optimization systems is on the rise. However, addressing complex urban and environmental management challenges often demands deep expertise in domain science and informatics. This expertise is essential for deriving data and simulation-driven insights that support informed decision-making. In this context, we investigate the potential of leveraging the pre-trained Large Language Models (LLMs) to create knowledge representations for supporting operations research. By adopting ChatGPT-4 API as the reasoning core, we outline an applied workflow that encompasses natural language processing, Methontology-based prompt tuning, and Generative Pre-trained Transformer (GPT), to automate the construction of scenario-based ontologies using existing research articles and technical manuals of urban datasets and simulations. From these ontologies, knowledge graphs can be derived using widely adopted formats and protocols, guiding various tasks towards data-informed decision support. The performance of our methodology is evaluated through a comparative analysis that contrasts our AI-generated ontology with the widely recognized pizza ontology, commonly used in tutorials for popular ontology software. We conclude with a real-world case study on optimizing the complex system of multi-modal freight transportation. Our approach advances urban decision support systems by enhancing data and metadata modeling, improving data integration and simulation coupling, and guiding the development of decision support strategies and essential software components. © 2024 Elsevier B.V., All rights reserved.},
	number = {5},
	journal = {Smart Cities},
	author = {Tupayachi, Jose and Xu, Haowen and Omitaomu, Olufemi A. and Camur, Mustafa Can and Sharmin, Aliza and Li, Xueping},
	year = {2024},
	note = {Section: 0},
	pages = {2392 -- 2421},
	annote = {Type: Article}
}

@article{valcalvo2025OntogenixLeveragingLarge,
	file = {References/pdf/valcalvo2025OntogenixLeveragingLarge.pdf},
	title = {{OntoGenix}: {Leveraging} {Large} {Language} {Models} for enhanced ontology engineering from datasets},
	volume = {62},
	issn = {0306-4573},
	url = {https://www.sciencedirect.com/science/article/pii/S0306457324004011},
	doi = {https://doi.org/10.1016/j.ipm.2024.104042},
	abstract = {Knowledge Graphs integrate data from multiple, heterogeneous sources, using ontologies to facilitate data interoperability. Ontology development is a resource-consuming task that requires the collaborative work of domain experts and ontology engineers. Therefore, companies invest considerable resources in order to generate and maintain Enterprise Knowledge Graphs and ontologies from large and complex datasets, most of which can be unfamiliar for ontology engineers. In this work, we study the use of Large Language Models to aid in the development of ontologies from datasets, ultimately increasing the automation of the generation of ontology-based Knowledge Graphs. As a result we have developed a structured workflow that leverages Large Language Models to enhance ontology engineering through data pre-processing, ontology planning, building, and entity improvement. Our method is also able to generate mappings and RDF data, but in this work we focus on the ontologies. The pipeline has been implemented in the OntoGenix tool. In this work we show the results of the application of OntoGenix to six datasets related to commercial activities. The findings indicate that the ontologies produced exhibit patterns of coherent modeling, and features that closely resemble those created by humans, although the most complex situations are better reflected by the ontologies developed by humans.},
	number = {3},
	journal = {Information Processing \& Management},
	author = {Val-Calvo, Mikel and Aranguren, Mikel Egaña and Mulero-Hernández, Juan and Almagro-Hernández, Ginés and Deshmukh, Prashant and Bernabé-Díaz, José Antonio and Espinoza-Arias, Paola and Sánchez-Fernández, José Luis and Mueller, Juergen and Fernández-Breis, Jesualdo Tomás},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Large Language Models, Ontology engineering, Knowledge graph, Large language model, Language model, Data interoperability, Ontology development, Modeling languages, Ontology's, Data assimilation, Collaborative Work, Domain experts, Heterogeneous sources},
	pages = {104042},
	annote = {Type: Article}
}

@Article{van2008VisualizingData,
	title = {Visualizing data using t-SNE.},
	author = {Van der Maaten, Laurens and Hinton, Geoffrey},
	journal = {Journal of machine learning research},
	volume = {9},
	number = {11},
	year = {2008}
}

@Article{vaswani2017AttentionIsAll,
	file = {References/pdf/vaswani2017AttentionIsAll.pdf},
	title = {Attention is all you need},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
	journal = {Advances in neural information processing systems},
	volume = {30},
	year = {2017}
}

@article{vieira2024TowardMethodGenerate,
	file = {References/pdf/vieira2024TowardMethodGenerate.pdf},
	title = {Toward a {Method} to {Generate} {Capability} {Ontologies} from {Natural} {Language} {Descriptions}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207822437&doi=10.1109%2FETFA61755.2024.10710783&partnerID=40&md5=102ee20eccf408c633442c86eed6632e},
	doi = {10.1109/ETFA61755.2024.10710783},
	abstract = {To achieve a flexible and adaptable system, capabil-ity ontologies are increasingly leveraged to describe functions in a machine-interpretable way. However, modeling such complex ontological descriptions is still a manual and error-prone task that requires a significant amount of effort and ontology expertise. This contribution presents an innovative method to automate capability ontology modeling using Large Language Models (LLMs), which have proven to be well suited for such tasks. Our approach requires only a natural language description of a capability, which is then automatically inserted into a predefined prompt using a few-shot prompting technique. After prompting an LLM, the resulting capability ontology is automatically verified through various steps in a loop with the LLM to check the overall correctness of the capability ontology. First, a syntax check is performed, then a check for contradictions, and finally a check for hallucinations and missing ontology elements. Our method greatly reduces manual effort, as only the initial natural language description and a final human review and possible correction are necessary, thereby streamlining the capability ontology generation process.},
	journal = {2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA)},
	author = {Vieira da Silva, Luis Miguel and Kocher, Aljosha and Gehlhoff, Felix and Fay, Alexander},
	month = sep,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Large Language Models, Large language model, Ontology, Language model, Large language models, Semantic Web, Semantics, Modeling languages, LLMs, Model generation, Reviews, Skill, Skills, Testing, Manuals, Natural languages, Syntactics, Adaptation models, Costs, Manufacturing automation, Capabilities, Model-Generation, Ontology's, Natural language processing systems, Semantic-Web, Capability},
	pages = {1--4},
	annote = {ISSN: 1946-0759}
}

@article{vieira2024UseLargeLanguage,
	file = {References/pdf/vieira2024UseLargeLanguage.pdf},
	title = {On the {Use} of {Large} {Language} {Models} to {Generate} {Capability} {Ontologies}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197107836&doi=10.1109%2FETFA61755.2024.10710775&partnerID=40&md5=544ef7ed4c7c396646d5da759dd60db8},
	doi = {10.1109/ETFA61755.2024.10710775},
	abstract = {Capability ontologies are increasingly used to model functionalities of systems or machines. The creation of such onto-logical models with all properties and constraints of capabilities is very complex and can only be done by ontology experts. However, Large Language Models (LLMs) have shown that they can generate machine-interpretable models from natural language text input and thus support engineers / ontology experts. Therefore, this paper investigates how LLMs can be used to create capability ontologies. We present a study with a series of experiments in which capabilities with varying complexities are generated using different prompting techniques and with different LLMs. Errors in the generated ontologies are recorded and compared. To analyze the quality of the generated ontologies, a semi-automated approach based on RDF syntax checking, OWL reasoning, and SHACL constraints is used. The results of this study are very promising because even for complex capabilities, the generated ontologies are almost free of errors.},
	journal = {2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA)},
	author = {Vieira da Silva, Luis Miguel and Kocher, Aljosha and Gehlhoff, Felix and Fay, Alexander},
	month = sep,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Large Language Models, Large language model, Ontology, Language model, Large language models, Semantic Web, Semantics, OWL, Resource description framework, LLMs, Cognition, Model generation, Skill, Computational linguistics, Skills, Complexity theory, Testing, Logical models, Natural languages, Shape, Syntactics, Capabilities, Model-Generation, Ontology's, Natural language processing systems, Semantic-Web, Capability},
	pages = {1--8},
	annote = {ISSN: 1946-0759}
}

@article{vrolijk2024OntologyLearningEsco,
	file = {References/pdf/vrolijk2024OntologyLearningEsco.pdf},
	title = {Ontology {Learning} for {ESCO}: {Leveraging} {LLMs} to {Navigate} {Labor} {Dynamics}},
	volume = {3853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212710838&partnerID=40&md5=c99afbb428f4560ed7610a55af6ef3b2},
	abstract = {The labor market is a dynamic environment that supports numerous knowledge-driven applications through ontologies, such as ESCO and O*NET. Maintaining the relevance and accuracy of information within these ontologies and taxonomies is both resource-intensive and time-consuming. In this paper, we propose an ontology learning system that utilizes self-supervised learning, retrieval-augmented generation, and autoregressive language models to identify, classify, and link labor market mentions and entities from raw job postings. Additionally, we demonstrate the language model's ability to discover "alternative labels" and "preferred labels", and perform relation classification. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Vrolijk, Jarno and Poslavsky, Victor and Bijl, Thijmen and Popov, Maksim and Mahdavi, Rana and Shokri, Mohammad},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Natural language processing, Language model, Ontology learning, Self-supervised learning, Semi-supervised learning, Language processing, Adversarial machine learning, Natural languages, Ontology's, Labour market, Wages, Commerce, Dynamic environments, Labor dynamics},
	annote = {Type: Conference paper}
}

@article{vukovic2024DialogueOntologyRelation,
	file = {References/pdf/vukovic2024DialogueOntologyRelation.pdf},
	title = {Dialogue {Ontology} {Relation} {Extraction} via {Constrained} {Chain}-of-{Thought} {Decoding}},
	url = {https://aclanthology.org/2024.sigdial-1.33/},
	doi = {10.18653/v1/2024.sigdial-1.33},
	abstract = {State-of-the-art task-oriented dialogue systems typically rely on task-specific ontologies for fulfilling user queries. The majority of task-oriented dialogue data, such as customer service recordings, comes without ontology and annotation. Such ontologies are normally built manually, limiting the application of specialised systems. Dialogue ontology construction is an approach for automating that process and typically consists of two steps: term extraction and relation extraction. In this work, we focus on relation extraction in a transfer learning set-up. To improve the generalisation, we propose an extension to the decoding mechanism of large language models. We adapt Chain-of-Thought (CoT) decoding, recently developed for reasoning problems, to generative relation extraction. Here, we generate multiple branches in the decoding space and select the relations based on a confidence threshold. By constraining the decoding to ontology terms and relations, we aim to decrease the risk of hallucination. We conduct extensive experimentation on two widely used datasets and find improvements in performance on target ontology for source fine-tuned and one-shot prompted large language models.},
	journal = {Proceedings of the 25th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
	author = {Vukovic, Renato and Arps, David and van Niekerk, Carel and Ruppik, Benjamin Matthias and Lin, Hsien-chin and Heck, Michael and Gasic, Milica},
	editor = {Kawahara, Tatsuya and Demberg, Vera and Ultes, Stefan and Inoue, Koji and Mehri, Shikib and Howcroft, David and Komatani, Kazunori},
	month = sep,
	year = {2024},
	note = {Place: Kyoto, Japan
Publisher: Association for Computational Linguistics
Section: 0},
	pages = {370--384}
}

@article{wang2022AmdResultsOaei,
	file = {References/pdf/wang2022AmdResultsOaei.pdf},
	title = {{AMD} {Results} for {OAEI} 2022},
	volume = {3324},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146423755&partnerID=40&md5=5d40e36481c36d7e9d14b4536f18bebe},
	abstract = {AgreementMakerDeep (AMD) is a new flexible and extensible ontology matching system. It exploits the contextual and structural information of ontologies by infusing knowledge to pre-trained masked language model, and then filter the output mappings using knowledge graph embedding techniques. AMD learns from classes and their relations between classes by constructing vector representations into the low dimensional embedding space with knowledge graph embedding methods. The results demonstrate that AMD achieves a competitive performance in many OAEI tracks, but AMD has limitations for property and instance matching. © 2023 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Wang, Zhu},
	year = {2022},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Ontology matching, Computational linguistics, Graph embeddings, Knowledge graph embedding, Pre-train language model, Ontology's, Matching system, Vector spaces, Structural information, Contextual information},
	pages = {145 -- 152},
	annote = {Type: Conference paper}
}

@article{wang2023AmdResultsOaei,
	file = {References/pdf/wang2023AmdResultsOaei.pdf},
	title = {{AMD} {Results} for {OAEI} 2023},
	volume = {3591},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180779638&partnerID=40&md5=5de524163e7e345de6e2c5ebd3bde262},
	abstract = {AgreementMakerDeep (AMD) is a new flexible and extensible ontology matching system. It exploits the contextual and structural information of ontologies by infusing knowledge to pre-trained masked language model, and then filter the output mappings using knowledge graph embedding techniques. AMD learns from classes and their relations between classes by constructing vector representations into the low dimensional embedding space with knowledge graph embedding methods. The results demonstrate that AMD achieves a competitive performance in many OAEI tracks, but AMD has limitations for property and instance matching. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Wang, Zhu},
	year = {2023},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Ontology matching, Computational linguistics, Graph embeddings, Knowledge graph embedding, Ontology's, Matching system, Vector spaces, Structural information, Contextual information},
	pages = {146 -- 153},
	annote = {Type: Conference paper}
}

@article{wang2023ContextualizedStructuralSelf,
	file = {References/pdf/wang2023ContextualizedStructuralSelf.pdf},
	title = {Contextualized {Structural} {Self}-supervised {Learning} for {Ontology} {Matching}},
	volume = {3591},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180754259&partnerID=40&md5=3cffc4029e8fbfd6858798439a8e6d9b},
	abstract = {Ontology matching (OM) entails the identification of semantic relationships between concepts within two or more knowledge graphs (KGs) and serves as a critical step in integrating KGs from various sources. Recent advancements in deep OM models have harnessed the power of transformer-based language models and the advantages of knowledge graph embedding. Nevertheless, these OM models still face persistent challenges, such as a lack of reference alignments, runtime latency, and unexplored different graph structures within an end-to-end framework. In this study, we introduce a novel self-supervised learning OM framework with input ontologies, called LaKERMap. This framework capitalizes on the contextual and structural information of concepts by integrating implicit knowledge into transformers. Specifically, we aim to capture multiple structural contexts, encompassing both local and global interactions, by employing distinct training objectives. To assess our methods, we utilize the Bio-ML datasets and tasks. The findings from our innovative approach reveal that LaKERMap surpasses state-of-the-art systems in terms of alignment quality and inference time. Our models and codes are available here https://github.com/ellenzhuwang/lakermap. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Wang, Zhu},
	year = {2023},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Semantics, Ontology matching, Semantic relationships, Graph embeddings, Power, Self-supervised learning, Supervised learning, Knowledge graph embedding, Graphic methods, Relationship between concepts, Critical steps, Matching models},
	pages = {37 -- 48},
	annote = {Type: Conference paper}
}

@article{wang2024CanLargeLanguage,
	file = {References/pdf/wang2024CanLargeLanguage.pdf},
	title = {Can {Large} {Language} {Models} {Understand} {DL}-{Lite} {Ontologies}? {An} {Empirical} {Study}},
	url = {https://aclanthology.org/2024.findings-emnlp.141/},
	doi = {10.18653/v1/2024.findings-emnlp.141},
	abstract = {Large language models (LLMs) have shown significant achievements in solving a wide range of tasks. Recently, LLMs' capability to store, retrieve and infer with symbolic knowledge has drawn a great deal of attention, showing their potential to understand structured information. However, it is not yet known whether LLMs can understand Description Logic (DL) ontologies. In this work, we empirically analyze the LLMs' capability of understanding DL-Lite ontologies covering 6 representative tasks from syntactic and semantic aspects. With extensive experiments, we demonstrate both the effectiveness and limitations of LLMs in understanding DL-Lite ontologies. We find that LLMs can understand formal syntax and model-theoretic semantics of concepts and roles. However, LLMs struggle with understanding TBox NI transitivity and handling ontologies with large ABoxes. We hope that our experiments and analyses provide more insights into LLMs and inspire to build more faithful knowledge engineering solutions.},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2024},
	author = {Wang, Keyu and Qi, Guilin and Li, Jiaqi and Zhai, Songlin},
	editor = {Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung},
	month = nov,
	year = {2024},
	note = {Place: Miami, Florida, USA
Publisher: Association for Computational Linguistics
Section: 0},
	keywords = {Ontology, Language model, Semantics, Knowledge engineering, Description logic, Empirical studies, Computational linguistics, Latent semantic analysis, Formal modeling, Syntactics, Ontology's, Structured information, Experiment and analysis, Formal syntaxes, Model-theoretic semantics, Symbolic knowledge},
	pages = {2503--2519},
	annote = {Type: Conference paper}
}

@article{wang2024DoAdvancedLanguage,
	title = {Do advanced language models eliminate the need for prompt engineering in software engineering?},
	author = {Wang, Guoqing and Sun, Zeyu and Gong, Zhihao and Ye, Sixiang and Chen, Yizhou and Zhao, Yifan and Liang, Qingyuan and Hao, Dan},
	journal = {arXiv preprint arXiv:2411.02093},
	year = {2024}
}

@article{wang2024ResearchKnowledgeGraph,
	file = {References/pdf/wang2024ResearchKnowledgeGraph.pdf},
	title = {Research on {Knowledge} {Graph} {Extraction} {Methods} for {Chinese} {STEM} {Curriculum}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215598070&doi=10.1109%2FMLNLP63328.2024.10800180&partnerID=40&md5=6e0a74fed87abe5a73acc1ed74985a8b},
	doi = {10.1109/MLNLP63328.2024.10800180},
	abstract = {STEM education, as an innovative teaching model, has gained widespread attention in recent years. However, the lack of relevant textbooks and learning resources has made its implementation challenging. Developing interdisciplinary knowledge graphs tailored for STEM education has become an urgent issue. To address this, a knowledge extraction framework named Llms4edu is proposed, which utilizes a series of effective prompts to guide large language models in knowledge extraction. Specifically, the knowledge extraction task is transformed into multiple rounds of question-and-answer interactions with the LLM, gradually identifying entity-relation triplets from subject data. Through experiments, an F1-score of 89.4\% was achieved on the named entity recognition task in the chemistry subject, and an F1-score of 66.7\% on the relation extraction task. Finally, a subject ontology model was built for subject text, and a subject data set was constructed using Llms4edu, which includes three subjects of junior high school mathematics, physics, and chemistry, a total of 2,511 entities, 2,010 relationship triples, and cross-disciplinary knowledge is linked to construct a cross-disciplinary knowledge graph.},
	journal = {2024 7th International Conference on Machine Learning and Natural Language Processing (MLNLP)},
	author = {Wang, Changlong and Sang, Xiujuan and Wang, Xijie and Gao, Yuan and Liu, Yi},
	month = oct,
	year = {2024},
	note = {Section: 0},
	keywords = {large language model, Ontologies, Knowledge graphs, Knowledge graph, Large language model, Language model, Named entity recognition, Large language models, Knowledge extraction, Knowledge engineering, Annotations, Data mining, Prompt engineering, prompt engineering, Training, Federated learning, STEM education, Adversarial machine learning, Chemistry, interdisciplinary knowledge graph, Physics, Contrastive Learning, F1 scores, Graph extractions, Cross-disciplinary, Interdisciplinary knowledge graph},
	pages = {1--8},
	annote = {Type: Conference paper}
}

@article{wei2025KnowledgeEnhancedOntology,
	file = {References/pdf/wei2025KnowledgeEnhancedOntology.pdf},
	title = {Knowledge-enhanced ontology-to-vector for automated ontology concept enrichment in {BIM}},
	volume = {45},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000158606&doi=10.1016%2Fj.jii.2025.100836&partnerID=40&md5=69dfeed55bf716337ecd255e2daf40be},
	doi = {10.1016/j.jii.2025.100836},
	abstract = {Building Information Modeling (BIM) relies on standardized ontologies like IfcOWL to address interoperability. However, the increasing complexity and diversity of construction information requirements demand automated enrichment of BIM ontologies, which is hindered by several factors, including complexity in ontology structure, scalability limitations, and domain-specific issues. Manual curation and maintenance of ontologies are labor-intensive and time-consuming, particularly as the scope of BIM projects expands. Despite these challenges, the construction industry lacks an effective automated approach for ontology concept enrichment. Thus, this study proposes a knowledge-enhanced ontology-to-vector (Keno2Vec) approach for automated BIM ontology concept enrichment, which can (1) encode ontology elements into meaningful and semantically rich embeddings by employing the BERT model to integrate both ontological information (names and labels) and external knowledge (definitions from authoritative knowledge bases), effectively addressing the domain expression specificity and complexity of BIM ontologies; and (2) provide a flexible framework that supports various downstream tasks of ontology concept enrichment by utilizing the resulting embeddings, thereby improving the task-specific adaptability and variability. Experimental results on datasets derived from the large-scale ifcOWL and two smaller BIM ontologies demonstrate that Keno2Vec significantly outperforms existing ontology embedding approaches in terms of accuracy and adaptability. For example, Keno2Vec achieves F1 scores on ifcOWL of nearly 87 \% for subsumption prediction, 60 \% for property identification, 95 \% for membership recognition, and 100 \% and 90 \% for category-based and schema-based concept classification, respectively. Additional analysis highlights the potential of Keno2Vec for improving BIM ontology encoding and benefiting downstream applications. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Journal of Industrial Information Integration},
	author = {Wei, Yinyi and Li, Xiao},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology, Natural language processing, Language model, Pre-trained language model, Semantics, Ontology concept enrichment, Ontology embedding, Semantic representation, Modeling languages, Embeddings, Building Information Modelling, Language processing, Natural languages, Ontology's, Natural language processing systems, Building information modeling ontology, Encoding (symbols), Ontology concepts},
	annote = {Type: Article}
}

@Article{white2023PromptPatternCatalog,
	file = {References/pdf/white2023PromptPatternCatalog.pdf},
	author = {Jules White and Quchen Fu and Sam Hays and Michael
                  Sandborn and Carlos Olea and Henry Gilbert and
                  Ashraf Elnashar and Jesse Spencer{-}Smith and
                  Douglas C. Schmidt},
	title = {A Prompt Pattern Catalog to Enhance Prompt
                  Engineering with ChatGPT},
	journal = {CoRR},
	year = 2023,
	volume = {abs/2302.11382},
	doi = {10.48550/ARXIV.2302.11382},
	eprint = {2302.11382},
	eprinttype = {arXiv},
	url = {https://doi.org/10.48550/arXiv.2302.11382},
	timestamp = {Sun, 19 Jan 2025 13:42:18 +0100},
	biburl = {https://dblp.org/rec/journals/corr/abs-2302-11382.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@Article{wilson2023ConceptualModelOntology,
	file = {References/pdf/wilson2023ConceptualModelOntology.pdf},
	author = {R. S. I. Wilson and Jeevani S. Goonetillake and
                  Anusha Indika Walisadeera and Athula Ginige},
	title = {A conceptual model for ontology quality assessment},
	journal = {Semantic Web},
	year = 2023,
	volume = 14,
	number = 6,
	pages = {1051-1097},
	doi = {10.3233/SW-233393},
	url = {https://doi.org/10.3233/SW-233393},
	timestamp = {Sun, 19 Jan 2025 14:56:42 +0100},
	biburl = {https://dblp.org/rec/journals/semweb/WilsonGWG23.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@Online{wolf2019HuggingfacesTransformersState,
	file = {References/pdf/wolf2019HuggingfacesTransformersState.pdf},
	author = {Thomas Wolf AND Lysandre Debut AND Victor Sanh AND
                  Julien Chaumond AND Clement Delangue AND Anthony Moi
                  AND Pierric Cistac AND Tim Rault AND Rémi Louf AND
                  Morgan Funtowicz AND Joe Davison AND Sam Shleifer
                  AND Patrick von Platen AND Clara Ma AND Yacine
                  Jernite AND Julien Plu AND Canwen Xu AND Teven Le
                  Scao AND Sylvain Gugger AND Mariama Drame AND
                  Quentin Lhoest AND Alexander M. Rush},
	title = {{HuggingFace's Transformers: State-of-the-art
                  Natural Language Processing}},
	year = 2019,
	eprint = {1910.03771v5},
	primaryclass = {cs.CL},
	archiveprefix = {arXiv}
}

@Article{wong2012OntologyLearningText,
	file = {References/pdf/wong2012OntologyLearningText.pdf},
	author = {Wilson Wong and Wei Liu and Mohammed Bennamoun},
	title = {Ontology learning from text: {A} look back and into
                  the future},
	journal = {{ACM} Comput. Surv.},
	year = 2012,
	volume = 44,
	number = 4,
	pages = {20:1--20:36},
	doi = {10.1145/2333112.2333115},
	url = {https://doi.org/10.1145/2333112.2333115},
	timestamp = {Mon, 26 Sep 2022 12:22:01 +0200},
	biburl = {https://dblp.org/rec/journals/csur/WongLB12.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{wu2023DoPlmsKnow,
	file = {References/pdf/wu2023DoPlmsKnow.pdf},
	title = {Do {PLMs} {Know} and {Understand} {Ontological} {Knowledge}?},
	volume = {1},
	url = {https://aclanthology.org/2023.acl-long.173/},
	doi = {10.18653/v1/2023.acl-long.173},
	abstract = {Ontological knowledge, which comprises classes and properties and their relationships, is integral to world knowledge. It is significant to explore whether Pretrained Language Models (PLMs) know and understand such knowledge. However, existing PLM-probing studies focus mainly on factual knowledge, lacking a system- atic probing of ontological knowledge. In this paper, we focus on probing whether PLMs store ontological knowledge and have a semantic un- derstanding of the knowledge rather than rote memorization of the surface form. To probe whether PLMs know ontological knowledge, we investigate how well PLMs memorize: (1) types of entities; (2) hierarchical relationships among classes and properties, e.g., Person is a subclass of Animal and Member of Sports Team is a subproperty of Member of ; (3) domain and range constraints of properties, e.g., the subject of Member of Sports Team should be a Person and the object should be a Sports Team. To further probe whether PLMs truly understand ontological knowledge beyond memorization, we comprehensively study whether they can reliably perform logical reasoning with given knowledge according to ontological entailment rules. Our probing results show that PLMs can memorize certain ontological knowledge and utilize implicit knowledge in reasoning. How- ever, both the memorizing and reasoning per- formances are less than perfect, indicating in- complete knowledge and understanding.},
	journal = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	author = {Wu, Weiqi and Jiang, Chengyue and Jiang, Yong and Xie, Pengjun and Tu, Kewei},
	editor = {Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki},
	month = jul,
	year = {2023},
	note = {Place: Toronto, Canada
Publisher: Association for Computational Linguistics
Section: 0},
	keywords = {Ontology, Language model, Semantics, Factual knowledge, Computational linguistics, Logical reasoning, Sports, Property, Implicit knowledge, Semantics understanding, Surface forms, World knowledge, Domain constraint, Range constraints},
	pages = {3080--3101},
	annote = {Type: Conference paper}
}

@article{wu2024OntologyExtensionBy,
	file = {References/pdf/wu2024OntologyExtensionBy.pdf},
	title = {Ontology extension by online clustering with large language model agents},
	volume = {7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206991474&doi=10.3389%2Ffdata.2024.1463543&partnerID=40&md5=4a013d00d9628be6b3bacdc7b5c1de48},
	doi = {10.3389/fdata.2024.1463543},
	abstract = {An ontology is a structured framework that categorizes entities, concepts, and relationships within a domain to facilitate shared understanding, and it is important in computational linguistics and knowledge representation. In this paper, we propose a novel framework to automatically extend an existing ontology from streaming data in a zero-shot manner. Specifically, the zero-shot ontology extension framework uses online and hierarchical clustering to integrate new knowledge into existing ontologies without substantial annotated data or domain-specific expertise. Focusing on the medical field, this approach leverages Large Language Models (LLMs) for two key tasks: Symptom Typing and Symptom Taxonomy among breast and bladder cancer survivors. Symptom Typing involves identifying and classifying medical symptoms from unstructured online patient forum data, while Symptom Taxonomy organizes and integrates these symptoms into an existing ontology. The combined use of online and hierarchical clustering enables real-time and structured categorization and integration of symptoms. The dual-phase model employs multiple LLMs to ensure accurate classification and seamless integration of new symptoms with minimal human oversight. The paper details the framework's development, experiments, quantitative analyses, and data visualizations, demonstrating its effectiveness in enhancing medical ontologies and advancing knowledge-based systems in healthcare. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Frontiers in Big Data},
	author = {Wu, Guanchen and Ling, Chen and Graetz, Ilana and Zhao, Liang},
	year = {2024},
	note = {Section: 0},
	annote = {Type: Article}
}

@article{wu2025TaxonomyInferenceTabular,
	file = {References/pdf/wu2025TaxonomyInferenceTabular.pdf},
	title = {Taxonomy {Inference} for {Tabular} {Data} {Using} {Large} {Language} {Models}},
	volume = {15718},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008012410&doi=10.1007%2F978-3-031-94575-5_22&partnerID=40&md5=59fb679fd3a86e06b779edbbdc66d3bd},
	doi = {10.1007/978-3-031-94575-5_22},
	abstract = {Taxonomy inference for tabular data is a critical task of schema inference, aiming at discovering entity types (i.e., concepts) of the tables and building their hierarchy. It can play an important role in data management, data exploration, ontology learning, and many data-centric applications. Existing schema inference systems focus more on XML, JSON or RDF data, and often rely on lexical formats and structures of the data for calculating similarities, with limited exploitation of the semantics of the text across a table. Motivated by recent works on taxonomy completion and construction using Large Language Models (LLMs), this paper presents two LLM-based methods for taxonomy inference for tables: (i) EmTT which embeds columns by fine-tuning with contrastive learning encoder-alone LLMs like BERT and utilises clustering for hierarchy construction, and (ii) GeTT which generates table entity types and their hierarchy by iterative prompting using a decoder-alone LLM like GPT-4. Extensive evaluation on three real-world datasets with six metrics covering different aspects of the output taxonomies has demonstrated that EmTT and GeTT can both produce taxonomies with strong consistency relative to the Ground Truth. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Wu, Zhenyu and Chen, Jiaoyan and Paton, Norman W.},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Semantics, Information management, Taxonomies, Data mining, Prompt learning, Computational linguistics, Data exploration, Tabular data, Learning systems, Critical tasks, Entity-types, Management data, Schema inference, Taxonomy inference},
	pages = {403 -- 422},
	annote = {Type: Conference paper}
}

@article{xiang2025GEtiIncorporating,
	file = {References/pdf/xiang2025GEtiIncorporating.pdf},
	title = {G-{ETI}: {Incorporating} {Graph} {Information} for {Improved} {Unsupervised} {Event} {Type} {Induction}},
	volume = {15437},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211910786&doi=10.1007%2F978-981-96-0567-5_31&partnerID=40&md5=978fdc6d4dfee4a7c17c2c5cf2e73151},
	doi = {10.1007/978-981-96-0567-5_31},
	abstract = {An event ontology is useful for the semantic integration of heterogeneous datasets related to events. To reduce manual efforts in event ontology construction, several Event-Type Induction (ETI) methods were proposed to automatically find new event types from a given data source. Existing ETI methods utilize a corpus-based data source, and achieve the ETI goal via document clustering over pre-trained neural text embeddings. Most of the ETI methods require a semi-supervised setting to obtain a satisfactory result. In this paper, we improve ETI performance by incorporating graph-based data sources, which usually consists of event nodes, participant subjects/objects and the relational edges. Our motivation is that event type information learned from an event graph can complement that learned from text. This idea leads to the Graph-ETI (G-ETI) algorithm, where event clusters are initially identified from text embeddings and later refined through graph-based label propagation. Our algorithm naturally supports the unsupervised ETI setting where no event types are known beforehand. Moreover, we also provide an LLM-based naming module to generate appropriate names for the new event clusters. In the experiment, our method exhibits better event clustering performance compared to existing baselines, especially in the unsupervised setting. These improved clustering assignments combined with our LLM naming module can lead to high-quality ETI capability, which facilitates the event ontology construction process. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Xiang, Lingzhi and Li, Qing and Li, Xiang and Diao, Xingchun},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology, Semantics, Event ontology, Embeddings, Ontology construction, Performance, Graph embeddings, Graph algorithms, Data-source, Event graphs, Event ontology construction, Event Types, Event-type induction, Induction method},
	pages = {443 -- 455},
	annote = {Type: Conference paper}
}

@article{xiang2025KnowledgeGraphBased,
	file = {References/pdf/xiang2025KnowledgeGraphBased.pdf},
	title = {A {Knowledge} {Graph}-{Based} {Approach} for {Construction} {Safety} {Hazards} {Management} and {Rectification} {Measures} {Intelligent} {Recommendation}},
	volume = {630},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000670719&doi=10.1007%2F978-3-031-84224-5_10&partnerID=40&md5=5fd09180629d082b432de3a2b2457b35},
	doi = {10.1007/978-3-031-84224-5_10},
	abstract = {Identification and rectification of safety hazards are crucial for the safety management of a construction site. However, the absence of structured knowledge necessitates a heavy reliance on experienced managers or experts for construction safety management. This dependence on manual formulation of rectification measures results in inefficient safety management and underutilization of data value. This study proposes a knowledge graph based approach for the safety hazards inspections and recommendation of rectification measures, which consists of four steps: (1) constructing the semantic expression framework of safety hazard ontology for information extraction; (2) extracting entities from textual and semi-structured data using a large language model (ChatGLM-6B); (3) knowledge fusion and inference; (4) storing structured knowledge and developing semantic retrieval and safety hazard rectification measures recommendation. The proposed method was validated in a hydropower project, where a knowledge graph of safety hazards was constructed, consisting of 108,000 entities and 121 relationships. The results demonstrate that this method can automatically provide targeted rectification measures for safety hazards such as fire, falls from heights, scaffold collapse and electric shock. This work can provide a practical reference for improving the effectiveness of the construction project safety management. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Civil Engineering},
	author = {Xiang, Yunfei and Lin, Peng and Luo, Yiming and Xu, Houlei and Ning, Zeyu and Qiao, Yu and Zhou, Mengxia},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Project management, Semantics, Information management, Construction safety, Safety management, Graph-based, Structured knowledge, Scaffolds, Construction sites, Data values, Hazard management, Intelligent recommendation, Safety hazards},
	pages = {133 -- 141},
	annote = {Type: Conference paper}
}

@article{xie2024OntologyEmbeddingsSubsumption,
	file = {References/pdf/xie2024OntologyEmbeddingsSubsumption.pdf},
	title = {Ontology {Embeddings} for {Subsumption} {Prediction} {Based} on {Graph} {Language} {Model}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007428875&doi=10.1109%2FDSInS64146.2024.10992171&partnerID=40&md5=2b1f28e91fc4db4db48fd3da725f8872},
	doi = {10.1109/DSInS64146.2024.10992171},
	abstract = {With the growing importance of knowledge graphs in artificial intelligence, accurately modeling hierarchical relationships in ontologies has become a critical issue in knowledge representation learning. To address this, this paper proposes an ontology embedding framework based on graph language models, named GLMSubs, aimed at enhancing the prediction of subclass relationships. The GLMSubs framework adopts a two-stage strategy of “multi-semantic view partitioning” and “advanced training of graph language models”. Initially, it deconstructs the ontology's concepts, attributes, and instance information into five types of semantic views, such as class hierarchy view and class-attribute relationship view, through a multi-view partitioning mechanism, comprehensively capturing information from different semantic dimensions. Subsequently, the framework employs graph language models for joint training on the multi-view data to obtain embeddings that integrate both semantic and structural information. Experiments on datasets such as FoodOn and GO validate the effectiveness of GLMSubs, demonstrating that its performance in class hierarchy relationship prediction tasks significantly surpasses existing methods.},
	journal = {2024 4th International Conference on Digital Society and Intelligent Systems (DSInS)},
	author = {Xie, Jiangcun and Li, Ren and Yang, Jianxi and Xiao, Qiao},
	month = nov,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Knowledge graphs, Knowledge graph, Language model, Semantics, OWL ontology, OWL, Resource description framework, knowledge graph, Embeddings, Knowledge representation learning, Training, Proteins, Biological system modeling, Predictive models, Medical services, graph language models, knowledge representation learning, Ontology's, Knowledge-representation, Image representation, Graph languages, OWL ontologies, Graph language model, Semantic views},
	pages = {133--137},
	annote = {Type: Conference paper {\textbar} RAYYAN-LABELS: Good for referencing}
}

@article{xilong2025LeveragingLargeLanguage,
	file = {References/pdf/xilong2025LeveragingLargeLanguage.pdf},
	title = {Leveraging large language models for classification of cultural heritage domain terms: {A} case study on {CIDOC} {CRM}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001112222&doi=10.1145%2F3677389.3702562&partnerID=40&md5=1bdc8619fb50a59d64cd1ccdbdf3d972},
	doi = {10.1145/3677389.3702562},
	abstract = {Large language models (LLMs) have recently revolutionized human language understanding and generation. Ontology is considered one of the primary cornerstones for representing knowledge in a more meaningful way on the semantic web. It s significant to explore whether LLMs know and understand such ontological knowledge. In this paper, we report an experiment to investigate the performance of LLMs in the task of classifying cultural heritage domain terms to upper-level ontology. We first probed the understanding and memorization of CIDOC CRM ontological knowledge by LLMs. Then, we further leverage LLMs to classify domain terms into the structure of CRM, and compare the match type with experts. Our initial findings indicate that LLMs demonstrate a certain level of awareness and comprehension of CIDOC CRM ontological knowledge. LLMs have shown potential as valuable assistants in enhancing ontology engineering and knowledge-intensive tasks. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Proceedings of the ACM/IEEE Joint Conference on Digital Libraries},
	author = {Xilong, Hou and Junhan, Zang and Wang, Xiaoguang},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Semantics, Language understanding, History, CIDOC CRM, Domain Knowledge, Ontology's, Classification (of information), Economic and social effects, Human language, Case-studies, Cultural heritages, Ontological knowledge probing, Term classification},
	annote = {Type: Conference paper}
}

@article{xiong2025EnhancingPatentMatching,
	file = {References/pdf/xiong2025EnhancingPatentMatching.pdf},
	series = {{SIGIR} '25},
	title = {Enhancing the {Patent} {Matching} {Capability} of {Large} {Language} {Models} via the {Memory} {Graph}},
	url = {https://doi.org/10.1145/3726302.3729970},
	doi = {10.1145/3726302.3729970},
	abstract = {Intellectual Property (IP) management involves strategically protecting and utilizing intellectual assets to enhance organizational innovation, competitiveness, and value creation. Patent matching is a crucial task in intellectual property management, which facilitates the organization and utilization of patents. Existing models often rely on the emergent capabilities of Large Language Models (LLMs) and leverage them to identify related patents directly. However, these methods usually depend on matching keywords and overlook the hierarchical classification and categorical relationships of patents. In this paper, we propose MemGraph, a method that augments the patent matching capabilities of LLMs by incorporating a memory graph derived from their parametric memory. Specifically, MemGraph prompts LLMs to traverse their memory to identify relevant entities within patents, followed by attributing these entities to corresponding ontologies. After traversing the memory graph, we utilize extracted entities and ontologies to improve the capability of LLM in comprehending the semantics of patents. Experimental results on the PatentMatch dataset demonstrate the effectiveness of MemGraph, achieving a 17.68\% performance improvement over baseline LLMs. The further analysis highlights the generalization ability of MemGraph across various LLMs, both in-domain and out-of-domain, and its capacity to enhance the internal reasoning processes of LLMs during patent matching. All data and codes are available at https://github.com/NEUIR/MemGraph.},
	journal = {Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	author = {Xiong, Qiushi and Xu, Zhipeng and Liu, Zhenghao and Wang, Mengjia and Chen, Zulong and Sun, Yue and Gu, Yu and Li, Xiaohua and Yu, Ge},
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Large language model, Ontology, Language model, Semantics, large language models, Retrieval-augmented generation, retrieval-augmented generation, memory graph, patent matching, Ontology's, Copyrights, Intellectual assets, Intellectual property management, Matchings, Memory graph, Organizational innovation, Patent matching, Patents and inventions},
	pages = {337--347},
	annote = {event-place: Padua, Italy}
}

@article{yang2024LlmSupportedApproach,
	file = {References/pdf/yang2024LlmSupportedApproach.pdf},
	title = {An {LLM} supported approach to ontology and knowledge graph construction},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217280910&doi=10.1109%2FBIBM62325.2024.10822222&partnerID=40&md5=5fb25a53e38880819cbef3caab99f1a6},
	doi = {10.1109/BIBM62325.2024.10822222},
	abstract = {The continuous development in the medical field faces multiple challenges in managing a large amount of literature and research results using traditional ontology and knowledge graph construction methods. These challenges include high labor costs, limited coverage, and poor dynamism of traditional ontology and knowledge graph construction methods. Large language models (LLMs) can solve various natural language processing tasks and can understand and generate human-like natural language, which makes automated construction of ontology expansion and knowledge graphs (KGs) possible. This paper proposes an ontology expansion method based on LLMs, using LLMs to formulate competency questions (CQs) to extend the initial ontology, and then constructing the knowledge graph based on the extended ontology. We demonstrated the feasibility of the method by creating a knowledge graph for breast cancer treatment. The combination of LLMs-based medical ontology and knowledge graph can achieve more efficient medical knowledge management and application, promoting the informatization and intelligent development of the medical field.},
	journal = {2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
	author = {Yang, Hang and Xiao, Liang and Zhu, Rujun and Liu, Ziji and Chen, Jianxia},
	month = dec,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Knowledge graphs, Knowledge graph, Large language model, Ontology, LLM, Natural language processing, Language model, Large language models, Semantic Web, Reliability, Usability, Medical knowledge, Iterative methods, Natural languages, Refining, Medical services, Breast cancer treatment, Ontology's, Natural language processing systems, Ontology graphs, Graphitization, Graph-construction method, Medical fields, Wages},
	pages = {5240--5246},
	annote = {ISSN: 2156-1133}
}

@article{yang2025KnowledgeGraphBased,
	keywords = {Cannot download},
	title = {Knowledge graph-based dual-modal collaborative {QA} framework for hydropower operation and maintenance},
	volume = {2025},
	doi = {10.1049/icp.2025.2348},
	abstract = {Maintenance of hydropower equipment is essential for ensuring a reliable supply of renewable energy. However, in practical maintenance operations, technicians rely heavily on personal experience and extensive domain manuals, which can reduce the accuracy and efficiency of decision-making processes. This paper proposes a knowledge graph-based dual-modal collaborative QA (KGD-QA) framework for hydropower operation and maintenance. Firstly, a multi-granularity segmentation strategy is used to divide domain manuals into thematically grouped text blocks and path-labeled sentence units. Secondly, a LoRA-fine-tuned large language model (LLM), guided by domain ontologies and chain-of-thought prompts, extracts entity-relation triples. Finally, a dual-modal QA mechanism is designed to integrate knowledge graph subgraph queries and text vector retrieval, enabling information acquisition in both detailed and global modes. Experimental results show that, compared with baseline model, this approach improves the accuracy of knowledge extraction while the dual-modal collaborative QA retrieval method provides more traceable and evidence-backed responses to maintenance-related queries. This framework offers a novel paradigm for advancing intelligent operation and maintenance technologies for hydropower equipment.},
	journal = {15th Prognostics and System Health Management Conference (PHM 2025)},
	author = {Yang, Ye and Duan, Ran and Yi, Xinyang and Ma, Qicheng and Liu, Jie and Hu, Zhongxu and Hu, Youmin},
	month = jun,
	year = {2025},
	note = {Section: 0},
	pages = {152--157},
	annote = {RAYYAN-LABELS: ontology-supported application}
}

@article{yao2025KnowledgeGraphConstruction,
	file = {References/pdf/yao2025KnowledgeGraphConstruction.pdf},
	title = {From knowledge graph construction to retrieval-augmented generation: a framework for comprehensive earthquake emergency support},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009902479&doi=10.1080%2F10095020.2025.2514813&partnerID=40&md5=0c9769723dc40c230bc7a317e19a3a0e},
	doi = {10.1080/10095020.2025.2514813},
	abstract = {Effective decision-making during earthquake emergencies requires rapid access to accurate, structured, and context-specific knowledge. However, existing knowledge resources in this domain are fragmented, heterogeneous, and largely unstructured, causing decision-makers to rely heavily on intuition or scattered textual materials, which often results in delayed, inconsistent, or suboptimal emergency responses. To address these challenges, this study proposes a structured framework integrating large language models (LLMs) with knowledge representation techniques to systematically construct domain-specific knowledge graphs (KGs) tailored explicitly for earthquake emergency scenarios. The framework comprises three primary stages: (1) developing an ontology that encompasses the complete earthquake emergency management cycle–prevention, preparedness, response, and recovery–as well as earthquake-specific measures, models, terminology, and attributes; (2) guiding LLMs with structured prompts to extract entities, relationships, and attributes from unstructured data; and (3) employing a knowledge fusion strategy to resolve ambiguities and consolidate information across the graph. From a corpus of 2682 professional documents, including emergency plans, technical standards, and specialized books, the framework extracted 284,801 entities and over 80,000 unique relationship types, subsequently consolidated into approximately 1000 meaningful categories. The final KG, refined through entity fusion and clustering, comprises over 268,000 nodes and 833,000 relationships. To effectively utilize the constructed KG, we developed an Improved Hybrid Retrieval-Augmented Generation (HybridRAG) application framework, integrating symbolic retrieval from the KG with semantic similarity-based retrieval from a vector database. This dual retrieval approach enables LLMs to generate responses that are both semantically coherent and deeply grounded in operational knowledge. Comparative experiments conducted on a newly constructed dataset of 150 earthquake-specific questions demonstrated that the Improved HybridRAG method significantly outperforms standard methods–including LLM-only, semantic vector-based retrieval, and purely symbolic retrieval–in accuracy, clarity, comprehensiveness, conciseness, and relevance. These findings validate the advantage of combining structured and semantic knowledge retrieval, illustrating the framework’s capability to provide reliable, contextually aligned, and actionable insights for decision-makers in earthquake emergency scenarios. Future work will focus on improving attribute completeness, refining entity alignment techniques to capture complex semantic nuances, and exploring multimodal data integration to further extend the KG’s utility. This study underscores the potential of systematically combining structured KGs and LLMs to significantly enhance decision-making capabilities in disaster management contexts. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Geo-Spatial Information Science},
	author = {Yao, Liwei and Ren, Fu and Du, Kaixuan and Du, Qingyun},
	year = {2025},
	note = {Section: 0},
	annote = {Type: Article}
}

@article{ye2022OntologyEnhancedPrompt,
	file = {References/pdf/ye2022OntologyEnhancedPrompt.pdf},
	series = {{WWW} '22},
	title = {Ontology-enhanced {Prompt}-tuning for {Few}-shot {Learning}},
	url = {https://doi.org/10.1145/3485447.3511921},
	doi = {10.1145/3485447.3511921},
	abstract = {Few-shot Learning (FSL) is aimed to make predictions based on a limited number of samples. Structured data such as knowledge graphs and ontology libraries has been leveraged to benefit the few-shot setting in various tasks. However, the priors adopted by the existing methods suffer from challenging knowledge missing, knowledge noise, and knowledge heterogeneity, which hinder the performance for few-shot learning. In this study, we explore knowledge injection for FSL with pre-trained language models and propose ontology-enhanced prompt-tuning (OntoPrompt). Specifically, we develop the ontology transformation based on the external knowledge graph to address the knowledge missing issue, which fulfills and converts structure knowledge to text. We further introduce span-sensitive knowledge injection via a visible matrix to select informative knowledge to handle the knowledge noise issue. To bridge the gap between knowledge and text, we propose a collective training algorithm to optimize representations jointly. We evaluate our proposed OntoPrompt in three tasks, including relation extraction, event extraction, and knowledge graph completion, with eight datasets. Experimental results demonstrate that our approach can obtain better few-shot performance than baselines.},
	journal = {Proceedings of the ACM Web Conference 2022},
	author = {Ye, Hongbin and Zhang, Ningyu and Deng, Shumin and Chen, Xiang and Chen, Hui and Xiong, Feiyu and Chen, Xi and Chen, Huajun},
	year = {2022},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Relation extraction, Few-shot Learning, Knowledge management, Knowledge graph completion, Performance, Event Extraction, Extraction, Few-shot learning, Relation Extraction, Prompt-tuning, Knowledge Graph Completion, Ontology's, Events extractions, Prediction-based, Number of samples},
	pages = {778--787},
	annote = {event-place: Virtual Event, Lyon, France {\textbar} RAYYAN-LABELS: ontology-supported application}
}

@article{yhdego2025AutomatedOntologyGeneration,
	file = {References/pdf/yhdego2025AutomatedOntologyGeneration.pdf},
	title = {Automated {Ontology} {Generation} for {Zero}-shot {Defect} {Identification} in {Manufacturing}},
	issn = {1558-3783},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217032682&doi=10.1109%2FTASE.2025.3537463&partnerID=40&md5=e5ab810de0ed81cdcfa98e466137c161},
	doi = {10.1109/TASE.2025.3537463},
	abstract = {A lack of labeled data presents a significant challenge to automatic defect identification in manufacturing, which is a crucial step in process control and certification during process development. State-of-the-art transfer learning is incapable of handling such zero-shot learning (ZSL) when defect labels are absent in training datasets. The latest research on ZSL leverages natural language processing (NLP) based on large language models (LLM) and shows promise by supplementing information to generate labels. However, its performance is hampered by the supporting LLMs pre-trained on generic vocabulary that failed to characterize manufacturing defects accurately. This paper establishes a methodology to automatically extract multi-level attributes from literature to improve defect representation, thereby facilitating ZSL. The extracted attributes contribute to a hierarchical knowledge graph, called defect ontology, to characterize multiple aspects of manufacturing defects. The proposed algorithm takes the defect images and associated text from the literature as input and develops an unsupervised method to identify the hierarchical relationships among the tokenized information extracted from the input text-feature corpora. The hierarchical graph is refined to retain the most relevant information by a pruning algorithm based on a minimum path search. A walk algorithm, along with NLP, parsed the generated ontology to create embedding of defects to enable zero-shot attribute learning to identify defects. The proposed method advances the ZSL methodology by automatically creating a hierarchical knowledge representation from literature and images to replace generic vocabulary in LLM adopted by ZSL algorithms, thus improving defect representation. The case studies are among the earlier attempts to demonstrate the feasibility of using literature data from public sources to extract attributes automatically to identify defects in a real additive manufacturing process based on direct-ink-writing.},
	journal = {IEEE Transactions on Automation Science and Engineering},
	author = {Yhdego, Tsegai O. and Wang, Hui},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Knowledge graph, Ontology, Language model, Automation, Manufacturing, Certification, Vocabulary, Data mining, Smart manufacturing, Ontology generation, Transfer learning, Graph embeddings, Self-supervised learning, Semi-supervised learning, Process control, Unsupervised learning, Zero-shot learning, Accuracy, Language processing, Natural languages, Zero shot learning, defect identification, manufacturing automation, self-supervised learning, Ontology's, Natural language processing systems, Labeled data, Network security, Manufacturing data processing, Manufacturing Automation, Defect identification, Gluing, Hierarchical knowledge, Manufacturing defects},
	pages = {1--1},
	annote = {Type: Article}
}

@article{yorsh2022TextOntologyMapping,
	file = {References/pdf/yorsh2022TextOntologyMapping.pdf},
	title = {Text-to-{Ontology} {Mapping} via {Natural} {Language} {Processing} {Models}},
	volume = {3226},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139875540&partnerID=40&md5=6da54e850bc7b9fa8ff112f3ca724e7b},
	abstract = {The paper presents work in progress attempting to solve a text-to-ontology mapping problem. While ontologies are being created as formal specifications of shared conceptualizations of application domains, different users often create different ontologies to represent the same domain. For better reasoning about concepts in scientific papers, it is desired to pick the ontology which best matches concepts present in the input text. We have started to automatize this process and attack the problem by utilizing state-of-the-art NLP tools and neural networks. Given a specific set of ontologies, we experiment with different training pipelines for NLP machine learning models with the aim to construct representative embeddings for the text-to-ontology matching task. We assess the final result through visualizing the latent space and exploring the mappings between an input text and ontology classes. © 2022 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Yorsh, Uladzislau and Behr, Alexander S. and Kockmann, Norbert and Holeňa, Martin},
	year = {2022},
	note = {Section: 0},
	keywords = {Ontology, Language model, Ontology mapping, BERT, Mapping, Text analysis, Language processing, Natural languages, Ontology's, Natural language processing systems, Learning algorithms, Matchings, Fasttext, Matching text to ontology},
	pages = {28 -- 34},
	annote = {Type: Conference paper}
}

@article{zaitoun2023OntoevalAutomatedOntology,
	file = {References/pdf/zaitoun2023OntoevalAutomatedOntology.pdf},
	series = {{WWW} '23 {Companion}},
	title = {{OntoEval}: an {Automated} {Ontology} {Evaluation} {System}},
	url = {https://doi.org/10.1145/3543873.3587318},
	doi = {10.1145/3543873.3587318},
	abstract = {Developing semantically-aware web services requires comprehensive and accurate ontologies. Evaluating an existing ontology or adapting it is a labor-intensive and complex task for which no automated tools exist. Nevertheless, in this paper we propose a tool that aims at making this vision come true, i.e., we present a tool for the automated evaluation of ontologies that allows one to rapidly assess an ontology’s coverage of a domain and identify specific problems in the ontology’s structure. The tool evaluates the domain coverage and correctness of parent-child relations of a given ontology based on domain information derived from a text corpus representing the domain. The tool provides both overall statistics and detailed analysis of sub-graphs of the ontology. In the demo, we show how these features can be used for the iterative improvement of an ontology.},
	journal = {Companion Proceedings of the ACM Web Conference 2023},
	author = {Zaitoun, Antonio and Sagi, Tomer and Hose, Katja},
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {BERT, natural language processing, ontology, knowledge engineering},
	pages = {82--85},
	annote = {event-place: Austin, TX, USA}
}

@InProceedings{zeginis2024ApplyingOntologyAware,
	file = {References/pdf/zeginis2024ApplyingOntologyAware.pdf},
	author = {Zeginis, Dimitris and Kalampokis, Evangelos and
                  Tarabanis, Konstantinos},
	title = {Applying an ontology-aware zero-shot LLM prompting
                  approach for information extraction in Greek: the
                  case of DIAVGEIA gov gr},
	year = 2024,
	booktitle = {Proceedings of the 28th Pan-Hellenic Conference on
                  Progress in Computing and Informatics},
	series = {PCI 2024},
	publisher = {ACM},
	month = dec,
	pages = {324–330},
	doi = {10.1145/3716554.3716603},
	url = {http://dx.doi.org/10.1145/3716554.3716603},
	collection = {PCI 2024}
}

@article{zeginis2025ApplyingOntologyAware,
	file = {References/pdf/zeginis2025ApplyingOntologyAware.pdf},
	series = {{PCI} '24},
	title = {Applying an ontology-aware zero-shot {LLM} prompting approach for information extraction in {Greek}: the case of {DIAVGEIA} gov gr},
	url = {https://doi.org/10.1145/3716554.3716603},
	doi = {10.1145/3716554.3716603},
	abstract = {Large Language Models (LLMs) have attracted considerable attention, primarily due to their potential to revolutionize sectors that heavily rely on textual information. Governance is one such sector. Public administrations around the globe produce millions of documents including laws, administrative decisions and acts (e.g., travel/budget approvals) that contain valuable information in unstructured way. The documents are usually stored at document-centered repositories. As a result the actual data of the documents cannot be further searched or processed. The availability of structured metadata of the documents (e.g., who has traveled, where, when) could further enhance the searching and processing of the documents as well as enable data analytics. The construction of metadata can be done through information extraction approaches such as Named Entity Recognition (NER), Relation Extraction (RE) and Event Extraction (EE) on the documents. LLMs are recently used successfully for information extraction tasks, while ontologies are traditionally used for meaningful data modeling. The aim of the paper is to apply and evaluate an ontology-aware zero-shot LLM prompting approach for information extraction in Greek language documents available in DIAVGEIA.gov.gr - the Greek Open Government portal for administrative documents. The evaluation assesses various LLM models/sizes for various difficulties of information extraction tasks. Overall the results are very promising, since most LLM models, even smaller ones, performed very well for all tasks in Greek.},
	journal = {Proceedings of the 28th Pan-Hellenic Conference on Progress in Computing and Informatics},
	author = {Zeginis, Dimitris and Kalampokis, Evangelos and Tarabanis, Konstantinos},
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Information extraction, Large language model, Ontology, LLM, Language model, Named entity recognition, Relation extraction, Modeling languages, Information retrieval, Metadata, Data mining, Public administration, Data analytics, NER, Greek, Ontology's, Information retrieval systems, Structured metadatas, Textual information},
	pages = {324--330},
	annote = {Type: Conference paper}
}

@article{zeng2024Xlore3Large,
	file = {References/pdf/zeng2024Xlore3Large.pdf},
	title = {{XLORE} 3: {A} {Large}-{Scale} {Multilingual} {Knowledge} {Graph} from {Heterogeneous} {Wiki} {Knowledge} {Resources}},
	volume = {42},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/3660521},
	doi = {10.1145/3660521},
	abstract = {In recent years, knowledge graph (KG) has attracted significant attention from academia and industry, resulting in the development of numerous technologies for KG construction, completion, and application. XLORE is one of the largest multilingual KGs built from Baidu Baike and Wikipedia via a series of knowledge modeling and acquisition methods. In this article, we utilize systematic methods to improve XLORE's data quality and present its latest version, XLORE 3, which enables the effective integration and management of heterogeneous knowledge from diverse resources. Compared with previous versions, XLORE 3 has three major advantages: (1) We design a comprehensive and reasonable schema, namely XLORE ontology, which can effectively organize and manage entities from various resources. (2) We merge equivalent entities in different languages to facilitate knowledge sharing. We provide a large-scale entity linking system to establish the associations between unstructured text and structured KG. (3) We design a multi-strategy knowledge completion framework, which leverages pre-trained language models and vast amounts of unstructured text to discover missing and new facts. The resulting KG contains 446 concepts, 2,608 properties, 66 million entities, and more than 2 billion facts. It is available and downloadable online at , providing a valuable resource for researchers and practitioners in various fields.},
	number = {6},
	journal = {ACM Trans. Inf. Syst.},
	author = {Zeng, Kaisheng and Jin, Hailong and Lv, Xin and Zhu, Fangwei and Hou, Lei and Zhang, Yi and Pang, Fan and Qi, Yu and Liu, Dingxiao and Li, Juanzi and Feng, Ling},
	month = aug,
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, knowledge management, Knowledge fusion, Schema construction, Entity alignment, Entity linking, entity linking, Knowledge resource, Entity typing, entity alignment, entity typing, knowledge completion, knowledge fusion, schema construction, Large-scales, Unstructured texts, Knowledge completion},
	annote = {Place: New York, NY, USA Publisher: Association for Computing Machinery}
}

@article{zengeya2025AttentionBasedDeep,
	file = {References/pdf/zengeya2025AttentionBasedDeep.pdf},
	title = {An {Attention}-{Based} {Deep} {Learning} {Model} for {Term} {Extraction} from {Text} {Using} {BERT}},
	volume = {632},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013199652&doi=10.1007%2F978-3-031-94439-0_6&partnerID=40&md5=6179d97728d4ea73b61714699c6d9ce6},
	doi = {10.1007/978-3-031-94439-0_6},
	abstract = {Extracting terms from text is relevant in many applications such as document summarizing, question answering, ontology learning and many more. However, the unstructured nature of textual data poses significant hurdles that make the automatic extraction of terms from text a challenging task. Furthermore, while significant research efforts have been dedicated to term extraction from textual data, the incorporation of domain knowledge and context awareness as a way of enriching the extracted terms remains a challenge. To tackle these challenges, this study proposes an attention-based Deep Learning model for term extraction from text using the Bidirectional Encoder Representations from Transformers (BERT) language model. The model uses (1) web scraping for term extraction from web pages, (2) BERT encoder for enriching term extraction through contextualization and cosine similarity to extract domain-specific terms and (3) WordNet for adding knowledge context and disambiguation through vocabulary labeling. The proposed system was applied to five different data samples from the horticulture domain and was evaluated with various metrics including accuracy, precision, and F1-score. The experimental results indicate that the proposed model improves the domain-specific term extraction and vocabulary labeling with an accuracy of 73\%, a precision of 89\%, a recall of 79\%, as well as F1-Score of 84\%, better than the related studies. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
	author = {Zengeya, Tsitsi and Fonou-Dombeu, Jean Vincent and Gwetu, Mandlenkosi Victor},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology, Deep learning, Term extraction, Intelligent systems, Textual data, Wordnet, Extraction, Bidirectional encoder representation from transformer, Learning systems, Text processing, Domain Knowledge, Natural language processing systems, Signal encoding, F1 scores, Domain specific, Learning models, Labelings, Cosine similarity measures, Vocabulary building, Websites},
	pages = {87 -- 102},
	annote = {Type: Conference paper}
}

@article{zhang2024LargeLanguageModel,
	file = {References/pdf/zhang2024LargeLanguageModel.pdf},
	title = {Large {Language} {Model} {Assisted} {Multi}-{Agent} {Dialogue} for {Ontology} {Alignment}},
	volume = {2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192997204&partnerID=40&md5=5a51d0a74903a3408ce05f2f077d62e6},
	abstract = {Ontology alignment is critical in cross-domain integration; however, it typically necessitates the involvement of a human domain-expert, which can make the task costly. Although a variety of machine-learning approaches have been proposed that can simplify this task by learning the patterns from experts, such techniques are still susceptible to domain knowledge updates that could potentially change the patterns and lead to extra expert involvement. The use of Large Language Models (LLMs) has demonstrated a general cognitive ability, which has the potential to assist ontology alignment from the cognition level, thus obviating the need for costly expert involvement. However, the process by which the output of LLMs is generated can be opaque and thus the reliability and interpretability of such models is not always predictable. This paper proposes a dialogue model, in which multiple agents negotiate the correspondence between two knowledge sets with the support from an LLM. We demonstrate that this approach not only reduces the need for the involvement of a domain expert for ontology alignment, but that the results are interpretable despite the use of LLMs. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
	author = {Zhang, Shiyao and Dong, Yuji and Zhang, Yichuan and Payne, Terry R. and Zhang, Jie},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Ontology alignment, Computational linguistics, Cross-domain, Autonomous agents, Multi agent systems, Learning systems, Domain Knowledge, Multi agent, Domain experts, Human domain, Dialog, Machine learning approaches, Negotiation},
	pages = {2594 -- 2596},
	annote = {Type: Conference paper}
}

@article{zhang2025ConstructionApplicationKnowledge,
	file = {References/pdf/zhang2025ConstructionApplicationKnowledge.pdf},
	title = {Construction and application of knowledge graph for flood defense and rescue of water infrastructure},
	volume = {56},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003194264&doi=10.13243%2Fj.cnki.slxb.20240268&partnerID=40&md5=adcb1bd8c0ce18aa28812655424bec12},
	doi = {10.13243/j.cnki.slxb.20240268},
	abstract = {The knowledge platform is an important component in digital twin of water conservancy. However, water conservancy knowledge is dispersed across multi —source texts, which exhibit obvious unstructured and frag-mented characteristics, and knowledge extraction and effective utilization face challenges. To addresses the issues of low data quality and underutilization of knowledge in the field, this study focuses on the texts of flood defense and emergency rescue, and proposes an intelligent method for constructing a flood defense and emergency rescue knowdedge graph by improving the knowledge extraction model and combining unstructured data and external semi-structured data. Initially, a large language model is employed to extract term from unstructured texts and construct an ontology model based on term themes, a pretraining module is used to enhance text representation features, and a convolutional module is introduced to improve the entity knowdedge extraction model, and an entity data enhance-ment method is proposed to improve model accuracy. Then external encyclopedia data is extracted to expand the knowdedge coverage to build a complete flood defense and rescue knowledge graph. Experimental results demonstrate that the proposed model achieves an Fl score of 89.91\% in entity knowdedge extraction, significantly outperforming baseline models. Finally, the application method of knowdedge graph in the field of flood defense and rescue is introduced, which can form a knowdedge engine for digital twin of water conservancy construction, providing knowledge support for flood control research and decision-making. © 2025 Elsevier B.V., All rights reserved.},
	number = {3},
	journal = {Shuili Xuebao/Journal of Hydraulic Engineering},
	author = {Zhang, Dongliang and Zhou, Wei and Ma, Gang and Wang, Xudong and Liu, Yu and Wang, Xiaomao},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Knowledge extraction, Emergency rescue, Multi-Sources, Extraction modeling, Flood control, Flood defence, Flood defense and rescue, Multi—source data, Source data, Water conservancy, Cannot find},
	pages = {341 -- 353},
	annote = {Type: Article}
}

@article{zhang2025NovelDualStrategy,
	file = {References/pdf/zhang2025NovelDualStrategy.pdf},
	title = {A {Novel} {Dual}-{Strategy} {Approach} for {Constructing} {Knowledge} {Graphs} in the {Home} {Appliance} {Fault} {Domain}},
	volume = {18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014352969&doi=10.3390%2Fa18080485&partnerID=40&md5=2f3d9626ee0b08b84c8e0aa9e2c7f935},
	doi = {10.3390/a18080485},
	abstract = {Knowledge graph technology holds significant importance for efficient fault diagnosis in household appliances. However, the scarcity of public fault diagnosis data and the lack of automated knowledge extraction pose major challenges to knowledge graph construction. To address issues such as ambiguous entity boundaries, severe entity nesting, and poor entity extraction performance in fault diagnosis texts, this paper proposes a dual-strategy progressive knowledge extraction framework. First, to tackle the high complexity of fault diagnosis texts, an entity recognition model named RoBERTa-zh-BiLSTM-MUL-CRF is designed, improving the accuracy of nested entity extraction. Second, leveraging the semantic understanding capability of large language models, a progressive prompting strategy is adopted for ontology alignment and relation extraction, achieving automated knowledge extraction. Experimental results show that the proposed named entity recognition model outperforms traditional models, with improvements of 3.87\%, 5.82\%, and 2.05\% in F1-score, recall, and precision, respectively. Additionally, the large language model demonstrates better performance in ontology alignment compared to traditional machine learning models. The constructed knowledge graph for household appliance fault diagnosis integrates structured fault diagnosis information. It effectively processes unstructured fault texts and supports visual queries and entity tracing. This framework can assist maintenance personnel in making rapid judgments, thereby improving fault diagnosis efficiency. © 2025 Elsevier B.V., All rights reserved.},
	number = {8},
	journal = {Algorithms},
	author = {Zhang, Daokun and Zhang, Jian and Jia, Yanhe and Liao, Mengjie},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Named entity recognition, Relationship extraction, Semantics, Knowledge extraction, Knowledge management, Failure analysis, Performance, Graph theory, Extraction, Fault detection, Learning systems, Domestic appliances, Entity extractions, Faults diagnosis, Home appliance fault},
	annote = {Type: Article}
}

@article{zhang2025OntochatFrameworkConversational,
	file = {References/pdf/zhang2025OntochatFrameworkConversational.pdf},
	title = {{OntoChat}: {A} {Framework} for {Conversational} {Ontology} {Engineering} {Using} {Language} {Models}},
	volume = {15344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218459527&doi=10.1007%2F978-3-031-78952-6_10&partnerID=40&md5=77776a3fa6293cb8bdfb5f1e88063c21},
	doi = {10.1007/978-3-031-78952-6_10},
	abstract = {Ontology engineering (OE) in large projects poses a number of challenges arising from the heterogeneous backgrounds of the various stakeholders, domain experts, and their complex interactions with ontology designers. This multi-party interaction often creates systematic ambiguities and biases from the elicitation of ontology requirements, which directly affect the design, evaluation and may jeopardise the target reuse. Meanwhile, current OE methodologies strongly rely on manual activities (e.g., interviews, discussion pages). After collecting evidence on the most crucial OE activities, we introduce OntoChat, a framework for conversational ontology engineering that supports requirement elicitation, analysis, and testing. By interacting with a conversational agent, users can steer the creation of user stories and the extraction of competency questions, while receiving computational support to analyse the overall requirements and test early versions of the resulting ontologies. We evaluate OntoChat by replicating the engineering of the Music Meta Ontology, and collecting preliminary metrics on the effectiveness of each component from users. We release all code at https://github.com/King-s-Knowledge-Graph-Lab/OntoChat. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Zhang, Bohui and Carriero, Valentina Anita and Schreiberhuber, Katrin and Tsaneva, Stefani and González, Lucía Sánchez and Kim, Jongmo and de Berardinis, Jacopo},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, Competency question, Requirements engineering, Design evaluation, Chatbots, Ontology's, Domain experts, Computational creativities, Large programs, Multiparty interaction},
	pages = {102 -- 121},
	annote = {Type: Conference paper}
}

@Article{zhao2023SurveyLargeLanguage,
	file = {References/pdf/zhao2023SurveyLargeLanguage.pdf},
	title = {A survey of large language models},
	author = {Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
	journal = {arXiv preprint arXiv:2303.18223},
	volume = {1},
	number = {2},
	year = {2023}
}

@Online{zheng2023WhenAeHelpful,
	file = {References/pdf/zheng2023WhenAeHelpful.pdf},
	author = {Mingqian Zheng AND Jiaxin Pei AND Lajanugen
                  Logeswaran AND Moontae Lee AND David Jurgens},
	title = {{When "A Helpful Assistant" Is Not Really Helpful:
                  Personas in System Prompts Do Not Improve
                  Performances of Large Language Models}},
	year = 2023,
	eprint = {2311.10054v3},
	primaryclass = {cs.CL},
	archiveprefix = {arXiv}
}

@article{zheng2025UnsupervisedOntologyConstruction,
	file = {References/pdf/zheng2025UnsupervisedOntologyConstruction.pdf},
	title = {An {Unsupervised} {Ontology} {Construction} {Method} {Based} on {Pre}-trained {Language} {Model}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013077743&doi=10.1145%2F3730436.3730532&partnerID=40&md5=e921376d1dd8149b1f6af466fd0859fb},
	doi = {10.1145/3730436.3730532},
	abstract = {With the fast growth of text data, the importance of automatic ontology construction has grown significantly. The proposed article provides a novel approach by applying pre-trained language models to automatically construct the ontology. The framework consists of two sequential phases: automatic concept discovery and automatic relation discovery. In the context of automatic concept discovery, instances and their embedding vectors are extracted first through Named Entity Recognition (NER). Then, the unsupervised affinity propagation (AP) clustering algorithm is applied to classify these embedding vectors, resulting in the discovery of the concepts. A denoising method is discussed to obtain higher accuracy with respect to the concepts obtained to reduce noise caused by complete clustering. Related to automatic relation discovery between concepts (mentioned in the next section), the process generates inexplicable concepts that are contextually similar based on the embedded vectors of instances mapping over the two entities. This can enable unsupervised automatic discovery of relations between the contextually related concepts. This method shows a certain feasibility and achieves early effectiveness in unsupervised automatic ontology construction with the experimental results. © 2025 Elsevier B.V., All rights reserved.},
	author = {Zheng, Hanqi and Ouyang, Guige and Huang, Yongzhong},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Pre-trained language model, Embeddings, Data mining, Ontology construction, Clustering algorithms, Affinity propagation, Automatic ontology, Automatic ontology construction, Concept discoveries, Construction method},
	pages = {588 -- 595},
	annote = {Type: Conference paper}
}

@Article{zhou2007OntologyLearningState,
	file = {References/pdf/zhou2007OntologyLearningState.pdf},
	author = {Lina Zhou},
	title = {Ontology learning: state of the art and open issues},
	journal = {Inf. Technol. Manag.},
	year = 2007,
	volume = 8,
	number = 3,
	pages = {241-252},
	doi = {10.1007/S10799-007-0019-5},
	url = {https://doi.org/10.1007/s10799-007-0019-5},
	timestamp = {Tue, 01 Jun 2021 15:21:20 +0200},
	biburl = {https://dblp.org/rec/journals/itm/Zhou07.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{zotova2022ClinidmapTowardsClinical,
	file = {References/pdf/zotova2022ClinidmapTowardsClinical.pdf},
	title = {{ClinIDMap}: {Towards} a {Clinical} {IDs} {Mapping} for {Data} {Interoperability}},
	url = {https://aclanthology.org/2022.lrec-1.390/},
	abstract = {This paper presents ClinIDMap, a tool for mapping identifiers between clinical ontologies and lexical resources. ClinIDMap interlinks identifiers from UMLS, SMOMED-CT, ICD-10 and the corresponding Wikipedia articles for concepts from the UMLS Metathesaurus. Our main goal is to provide semantic interoperability across the clinical concepts from various knowledge bases. As a side effect, the mapping enriches already annotated corpora in multiple languages with new labels. For instance, spans manually annotated with IDs from UMLS can be annotated with Semantic Types and Groups, and its corresponding SNOMED CT and ICD-10 IDs. We also experiment with sequence labelling models for detecting Diagnosis and Procedures concepts and for detecting UMLS Semantic Groups trained on Spanish, English, and bilingual corpora obtained with the new mapping procedure. The ClinIDMap tool is publicly available.},
	journal = {Proceedings of the Thirteenth Language Resources and Evaluation Conference},
	author = {Zotova, Elena and Cuadros, Montse and Rigau, German},
	editor = {Calzolari, Nicoletta and Béchet, Frédéric and Blache, Philippe and Choukri, Khalid and Cieri, Christopher and Declerck, Thierry and Goggi, Sara and Isahara, Hitoshi and Maegaard, Bente and Mariani, Joseph and Mazo, Hélène and Odijk, Jan and Piperidis, Stelios},
	month = jun,
	year = {2022},
	note = {Place: Marseille, France
Publisher: European Language Resources Association
Section: 0},
	pages = {3661--3669}
}

@article{ŝvabzamazal2024TowardsPatternBased,
	file = {References/pdf/ŝvabzamazal2024TowardsPatternBased.pdf},
	title = {Towards {Pattern}-based {Complex} {Ontology} {Matching} using {SPARQL} and {LLM}},
	volume = {3759},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204733796&partnerID=40&md5=5f38b3109696be1d51c0bc9e2ef0d2c3},
	abstract = {Complex ontology matching is a process to match complex structures in ontologies.While many matching tools tackle simple ontology matching, complex ontology matching is still rare.However, one entity in one ontology can be similar to a complex structure (1-to-n) or even complex structures can be on both sides (m-to-n).Therefore, the application, e.g., data integration, must consider complex correspondences within ontology alignment.Our poster paper presents a pattern-based approach where particular SPARQL queries correspond to a specific pattern, e.g., Class by Attribute Type (CAT), for its detection.SPARQL queries are anchored to entities from simple correspondences on input.Detected complex correspondence candidates are verbalized to be validated by the Large Language Model (LLM).Further, we provide a zero-shot prompting preliminary experiment and evaluation.The poster paper is equipped with the Jupyter notebook for automation of the pipeline and the full report of the experiment at: https://github.com/OndrejZamazal/ComplexOntologyMatching-SEMANTiCS2024. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Ŝváb-Zamazal, Ondr̂ej Ř.Ej},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Semantics, Ontology matching, Modeling languages, Structured Query Language, Ontology's, Complexes structure, Simple++, Complex ontology matching, Complex correspondences},
	annote = {Type: Conference paper}
}

